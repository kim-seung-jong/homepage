{
  
    
        "post0": {
            "title": "Title",
            "content": "코드 출처 - 이제현님 블로그 . https://jehyunlee.github.io/2020/09/30/Python-DS-34-seaborn_matplotlib/ . 1.1 Load data . 예제로 사용할 펭귄 데이터를 불러옵니다. | seaborn에 내장되어 있습니다. | . import pandas as pd import matplotlib.pyplot as plt import seaborn as sns penguins = sns.load_dataset(&quot;penguins&quot;) penguins.head() . species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex . 0 Adelie | Torgersen | 39.1 | 18.7 | 181.0 | 3750.0 | Male | . 1 Adelie | Torgersen | 39.5 | 17.4 | 186.0 | 3800.0 | Female | . 2 Adelie | Torgersen | 40.3 | 18.0 | 195.0 | 3250.0 | Female | . 3 Adelie | Torgersen | NaN | NaN | NaN | NaN | NaN | . 4 Adelie | Torgersen | 36.7 | 19.3 | 193.0 | 3450.0 | Female | . 1.2 Figure and Axes . matplotlib으로 도화지figure를 깔고 축공간axes를 만듭니다. | 1 x 2 축공간을 구성합니다. | . fig, axes = plt.subplots(ncols=2, figsize=(8,4)) fig.tight_layout() . 1.3 plot with matplotlib . matplotlib 기능을 이용해서 산점도를 그립니다. | x축은 부리 길이 bill length | y축은 부리 위 아래 두께 bill depth | 색상은 종species로 합니다. | Adelie, Chinstrap, Gentoo이 있습니다. | 두 축공간 중 왼쪽에만 그립니다. | 컬러를 다르게 주기 위해 f-string 포맷을 사용했습니다. | f-string 포맷에 대한 설명은 https://blockdmask.tistory.com/429를 참고하세요 | . fig, axes = plt.subplots(ncols=2,figsize=(8,4)) species_u = penguins[&quot;species&quot;].unique() for i, s in enumerate(species_u): axes[0].scatter(penguins[&quot;bill_length_mm&quot;].loc[penguins[&quot;species&quot;]==s], penguins[&quot;bill_depth_mm&quot;].loc[penguins[&quot;species&quot;]==s], c=f&quot;C{i}&quot;, label=s, alpha=0.3) axes[0].legend(species_u, title=&quot;species&quot;) axes[0].set_xlabel(&quot;Bill Length (mm)&quot;) axes[0].set_ylabel(&quot;Bill Depth (mm)&quot;) # plt.show() fig.tight_layout() . 조금 더 간단히 그리는 방법 matplotlib는 기본적으로 Categorical 변수를 color로 바로 사용하지 못함 . penguins[&quot;species_codes&quot;] = pd.Categorical(penguins[&quot;species&quot;]).codes fig, axes = plt.subplots(ncols=2,figsize=(8,4)) axes[0].scatter(data=penguins, x=&quot;bill_length_mm&quot;, y=&quot;bill_depth_mm&quot;, c=&quot;species_codes&quot;, alpha=0.3) . &lt;matplotlib.collections.PathCollection at 0x19cb92d2b00&gt; . 1.4 Plot with seaborn . fig, axes = plt.subplots(ncols=2,figsize=(8,4)) species_u = penguins[&quot;species&quot;].unique() # plot 0 : matplotlib for i, s in enumerate(species_u): axes[0].scatter(penguins[&quot;bill_length_mm&quot;].loc[penguins[&quot;species&quot;]==s], penguins[&quot;bill_depth_mm&quot;].loc[penguins[&quot;species&quot;]==s], c=f&quot;C{i}&quot;, label=s, alpha=0.3) axes[0].legend(species_u, title=&quot;species&quot;) axes[0].set_xlabel(&quot;Bill Length (mm)&quot;) axes[0].set_ylabel(&quot;Bill Depth (mm)&quot;) # plot 1 : seaborn sns.scatterplot(x=&quot;bill_length_mm&quot;, y=&quot;bill_depth_mm&quot;, hue=&quot;species&quot;, data=penguins, alpha=0.3, ax=axes[1]) axes[1].set_xlabel(&quot;Bill Length (mm)&quot;) axes[1].set_ylabel(&quot;Bill Depth (mm)&quot;) fig.tight_layout() . 단 세 줄로 거의 동일한 그림이 나왔습니다. scatter plot의 점 크기만 살짝 작습니다. | label의 투명도만 살짝 다릅니다. | . | seaborn 명령 scatterplot()을 그대로 사용했습니다. | x축과 y축 label도 바꾸었습니다. ax=axes[1] 인자에서 볼 수 있듯, 존재하는 axes에 그림만 얹었습니다. | matplotlib 틀 + seaborn 그림 이므로, matplotlib 명령이 모두 통합니다. | . | . 1.5 matplotlib + seaborn &amp; seaborn + matplotlib . matplotlib과 seaborn이 자유롭게 섞일 수 있습니다. matplotlib 산점도 위에 seaborn 추세선을 얹을 수 있고, | seaborn 산점도 위에 matplotlib 중심점을 얹을 수 있습니다. | . | 파이썬 코드는 다음과 같습니다. | . fig, axes = plt.subplots(ncols=2, figsize=(8, 4)) species_u = penguins[&quot;species&quot;].unique() # plot 0 : matplotlib + seaborn for i, s in enumerate(species_u): # matplotlib 산점도 axes[0].scatter(penguins[&quot;bill_length_mm&quot;].loc[penguins[&quot;species&quot;]==s], penguins[&quot;bill_depth_mm&quot;].loc[penguins[&quot;species&quot;]==s], c=f&quot;C{i}&quot;, label=s, alpha=0.3 ) # seaborn 추세선 sns.regplot(x=&quot;bill_length_mm&quot;, y=&quot;bill_depth_mm&quot;, data=penguins.loc[penguins[&quot;species&quot;]==s], scatter=False, ax=axes[0]) axes[0].legend(species_u, title=&quot;species&quot;) axes[0].set_xlabel(&quot;Bill Length (mm)&quot;) axes[0].set_ylabel(&quot;Bill Depth (mm)&quot;) # plot 1 : seaborn + matplotlib # seaborn 산점도 sns.scatterplot(x=&quot;bill_length_mm&quot;, y=&quot;bill_depth_mm&quot;, hue=&quot;species&quot;, data=penguins, alpha=0.3, ax=axes[1]) axes[1].set_xlabel(&quot;Bill Length (mm)&quot;) axes[1].set_ylabel(&quot;Bill Depth (mm)&quot;) for i, s in enumerate(species_u): # matplotlib 중심점 axes[1].scatter(penguins[&quot;bill_length_mm&quot;].loc[penguins[&quot;species&quot;]==s].mean(), penguins[&quot;bill_depth_mm&quot;].loc[penguins[&quot;species&quot;]==s].mean(), c=f&quot;C{i}&quot;, alpha=1, marker=&quot;x&quot;, s=100 ) fig.tight_layout() . 1.6 seaborn + seaborn + matplotlib . 안 될 이유가 없습니다. | seaborn scatterplot + seaborn kdeplot + matplotlib text입니다 | . fig, ax = plt.subplots(figsize=(6,5)) # plot 0: scatter plot sns.scatterplot(x=&quot;bill_length_mm&quot;, y=&quot;bill_depth_mm&quot;, color=&quot;k&quot;, data=penguins, alpha=0.3, ax=ax, legend=False) # plot 1: kde plot sns.kdeplot(x=&quot;bill_length_mm&quot;, y=&quot;bill_depth_mm&quot;, hue=&quot;species&quot;, data=penguins, alpha=0.5, ax=ax, legend=False) # text: species_u = penguins[&quot;species&quot;].unique() for i, s in enumerate(species_u): ax.text(penguins[&quot;bill_length_mm&quot;].loc[penguins[&quot;species&quot;]==s].mean(), penguins[&quot;bill_depth_mm&quot;].loc[penguins[&quot;species&quot;]==s].mean(), s = s, fontdict={&quot;fontsize&quot;:14, &quot;fontweight&quot;:&quot;bold&quot;,&quot;color&quot;:&quot;k&quot;} ) ax.set_xlabel(&quot;Bill Length (mm)&quot;) ax.set_ylabel(&quot;Bill Depth (mm)&quot;) fig.tight_layout() .",
            "url": "https://kim-seung-jong.github.io/homepage/2022/06/15/seaborn_and_matplotlib.html",
            "relUrl": "/2022/06/15/seaborn_and_matplotlib.html",
            "date": " • Jun 15, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Title",
            "content": "Data Mining Final Project . &#53076;&#47196;&#45208; &#45936;&#51060;&#53552; &#49884;&#44033;&#54868; . &#47785;&#52264; . 1. 분석 배경 및 목적 1-1. 분석 목적 | 1-2. 패키지 설치 | . | 2. 데이터 소개 및 설명 2-1. 데이터 제공 | 2-2. 데이터 소개 | 2-3. 데이터 불러오기 | . | 3. 분석 결과 3_1. 코로나로 인한 검색 트랜드 변화 결과 | . | 3_2. 지역별 확진자 수 현황 결과 | . | 3_3. 대구 코로나 감염의 집단 감염 여부 결과 | . | 3_4. 집단 감염이 100명 이상인 감염경로 결과 | . | 3_5. 연령대 별 확진자 수 결과 | . | 3_6. 연령대 별 접촉자 수 평균 결과 | . | . | 4. 결론 분석을 통한 내용 | . | . 1. &#48516;&#49437; &#48176;&#44221; &#48143; &#47785;&#51201; . 데이콘에서 진행했던 코로나 데이터 시각화 AI 경진대회에 사용했던 데이터를 사용 | . 1-1. &#48516;&#49437; &#47785;&#51201; . 코로나로 인하여 검색량에 변화와 가장 많이 코로나 피해를 입은 지역, 가장 많이 확진된 지역에 집단감염 여부, 연령대 확진자와 접촉자 평균을 알아보기 위해 진행하였다. | . 1-2. &#54056;&#53412;&#51648; &#49444;&#52824; . import numpy as np import pandas as pd import plotly import matplotlib.pylab as plt import seaborn as sns import plotly.express as px import plotly.offline as plyo import cufflinks import plotly.graph_objects as go . from matplotlib import font_manager, rc # matplotlib 패키지의 font_manager를 로드 font_name = font_manager.FontProperties(fname=&quot;c:/Windows/Fonts/malgun.ttf&quot;).get_name() # 폰트 이름을 변수에 할당 rc(&#39;font&#39;, family=font_name) # 폰트 이름으로 설정 . 2. &#45936;&#51060;&#53552; &#49548;&#44060; &#48143; &#49444;&#47749; . 2-1. &#45936;&#51060;&#53552; &#51228;&#44277; . 데이콘 | . 2-2. &#45936;&#51060;&#53552; &#49548;&#44060; . &#39;코로나 데이터 시각화 AI 경진대회&#39; 데이터 Case.csv.csv : 확진자에 지역 관련 데이터 | PatientInfo.csv : 환자의 정보 데이터 | Searchtrend.csv : 일별 검색량 데이터 | . | . 2-3. &#45936;&#51060;&#53552; &#48520;&#47084;&#50724;&#44592; . case = pd.read_csv(&quot;coronavirusdataset_20200430/Case.csv&quot;) patient_info = pd.read_csv(&#39;coronavirusdataset_20200430/PatientInfo.csv&#39;) SearchTrend = pd.read_csv(&#39;coronavirusdataset_20200430/SearchTrend.csv&#39;) . 3. &#48516;&#49437; &#44208;&#44284; . 3-1. &#53076;&#47196;&#45208;&#47196; &#51064;&#54620; &#44160;&#49353; &#53944;&#47004;&#46300; &#48320;&#54868; . SearchTrend.csv 이용 | 결측값이 있나 확인 후 2019.12.01 ~ 2020.04.29까지 알아보기 위하여 행을 지정 후 만든 데이터를 새로운 이름으로 넣어준다. | . SearchTrend.isnull().sum() # 결측값 확인 . date 0 cold 0 flu 0 pneumonia 0 coronavirus 0 dtype: int64 . Search=SearchTrend[&#39;date&#39;] Search1Year=Search[1430:] SearchC=SearchTrend[&#39;cold&#39;] SearchCold=SearchC[1430:] SearchF=SearchTrend[&#39;flu&#39;] SearchFlu=SearchF[1430:] SearchP=SearchTrend[&#39;pneumonia&#39;] SearchPneumonia=SearchP[1430:] SearchCorona=SearchTrend[&#39;coronavirus&#39;] SearchCoronavirus=SearchCorona[1430:] Search1Year . 1430 2019-12-01 1431 2019-12-02 1432 2019-12-03 1433 2019-12-04 1434 2019-12-05 ... 1576 2020-04-25 1577 2020-04-26 1578 2020-04-27 1579 2020-04-28 1580 2020-04-29 Name: date, Length: 151, dtype: object . plt.figure(figsize=(20,7)) # 사이즈 plt.plot(Search1Year,SearchCold) # 보여주기 plt.plot(Search1Year,SearchFlu) plt.plot(Search1Year,SearchPneumonia) plt.plot(Search1Year,SearchCoronavirus) plt.title(&#39;19.12.01 ~ 20.04.29 검색량&#39;) # 제목 plt.xlabel(&#39;날짜&#39;) # x축 이름 plt.ylabel(&#39;검색량&#39;) # y축 이름 plt.xticks(fontsize=8,rotation=55) # 폰트 사이즈 plt.legend([&#39;감기&#39;,&#39;발열&#39;,&#39;폐렴&#39;,&#39;코로나바이러스&#39;],fontsize=12) # 그래프에 색에 따른 이름 plt.show() . &#44208;&#44284; . 20.01.07에 사람들이 코로나에 여부를 알았으며, 20.01.18에 사람들에 관심이 매우 증가한 것을 알 수 있다. | . 3-2. &#51648;&#50669;&#48324; &#54869;&#51652;&#51088; &#49688; &#54788;&#54889; . Case.csv 이용 | 지역별로 groupby()하여 지역별 총 confirmed를 내림차순으로 정렬 | . case.head() . case_id province city group infection_case confirmed latitude longitude . 0 1000001 | Seoul | Guro-gu | True | Guro-gu Call Center | 98 | 37.508163 | 126.884387 | . 1 1000002 | Seoul | Dongdaemun-gu | True | Dongan Church | 20 | 37.592888 | 127.056766 | . 2 1000003 | Seoul | Guro-gu | True | Manmin Central Church | 41 | 37.481059 | 126.894343 | . 3 1000004 | Seoul | Eunpyeong-gu | True | Eunpyeong St. Mary&#39;s Hospital | 14 | 37.63369 | 126.9165 | . 4 1000005 | Seoul | Seongdong-gu | True | Seongdong-gu APT | 13 | 37.55713 | 127.0403 | . group_province = case.groupby(&quot;province&quot;).sum() # 지역별로 groupby하여 group를 묶어서 지역별 확진자 보기 . group_province = group_province.sort_values(by=&quot;confirmed&quot;, ascending=False) # ascending = False 내림차순정렬 / confirmed 기준 내림차순 group_province.head(20) # 상위 20개 보기 / 18개 밖에 없어서 18개만 보여준다 . case_id group confirmed . province . Daegu 10800045 | 6 | 6650 | . Gyeongsangbuk-do 72000078 | 9 | 1314 | . Seoul 11000066 | 8 | 574 | . Gyeonggi-do 18000045 | 6 | 556 | . Busan 9900045 | 6 | 139 | . Chungcheongnam-do 20500015 | 2 | 137 | . Gyeongsangnam-do 61000055 | 7 | 115 | . Incheon 7000015 | 2 | 79 | . Gangwon-do 18000021 | 3 | 51 | . Sejong 10200021 | 3 | 46 | . Ulsan 6400010 | 1 | 42 | . Chungcheongbuk-do 20000015 | 2 | 38 | . Daejeon 9000021 | 3 | 34 | . Gwangju 5200010 | 1 | 30 | . Jeollanam-do 25500015 | 2 | 16 | . Jeollabuk-do 15000006 | 1 | 15 | . Jeju-do 21000006 | 0 | 13 | . plt.figure(figsize=(23,9)) sns.barplot(data=group_province, x=group_province.index, y=&#39;confirmed&#39;) # group_province에 x,y로 그래프 그리기 plt.show() . &#44208;&#44284; . 위에 표와 같이 대구 -&gt; 경북 -&gt; 서울 순으로 확진자가 많고 대구가 절반 이상을 차지한 것을 알 수 있다. | . 3-3. &#45824;&#44396; &#53076;&#47196;&#45208; &#44048;&#50684;&#51032; &#51665;&#45800; &#44048;&#50684; &#50668;&#48512; . Case.csv 사용 | Daegu 행을 찾아서 case_Daegu로 만든다. | . case_Daegu=case[20:29] # 대구가 20:29까지여서 20:29까지 추출후 case_Daegu로 만든다. case_Daegu . case_id province city group infection_case confirmed latitude longitude . 20 1200001 | Daegu | Nam-gu | True | Shincheonji Church | 4510 | 35.84008 | 128.5667 | . 21 1200002 | Daegu | Dalseong-gun | True | Second Mi-Ju Hospital | 196 | 35.857375 | 128.466651 | . 22 1200003 | Daegu | Seo-gu | True | Hansarang Convalescent Hospital | 128 | 35.885592 | 128.556649 | . 23 1200004 | Daegu | Dalseong-gun | True | Daesil Convalescent Hospital | 100 | 35.857393 | 128.466653 | . 24 1200005 | Daegu | Dong-gu | True | Fatima Hospital | 37 | 35.88395 | 128.624059 | . 25 1200006 | Daegu | from other city | True | Cheongdo Daenam Hospital | 2 | - | - | . 26 1200007 | Daegu | - | False | overseas inflow | 24 | - | - | . 27 1200008 | Daegu | - | False | contact with patient | 929 | - | - | . 28 1200009 | Daegu | - | False | etc | 724 | - | - | . plt.figure(figsize=(4,4)) plt.bar(case_Daegu[&#39;group&#39;], case_Daegu[&#39;confirmed&#39;]) # 집단감염 T/F, 확진자 수 plt.title(&#39;대구 집단감염 여부&#39;) # 제목 plt.xlabel(&#39;집단 감염 T/F&#39;) # x축 plt.ylabel(&#39;확진자 수&#39;) # y축 plt.xticks([0,1],[&#39;집단 감염X&#39;,&#39;집단 감염&#39;]) plt.show() . &#44208;&#44284; . 대구 전체 확진자 6천명 이상 가운데 4천명 이상이 집단으로 감염된 것을 확인할 수 있다. | . 3-4. &#51665;&#45800; &#44048;&#50684;&#51060; 100&#47749; &#51060;&#49345;&#51064; &#44048;&#50684;&#44221;&#47196; . Case.csv 이용 | confirmed가 100이상 추출 | . case100 = case[case[&#39;confirmed&#39;] &gt;= 100] # case데이터에서 confirmed가 100개 이상인 것 case100 . case_id province city group infection_case confirmed latitude longitude . 8 1000009 | Seoul | - | False | overseas inflow | 321 | - | - | . 20 1200001 | Daegu | Nam-gu | True | Shincheonji Church | 4510 | 35.84008 | 128.5667 | . 21 1200002 | Daegu | Dalseong-gun | True | Second Mi-Ju Hospital | 196 | 35.857375 | 128.466651 | . 22 1200003 | Daegu | Seo-gu | True | Hansarang Convalescent Hospital | 128 | 35.885592 | 128.556649 | . 23 1200004 | Daegu | Dalseong-gun | True | Daesil Convalescent Hospital | 100 | 35.857393 | 128.466653 | . 27 1200008 | Daegu | - | False | contact with patient | 929 | - | - | . 28 1200009 | Daegu | - | False | etc | 724 | - | - | . 60 2000007 | Gyeonggi-do | - | False | overseas inflow | 225 | - | - | . 74 4100001 | Chungcheongnam-do | Cheonan-si | True | gym facility in Cheonan | 103 | 36.81503 | 127.1139 | . 87 6000001 | Gyeongsangbuk-do | from other city | True | Shincheonji Church | 566 | - | - | . 88 6000002 | Gyeongsangbuk-do | Cheongdo-gun | True | Cheongdo Daenam Hospital | 120 | 35.64887 | 128.7368 | . 97 6000011 | Gyeongsangbuk-do | - | False | contact with patient | 192 | - | - | . 98 6000012 | Gyeongsangbuk-do | - | False | etc | 134 | - | - | . case100_1 = pd.DataFrame(case100.groupby([&#39;infection_case&#39;])[&#39;confirmed&#39;].max()) # case100데이터를 가지고 infection_case, confirmed groupby. max case100_1 = case100_1.sort_values(by=[&#39;confirmed&#39;], ascending=False) # confirmed를 기준으로 내림차순 정렬 case100_1 . confirmed . infection_case . Shincheonji Church 4510 | . contact with patient 929 | . etc 724 | . overseas inflow 321 | . Second Mi-Ju Hospital 196 | . Hansarang Convalescent Hospital 128 | . Cheongdo Daenam Hospital 120 | . gym facility in Cheonan 103 | . Daesil Convalescent Hospital 100 | . # case100_1데이터에서 values(값) = confirmed, names = case100_1.index 크기 순으로 나온값 fig = px.pie(case100_1, values=&#39;confirmed&#39;, names= case100_1.index, title= &#39;집단 감염이 100명 이상인 감염경로&#39;) # 제목 fig.update_traces( textinfo=&#39;percent+label&#39;) # percent와 label이 나오게 fig.show() . &#44208;&#44284; . 표를 보면 알 수 있듯이 신천지가 63.2%로 가장 높고, 확진자, 기타, 해외유입을 제외하면 미주병원, 한사랑 요양병원 순으로 높은 것을 알 수 있다. . 3-5. &#50672;&#47161;&#45824; &#48324; &#54869;&#51652;&#51088; &#49688; . PatientInfo.csv 이용 | . patient_1 = patient_info.groupby(&#39;age&#39;).count().patient_id fig = patient_1.iplot(asFigure=True, kind=&#39;bar&#39;, color = &#39;green&#39;, title=&quot;연령대 별 확진자 수&quot;, xTitle=&#39;연련대&#39;, yTitle=&#39;확진자 수&#39;) fig.show() . &#44208;&#44284; . 20s -&gt; 50s -&gt; 40s 순으로 확진자가 많다. | 10s는 높지 않은 비율을 보여준다. | . 3-6. &#50672;&#47161;&#45824; &#48324; &#51217;&#52489;&#51088; &#49688; &#54217;&#44512; . PatientInfo.csv 이용 | 90s와 100s에 결측 값이 있어 제거 후 평균 추출 | . # patient_info에서 age groupby하고 contact_number에 평균을 구한다. patient_mean = pd.DataFrame(patient_info.groupby([&#39;age&#39;])[&#39;contact_number&#39;].mean()) patient_mean . contact_number . age . 0s 1.818182 | . 100s NaN | . 10s 38.969697 | . 20s 15.851064 | . 30s 16.191919 | . 40s 19.603306 | . 50s 18.108108 | . 60s 22.878378 | . 70s 5.612903 | . 80s 15.230769 | . 90s NaN | . patient_mean = patient_mean.dropna(axis=0) # 평균을 구하고 결측값이 있는 행을 제거한다. patient_mean . contact_number . age . 0s 1.818182 | . 10s 38.969697 | . 20s 15.851064 | . 30s 16.191919 | . 40s 19.603306 | . 50s 18.108108 | . 60s 22.878378 | . 70s 5.612903 | . 80s 15.230769 | . labels = [&#39;0s&#39;,&#39;10s&#39;,&#39;20s&#39;,&#39;30s&#39;,&#39;40s&#39;, &#39;50s&#39;,&#39;60s&#39;,&#39;70s&#39;,&#39;80s&#39;] # 연령대 age values = [1.818182, 38.969697, 15.851064, 16.191919,19.603306, 18.108108,22.878378,5.612903,15.230769] # 평균 contact_number fig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.3, title = &#39;연령별 접촉자 평균&#39;)]) fig.update_traces( textinfo=&#39;percent+label&#39;) fig.show() . &#44208;&#44284; . 연령대 별 확진자는 20s가 가장 많았는데, 접촉자는 10s가 가장 높은 비율을 보이고 있다. | 연령대 별 확진자 수와 접촉자 수는 깊은 관계를 가지고 있지 않는 것 같다. | . 4. &#44208;&#47200; . 4-1. &#48516;&#49437;&#51012; &#53685;&#54620; &#45236;&#50857; . 코로나가 알려진 이후 검색량이 코로나 위주로 크게 바뀌였다. | 대구에서 발생한 코로나 확진자들은 절반 이상이 집단으로 감염되었다. | 집단 감염이 100명 이상인 곳은 대구 신천지가 63.2%로 많은 비율을 차지한다. | 20대 확진자가 가장 많지만, 연령별로 접촉한 인원은 10대가 가장 높다. |",
            "url": "https://kim-seung-jong.github.io/homepage/2022/06/15/data_mining(final).html",
            "relUrl": "/2022/06/15/data_mining(final).html",
            "date": " • Jun 15, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "목차",
            "content": "원문: by Aurélien Geron (Link) . | Translated by Chansung PARK (Link) . | Object Oriented API Addition by Jehyun LEE (Link) | . Tools - matplotlib . 이 노트북은 matplotlib 라이브러리를 사용하여 아름다운 그래프를 그리는 방법을 보여줍니다. . 이제현 주 : 원 코드가 pyplot 기반으로 작성되었기에 object oriented API를 추가하였습니다. pyplot은 pandas 같은 라이브러리와 함께 사용하며 그래프를 빠르게 그려보기 좋습니다. 그러나 코드의 가독성과 섬세한 제어는 object oriented API(객체지향 인터페이스)방식이 더 유리하게 느껴집니다. . pyplot과 object oriented API의 차이에 대해 상세히 알고 싶으시면 이 글을 참고하십시오 | . . &#52376;&#51020;&#51004;&#47196; &#44536;&#47140;&#48372;&#45716; &#44536;&#47000;&#54532; . 우선은 matplotlib 라이브러리를 임포트 해줘야 합니다. . import matplotlib . Matplotlib은 Tk, wxPython 등과 같이 다양한 그래픽 라이브러리를 기반으로 사용하여 그래프를 출력할 수 있습니다. 명령줄을 사용하여 Python을 실행하는 경우, 일반적으로 그래프는 별도의 윈도우 창에서 나타납니다. 주피터 노트북을 사용한다면, %matplotlib inline 이라는 magic command를 사용하여 노트북 속에서 그래프를 출력할 수 있습니다. . 이제현 주:* 매직 명령어, 마술 명령어라고도 불리는 Magic command는 파이썬 코드를 실행하는 것이 아니라 주피터 노트북이나 Colab같은 IPython 커널 사용을 도와주는 명령입니다. 현재 작업 디렉토리를 확인하거나(%pwd) 작업 수행에 걸리는 시간을 확인할 수 있습니다(%timeit). 여기서는 matplotlib의 실행 결과를 노트북에 그대로 보여주도록 지정하고 있습니다(%matplotlib inline). . magic command에 대해 자세히 알고 싶으면 이 글을 참고하세요.) | . %matplotlib inline # matplotlib.use(&quot;TKAgg&quot;) # 그래픽 백엔드로 Tk를 사용하고자 한다면, 이 코드를 사용하시기 바랍니다. . 그러면 첫 번째 그래프를 그려보겠습니다! :) . import matplotlib.pyplot as plt plt.plot([1, 2, 4, 9, 5, 3]) plt.show() . 그렇습니다. 데이터 몇 개로 plot 함수를 호출한 다음, show 함수를 호출해주면 간단히 그래프를 그려볼 수 있습니다! . plot 함수에 단일 배열의 데이터가 주어진다면, 수직 축의 좌표로서 이를 사용하게 되며, 각 데이터의 배열상 색인(인덱스)을 수평 좌표로서 사용합니다. 두 개의 배열을 넣어줄 수도 있습니다: 그러면, 하나는 x 축에 대한것이며, 다른 하나는 y 축에 대한것이 됩니다: . 이제현 주: 같은 그림을 object oriented API를 이용해 그려보겠습니다. object oriented API는 그래프의 각 부분을 객체로 지정하고 그리는 것으로, 다음과 같은 패턴을 가지고 있습니다. 아래 코드와 주석의 # object oriented API 부분은 이제현이 추가한 부분입니다. . object oriented API와 구분하기 위해 원본 코드에는 #pyplot이라는 헤더를 달았습니다.) | . fig, ax = plt.subplot() ax.plot([1,2,4,9,5,3]) plt.show() . TypeError Traceback (most recent call last) c: Users user Desktop VS_C data_mining notebook Tools_matplotlib_(박찬성_번역_이제현_OO_API_추가).ipynb Cell 13&#39; in &lt;cell line: 1&gt;() -&gt; &lt;a href=&#39;vscode-notebook-cell:/c%3A/Users/user/Desktop/VS_C/data_mining/notebook/Tools_matplotlib_%28%EB%B0%95%EC%B0%AC%EC%84%B1_%EB%B2%88%EC%97%AD_%EC%9D%B4%EC%A0%9C%ED%98%84_OO_API_%EC%B6%94%EA%B0%80%29.ipynb#ch0000135?line=0&#39;&gt;1&lt;/a&gt; fig, ax = plt.subplot() &lt;a href=&#39;vscode-notebook-cell:/c%3A/Users/user/Desktop/VS_C/data_mining/notebook/Tools_matplotlib_%28%EB%B0%95%EC%B0%AC%EC%84%B1_%EB%B2%88%EC%97%AD_%EC%9D%B4%EC%A0%9C%ED%98%84_OO_API_%EC%B6%94%EA%B0%80%29.ipynb#ch0000135?line=2&#39;&gt;3&lt;/a&gt; ax.plot([1,2,4,9,5,3]) &lt;a href=&#39;vscode-notebook-cell:/c%3A/Users/user/Desktop/VS_C/data_mining/notebook/Tools_matplotlib_%28%EB%B0%95%EC%B0%AC%EC%84%B1_%EB%B2%88%EC%97%AD_%EC%9D%B4%EC%A0%9C%ED%98%84_OO_API_%EC%B6%94%EA%B0%80%29.ipynb#ch0000135?line=4&#39;&gt;5&lt;/a&gt; plt.show() TypeError: cannot unpack non-iterable AxesSubplot object . fig, ax = plt.subplots() # fig=종이, ax=그림 # 2. ax 위에 그래프를 그립니다. ax.plot([1, 2, 4, 9, 5, 3]) # 3. 그래프를 화면에 출력합니다. plt.show() . 이제현 주: pyplot과 동일한 형태의 그래프가 그려집니다. fig, ax를 선언하느라 한 줄을 더 입력해야 한다는 불편함이 있지만 ax 객체가 있어 그래프를 제어하기 더 쉬워집니다. . 많은 경우 fig, ax = plt.subplots() 대신 ax = plt.subplot()으로 해도 됩니다. | 그러나 fig 대상 명령(예. savefig)을 사용해야 할 때도 있고, 두 가지를 따로 외우려면 혼동이 되니 한 가지로 통일하는 것이 좋습니다. | . plt.plot([-3, -2, 5, 0], [1, 6, 4, 3]) # 앞에 x좌표, 뒤에가 y좌표 plt.show() . fig, ax = plt.subplots() ax.plot([-3, -2, 5, 0], [1, 6, 4, 3]) plt.show() . 이번에는 수학적인 함수를 그려보겠습니다. NumPy의 linespace 함수를 사용하여 -2 ~ 2 범위에 속하는 500개의 부동소수로 구성된 x 배열을 생성합니다. 그 다음 x의 각 값의 거듭제곱된 값을 포함하는 y 배열을 생성합니다 (NumPy에 대하여 좀 더 알고 싶다면, NumPy 튜토리얼을 참고하시기 바랍니다). . import numpy as np x = np.linspace(-2, 2, 500) # -2부터 2까지 500 y = x**2 plt.plot(x, y) plt.show() . fig, ax = plt.subplots() ax.plot(x, y) plt.show() . 그래프가 약간은 삭막해 보입니다. 타이틀과 x 및 y축에 대한 라벨, 그리고 모눈자를 추가적으로 그려보겠습니다. . plt.plot(x, y) plt.title(&quot;Square function&quot;) plt.xlabel(&quot;x&quot;) plt.ylabel(&quot;y = x**2&quot;) plt.grid(True) plt.show() . 이제현 주 : object-oriented API는 축 이름과 같은 설정 명령어가 pyplot과 다소 다릅니다. 대체로 축 이름(label), 범위(limits) 등을 지정하는 명령어는 set_대상(), 거꾸로 그래프에서 설정값을 가져오는 명령어는 get_대상()으로 통일되어 있습니다. . 개인적으로 pyplot의 명령어 체계보다 object-oriented API의 체계를 선호합니다. | . fig, ax = plt.subplots() ax.plot(x, y) ax.set_title(&quot;Square function&quot;) ax.set_xlabel(&quot;x&quot;) ax.set_ylabel(&quot;y = x**2&quot;) ax.grid(True) plt.show() . &#49440;&#51032; &#49828;&#53440;&#51068;&#44284; &#49353;&#49345; . 기본적으로 matplotlib은 바로 다음에 위치한(연이은) 데이터 사이에 선을 그립니다. . plt.plot([0, 100, 100, 0, 0, 100, 50, 0, 100], [0, 0, 100, 100, 0, 100, 130, 100, 0]) plt.axis([-10, 110, -10, 140]) plt.show() . fig, ax = plt.subplots() ax.plot([0, 100, 100, 0, 0, 100, 50, 0, 100], [0, 0, 100, 100, 0, 100, 130, 100, 0]) ax.set_xlim(-10, 110) # x축에 최소값, 최대값 ax.set_ylim(-10, 140) # y축에 최소값,최대값 # 그래프의 범위는 pyplot과 같이 ax.axis([-10, 110, -10, 140]) 으로 지정할 수 있습니다. # 하지만 위와 같이 set_xlim, set_ylim을 사용해서 명시하는 것이 더 체계적으로 느껴집니다. plt.show() . 세 번째 파라미터를 지정하면 선의 스타일과 색상을 바꿀 수 있습니다. 예를 들어서 &quot;g--&quot;는 &quot;초록색 파선&quot;을 의미합니다. 예를 들어 아래와 같이 말이죠: . plt.plot([0, 100, 100, 0, 0], [0, 0, 100, 100, 0], &quot;r-&quot;, [0, 100, 50, 0, 100], [0, 100, 130, 100, 0], &quot;g--&quot;) # - 하나면 실선, 두개면 점선 plt.axis([-10, 110, -10, 140]) plt.show() . fig, ax = plt.subplots() ax.plot([0, 100, 100, 0, 0], [0, 0, 100, 100, 0], &quot;r-&quot;, [0, 100, 50, 0, 100], [0, 100, 130, 100, 0], &quot;g--&quot;) ax.set_xlim(-10, 110) ax.set_ylim(-10, 140) plt.show() . 또는 show를 호출하기 전 plot을 여러번 호출해도 가능합니다. . plt.plot([0, 100, 100, 0, 0], [0, 0, 100, 100, 0], &quot;r-&quot;) plt.plot([0, 100, 50, 0, 100], [0, 100, 130, 100, 0], &quot;g--&quot;) plt.axis([-10, 110, -10, 140]) plt.show() . fig, ax = plt.subplots() ax.plot([0, 100, 100, 0, 0], [0, 0, 100, 100, 0], &quot;r-&quot;) ax.plot([0, 100, 50, 0, 100], [0, 100, 130, 100, 0], &quot;g--&quot;) ax.set_xlim(-10, 110) ax.set_ylim(-10, 140) plt.show() . 선 대신에 간단한 점을 그려보는 것도 가능합니다. 아래는 초록색 파선, 빨강 점선, 파랑 삼각형의 예를 보여줍니다. 공식 문서에서 사용 가능한 스타일 및 색상의 모든 옵션을 확인해 볼 수 있습니다. . x = np.linspace(-1.4, 1.4, 30) plt.plot(x, x, &#39;g--&#39;, x, x**2, &#39;r:&#39;, x, x**3, &#39;b^&#39;) # 뒤에가 선의 종류 plt.show() . fig, ax = plt.subplots() x = np.linspace(-1.4, 1.4, 30) ax.plot(x, x, &#39;g--&#39;) ax.plot(x, x**2, &#39;r:&#39;) ax.plot(x, x**3, &#39;b^&#39;) # 여러 그래프를 ax.plot(x, x, &#39;g--&#39;, x, x**2, &#39;r:&#39;, x, x**3, &#39;b^&#39;)과 같이 한 줄에 그릴 수도 있습니다. # 그러나 이와 같이 따로 떼서 그리면 혼동을 방지할 수 있습니다. # 이는 pyplot도 마찬가지입니다. plt.show() . plot 함수는 Line2D객체로 구성된 리스트를 반환합니다 (각 객체가 각 선에 대응됩니다). 이 선들에 대한 추가적인 속성을 설정할 수도 있습니다. 가령 선의 두께, 스타일, 투명도 같은것의 설정이 가능합니다. 공식 문서에서 설정 가능한 모든 속성을 확인해볼 수 있습니다. . x = np.linspace(-1.4, 1.4, 30) line1, line2, line3 = plt.plot(x, x, &#39;g--&#39;, x, x**2, &#39;r:&#39;, x, x**3, &#39;b^&#39;) line1.set_linewidth(3.0) # 굵기 line1.set_dash_capstyle(&quot;round&quot;) # line3.set_alpha(0.2) # 투명도 plt.show() . x = np.linspace(-1.4, 1.4, 30) fig, ax = plt.subplots() # plot을 나누어 그리면 어디에 어떤 설정이 적용되었는지 알아보기 편합니다. # linewidth, alpha와 같은 line style도 plot() 안에 넣으면 혼동을 방지할 수 있습니다. line1 = ax.plot(x, x, &#39;g--&#39;, linewidth=3, dash_capstyle=&#39;round&#39;) line2 = ax.plot(x, x**2, &#39;r:&#39;) line3 = ax.plot(x, x**3, &#39;b^&#39;, alpha=0.2) plt.show() . &#44536;&#47548; &#51200;&#51109; . 그래프를 그림파일로 저장하는 방법은 간단합니다. 단순히 파일이름을 지정하여 savefig 함수를 호출해 주기만 하면 됩니다. 가능한 이미지 포맷은 사용하는 그래픽 백엔드에 따라서 지원 여부가 결정됩니다. . x = np.linspace(-1.4, 1.4, 30) plt.plot(x, x**2) plt.savefig(&quot;my_square_function.png&quot;, transparent=True) . &#48512;&#48516; &#44536;&#47000;&#54532; (subplot) . matplotlib는 하나의 그림(figure)에 여러개의 부분 그래프를 포함할 수 있습니다. 이 부분 그래프는 격자 형식으로 관리됩니다. subplot 함수를 호출하여 부분 그래프를 생성할 수 있습니다. 이 때 격자의 행/열의 수 및 그래프를 그리고자 하는 부분 그래프의 색인을 파라미터로서 지정해줄 수 있습니다 (색인은 1부터 시작하며, 좌-&gt;우, 상단-&gt;하단의 방향입니다). . pyplot은 현재 활성화된 부분 그래프를 계속해서 추적합니다 (plt.gca()를 호출하여 해당 부분 그래프의 참조를 얻을 수 있습니다). 따라서, plot 함수를 호출할 때 활성화된 부분 그래프에 그림이 그려지게 됩니다.이제현 주 : object oriented API 방식에서는 그래프를 그리기 전에 먼저 틀을 잡아둡니다. 그래프를 그릴 때 사전에 정의된 영역 중 어디에 그래프를 그릴지 지정하는 방식입니다. pyplot의 plt.gca()가 바로 object oriented API의 axes입니다. . | . x = np.linspace(-1.4, 1.4, 30) # subplot(2,2,1)은 subplot(221)로 축약할 수 있습니다. plt.subplot(2, 2, 1) # 2 행 2 열 크기의 격자 중 첫 번째 부분 그래프 = 좌측 상단 plt.plot(x, x) plt.subplot(2, 2, 2) # 2 행 2 열 크기의 격자 중 두 번째 부분 그래프 = 우측 상단 plt.plot(x, x**2) plt.subplot(2, 2, 3) # 2 행 2 열 크기의 격자 중 세 번째 부분 그래프 = 좌측 하단 plt.plot(x, x**3) plt.subplot(2, 2, 4) # 2 행 2 열 크기의 격자 중 네 번째 부분 그래프 = 우측 하단 plt.plot(x, x**4) plt.show() . x = np.linspace(-1.4, 1.4, 30) fig, ax = plt.subplots(2, 2) # 순서대로 row의 갯수, col의 갯수입니다. nrows=2, cols=2로 지정할 수도 있습니다. # plot위치는 ax[row, col] 또는 ax[row][col]로 지정합니다. ax[0, 0].plot(x, x) # 2 행 2 열 크기의 격자 중 첫 번째 부분 그래프 = 좌측 상단 ax[0, 1].plot(x, x**2) # 2 행 2 열 크기의 격자 중 두 번째 부분 그래프 = 우측 상단 ax[1, 0].plot(x, x**3) # 2 행 2 열 크기의 격자 중 세 번째 부분 그래프 = 좌측 하단 ax[1, 1].plot(x, x**4) # 2 행 2 열 크기의 격자 중 네 번째 부분 그래프 = 우측 하단 plt.show() . 격자의 여러 영역으로 확장된 부분 그래프를 생성하는 것도 쉽습니다: . plt.subplot(2, 2, 1) # 2 행 2 열 크기의 격자 중 첫 번째 부분 그래프 = 좌측 상단 plt.plot(x, x) plt.subplot(2, 2, 2) # 2 행 2 열 크기의 격자 중 두 번째 부분 그래프 = 우측 상단 plt.plot(x, x**2) plt.subplot(2, 1, 2) # 2행 *1* 열의 두 번째 부분 그래프 = 하단 # 2행 1열 크기의 그래프가 두 개 그려질 수 있지만, # 상단 부분은 이미 두 개의 부분 그래프가 차지하였다. # 따라서, 두 번째 부분 그래프로 지정함 plt.plot(x, x**3) plt.show() . grid = plt.GridSpec(2, 2) # 2행 2열 크기의 격?자를 준비합니다. ax1 = plt.subplot(grid[0, 0]) # 2행 2열 크기의 격자 중 첫 번째 부분 그래프 = 좌측 상단 ax2 = plt.subplot(grid[0, 1]) # 2행 2열 크기의 격자 중 두 번째 부분 그래프 = 우측 상단 ax3 = plt.subplot(grid[1, 0:]) # 2행 *1*열의 두 번째 부분 그래프 = 하단 # 범위를 [1, 0:]으로 설정하여 2행 전체를 지정함. ax1.plot(x, x) ax2.plot(x, x**2) ax3.plot(x, x**3) plt.show() . 보다 복잡한 부분 그래프의 위치 선정이 필요하다면, subplot2grid를 대신 사용할 수 있습니다. 격자의 행과 열의 번호 및 격자에서 해당 부분 그래프를 그릴 위치를 지정해줄 수 있습니다 (좌측상단 = (0,0). 또한 몇 개의 행/열로 확장되어야 하는지도 추가적으로 지정할 수 있습니다. 아래는 그에 대한 예를 보여줍니다: . plt.subplot2grid((3,3), (0, 0), rowspan=2, colspan=2) plt.plot(x, x**2) plt.subplot2grid((3,3), (0, 2)) plt.plot(x, x**3) plt.subplot2grid((3,3), (1, 2), rowspan=2) plt.plot(x, x**4) plt.subplot2grid((3,3), (2, 0), colspan=2) plt.plot(x, x**5) plt.show() . gridsize = (3, 3) # 2행 2열 크기의 격자를 준비합니다. ax1 = plt.subplot2grid(gridsize, (0,0), rowspan=2, colspan=2) ax2 = plt.subplot2grid(gridsize, (0,2)) ax3 = plt.subplot2grid(gridsize, (1,2), rowspan=2) ax4 = plt.subplot2grid(gridsize, (2,0), colspan=2) ax1.plot(x, x**2) ax2.plot(x, x**3) ax3.plot(x, x**4) ax4.plot(x, x**5) plt.show() . 보다 유연한 부분그래프 위치선정이 필요하다면, GridSpec 문서를 확인해 보시길 바랍니다. . &#50668;&#47084;&#44060;&#51032; &#44536;&#47548; (figure) . 여러개의 그림을 그리는것도 가능합니다. 각 그림은 하나 이상의 부분 그래프를 가질 수 있습니다. 기본적으로는 matplotlib이 자동으로 figure(1)을 생성합니다. 그림간 전환을 할 때, pyplot은 현재 활성화된 그림을 계속해서 추적합니다 (이에대한 참조는 plt.gcf()의 호출로 알 수 있습니다). 또한 활성화된 그림의 활성화된 부분 그래프가 현재 그래프가 그려질 부분 그래프가 됩니다. . 이제현 주 : object oriented API에서는 실행 순이 아니라 객체를 중심으로 명령을 실행합니다. 다른 그림을 그리다가 앞서 그림을 추가할 때 pyplot에서 plt.figure() 명령으로 위 그림을 호출하는 대신 object oriented API는 목표 Axes를 지정하여 추가합니다. . import numpy as np . x = np.linspace(-1.4, 1.4, 30) plt.figure(1) plt.subplot(211) plt.plot(x, x**2) plt.title(&quot;Square and Cube&quot;) plt.subplot(212) plt.plot(x, x**3) plt.figure(2, figsize=(10, 5)) plt.subplot(121) plt.plot(x, x**4) plt.title(&quot;y = x**4&quot;) plt.subplot(122) plt.plot(x, x**5) plt.title(&quot;y = x**5&quot;) plt.figure(1) # 그림 1로 돌아가며, 활성화된 부분 그래프는 212 (하단)이 됩니다 plt.plot(x, -x**3, &quot;r:&quot;) plt.show() . x = np.linspace(-1.4, 1.4, 30) fig1, ax1 = plt.subplots(nrows=2, ncols=1) ax1[0].plot(x, x**2) ax1[0].set_title(&quot;Square and Cube&quot;) ax1[1].plot(x, x**3) fig2, ax2 = plt.subplots(nrows=1, ncols=2, figsize=(10, 5)) ax2[0].plot(x, x**4) ax2[0].set_title(&quot;y = x**4&quot;) ax2[1].plot(x, x**5) ax2[1].set_title(&quot;y = x**5&quot;) ax1[1].plot(x, -x**3, &quot;r:&quot;) # 그림 1로 돌아가며, 활성화된 부분 그래프는 ax1[1] (하단)이 됩니다. plt.show() . Pyplot&#51032; &#49345;&#53468; &#47672;&#49888;: &#50516;&#49884;&#51201; vs &#47749;&#49884;&#51201; . 지금까지 현재의 활성화된 부분 그래프를 추적하는 Pyplot의 상태 머신을 사용했었습니다. plot 함수를 호출할 때마다 pyplot은 단지 현재 활성화된 부분 그래프에 그림을 그립니다. 그리고 plot 함수를 호출 할 때, 그림 및 부분 그래프가 아직 존재하지 않는다면 이들을 만들어내는 마법같은(?) 작업도 일부 수행합니다. 이는 주피터와 같은 대화식의 환경에서 편리합니다. . 그러나 프로그램을 작성하는 것이라면, 명시적인 것이 암시적인것 보다 더 낫습니다. 명시적인 코드는 일반적으로 디버깅과 유지보수가 더 쉽습니다. 이 말에 동의하지 않는다면, Python 젠(Zen)의 두 번째 규칙을 읽어보시기 바랍니다. . import this . The Zen of Python, by Tim Peters Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. Complex is better than complicated. Flat is better than nested. Sparse is better than dense. Readability counts. Special cases aren&#39;t special enough to break the rules. Although practicality beats purity. Errors should never pass silently. Unless explicitly silenced. In the face of ambiguity, refuse the temptation to guess. There should be one-- and preferably only one --obvious way to do it. Although that way may not be obvious at first unless you&#39;re Dutch. Now is better than never. Although never is often better than *right* now. If the implementation is hard to explain, it&#39;s a bad idea. If the implementation is easy to explain, it may be a good idea. Namespaces are one honking great idea -- let&#39;s do more of those! . 아름다움이 추한 것보다 낫다. . 명확함이 함축된 것보다 낫다. . 단순함이 복잡한 것보다 낫다. . 복잡함이 난해한 것보다 낫다. . 단조로움이 중접된 것보다 낫다. . 여유로움이 밀집된 것보다 낫다. . 가독성은 중요하다. . 비록 실용성이 이상을 능가한다 하더라도 규칙을 깨야할 정도로 특별한 경우란 없다. . 알고도 침묵하지 않는 한 오류는 결코 조용히 지나가지 않는다. . 모호함을 마주하고 추측하려는 유혹을 거절하라. 비록 당신이 우둔해서 처음에는 명백해 보이지 않을 수도 있겠지만 문제를 해결할 하나의 - 바람직하고 유일한 - 명백한 방법이 있을 것이다. . 비록 하지않는 것이 지금 하는 것보다 나을 때도 있지만 지금 하는 것이 전혀 안하는 것보다 낫다. . 설명하기 어려운 구현이라면 좋은 아이디어가 아니다. 쉽게 설명할 수 있는 구현이라면 좋은 아이디어일 수 있다. 네임스페이스는 정말 대단한 아이디어다. -- 자주 사용하자! . from 출처 . 다행히도 Pyplot은 상태 머신을 완전히 무시할 수 있게끔 해 줍니다. 따라서 아름다운 명시적 코드를 작성하는것이 가능하죠. 간단히 subplots 함수를 호출해서 반환되는 figure 객체 및 축의 리스트를 사용하면 됩니다*. 마법은 더 이상 없습니다! . 이제현 주:* 여기서 설명하는 부분이 matplotlib의 object oriented API(객체지향 인터페이스)입니다. 아래는 이에 대한 예 입니다: . x = np.linspace(-2, 2, 200) fig1, (ax_top, ax_bottom) = plt.subplots(2, 1, sharex=True) fig1.set_size_inches(10,5) line1, line2 = ax_top.plot(x, np.sin(3*x**2), &quot;r-&quot;, x, np.cos(5*x**2), &quot;b-&quot;) # line1은 위에 파랑, line2는 위에 빨강 line3, = ax_bottom.plot(x, np.sin(3*x), &quot;r-&quot;) # line은 밑에 빨강 ax_top.grid(True) fig2, ax = plt.subplots(1, 1) ax.plot(x, x**2) plt.show() . 일관성을 위해서 이 튜토리얼의 나머지 부분에서는 pyplot의 상태 머신을 계속해서 사용할 것입니다. 그러나 프로그램에서는 객체지향 인터페이스의 사용을 권장하고 싶습니다. . Pylab vs Pyplot vs Matplotlib . pylab, pyplot, matplotlib 간의 관계에대한 혼동이 있습니다. 그러나 이들의 관계는 매우 단순합니다: matplotlib은 완전한 라이브러리이며, pylab 및 pyplot을 포함한 모든것을 가지고 있습니다. . Pyplot은 그래프를 그리기위한 다양한 도구를 제공합니다. 여기에는 내부적인 객체지향적인 그래프 그리기 라이브러리에 대한 상태 머신 인터페이스도 포함됩니다. . Pylab은 mkatplotlib.pyplot 및 NumPy를 단일 네임스페이스로 임포트하는 편리성을 위한 모듈입니다. 인터넷에 떠도는 pylab을 사용하는 여러 예제를 보게 될 것입니다. 그러나 이는 더이상 권장되는 사용방법은 아닙니다 (왜냐하면 명시적인 임포트가 암시적인것 보다 더 낫기 때문입니다). . 이제현 주 :* Pylab, Pyplot, Object oriented API의 관계는 여기를 참고하십시오 . &#53581;&#49828;&#53944; &#44536;&#47532;&#44592; . text 함수를 호출하여 텍스트를 그래프의 원하는 위치에 추가할 수 있습니다. 출력을 원하는 텍스트와 수평 및 수직 좌표를 지정하고, 추가적으로 몇 가지 속성을 지정해 주기만 하면 됩니다. matplotlib의 모든 텍스트는 TeX 방정식 표현을 포함할 수 있습니다. 더 자세한 내용은 공식 문서를 참조하시기 바랍니다. . x = np.linspace(-1.5, 1.5, 30) px = 0.8 py = px**2 plt.plot(x, x**2, &quot;b-&quot;, px, py, &quot;ro&quot;) plt.text(0, 1.5, &quot;Square function n$y = x^2$&quot;, fontsize=20, color=&#39;blue&#39;, horizontalalignment=&quot;center&quot;) plt.text(px - 0.08, py, &quot;Beautiful point&quot;, ha=&quot;right&quot;, weight=&quot;heavy&quot;) plt.text(px, py, &quot;x = %0.2f ny = %0.2f&quot;%(px, py), rotation=50, color=&#39;gray&#39;) plt.show() . fig, ax = plt.subplots() ax.plot(x, x**2, &quot;b-&quot;) ax.plot(px, py, &quot;ro&quot;) ax.text(0, 1.5, &quot;Square function n$y = x^2$&quot;, fontsize=20, color=&#39;blue&#39;, horizontalalignment=&quot;center&quot;) ax.text(px - 0.08, py, &quot;Beautiful point&quot;, ha=&quot;right&quot;, weight=&quot;heavy&quot;) ax.text(px, py, &quot;x = %0.2f ny = %0.2f&quot;%(px, py), rotation=50, color=&#39;gray&#39;) plt.show() . 알아둘 것: ha는 horizontalalignment(수평정렬)의 이명 입니다. | . 더 많은 텍스트 속성을 알고 싶다면, 공식 문서를 참조하시기 바랍니다. . 아래 그래프의 &quot;beautiful point&quot; 같은 텍스트 처럼, 그래프의 요소에 주석을 다는것은 꽤 흔한 일입니다. annotate 함수는 이를 쉽게 할 수 있게 해 줍니다: 관심있는 부분의 위치를 지정하고, 텍스트의 위치를 지정합니다. 그리고 텍스트 및 화살표에 대한 추가적인 속성도 지정해줄 수 있습니다. . plt.plot(x, x**2, px, py, &quot;ro&quot;) plt.annotate(&quot;Beautiful point&quot;, xy=(px, py), xytext=(px-1.3,py+0.5), color=&quot;green&quot;, weight=&quot;heavy&quot;, fontsize=14, arrowprops={&quot;facecolor&quot;: &quot;lightgreen&quot;}) plt.show() . fig, ax = plt.subplots() ax.plot(x, x**2, px, py, &quot;ro&quot;) ax.annotate(&quot;Beautiful point&quot;, xy=(px, py), xytext=(px-1.3,py+0.5), color=&quot;green&quot;, weight=&quot;heavy&quot;, fontsize=14, arrowprops={&quot;facecolor&quot;: &quot;lightgreen&quot;}) plt.show() . bbox 속성을 사용하면, 텍스트를 포함하는 사각형을 그려볼 수도 있습니다: . plt.plot(x, x**2, px, py, &quot;ro&quot;) bbox_props = dict(boxstyle=&quot;rarrow,pad=0.3&quot;, ec=&quot;b&quot;, lw=2, fc=&quot;lightblue&quot;) plt.text(px-0.2, py, &quot;Beautiful point&quot;, bbox=bbox_props, ha=&quot;right&quot;) bbox_props = dict(boxstyle=&quot;round4,pad=1,rounding_size=0.2&quot;, ec=&quot;black&quot;, fc=&quot;#EEEEFF&quot;, lw=5) plt.text(0, 1.5, &quot;Square function n$y = x^2$&quot;, fontsize=20, color=&#39;black&#39;, ha=&quot;center&quot;, bbox=bbox_props) plt.show() . fig, ax = plt.subplots() ax.plot(x, x**2) ax.plot(px, py, &quot;ro&quot;) bbox_props = dict(boxstyle=&quot;rarrow,pad=0.3&quot;, ec=&quot;b&quot;, lw=2, fc=&quot;lightblue&quot;) ax.text(px-0.2, py, &quot;Beautiful point&quot;, bbox=bbox_props, ha=&quot;right&quot;) bbox_props = dict(boxstyle=&quot;round4,pad=1,rounding_size=0.2&quot;, ec=&quot;black&quot;, fc=&quot;#EEEEFF&quot;, lw=5) ax.text(0, 1.5, &quot;Square function n$y = x^2$&quot;, fontsize=20, color=&#39;black&#39;, ha=&quot;center&quot;, bbox=bbox_props) plt.show() . 재미를 위해서 xkcd 스타일의 그래프를 그려보고 싶다면, with plt.xkcd() 섹션 블록을 활용할 수도 있습니다: . with plt.xkcd(): plt.plot(x, x**2, px, py, &quot;ro&quot;) bbox_props = dict(boxstyle=&quot;rarrow,pad=0.3&quot;, ec=&quot;b&quot;, lw=2, fc=&quot;lightblue&quot;) plt.text(px-0.2, py, &quot;Beautiful point&quot;, bbox=bbox_props, ha=&quot;right&quot;) bbox_props = dict(boxstyle=&quot;round4,pad=1,rounding_size=0.2&quot;, ec=&quot;black&quot;, fc=&quot;#EEEEFF&quot;, lw=5) plt.text(0, 1.5, &quot;Square function n$y = x^2$&quot;, fontsize=20, color=&#39;black&#39;, ha=&quot;center&quot;, bbox=bbox_props) plt.show() . &#48276;&#47168; (Legends) . 범례를 추가하는 가장 간단한 방법은 모든 선에 라벨을 설정 해 주고, legend 함수를 호출하는 것입니다. . x = np.linspace(-1.4, 1.4, 50) plt.plot(x, x**2, &quot;r--&quot;, label=&quot;Square function&quot;) plt.plot(x, x**3, &quot;g-&quot;, label=&quot;Cube function&quot;) plt.legend(loc=&quot;best&quot;) plt.grid(True) plt.show() . x = np.linspace(-1.4, 1.4, 50) fig, ax = plt.subplots() ax.plot(x, x**2, &quot;r--&quot;, label=&quot;Square function&quot;) ax.plot(x, x**3, &quot;g-&quot;, label=&quot;Cube function&quot;) ax.legend(loc=&quot;best&quot;) ax.grid(True) plt.show() . &#48708;&#49440;&#54805; &#52377;&#46020; . Matplotlib은 로그, 로짓(logit)과 같은 비선형 척도를 지원합니다. . x = np.linspace(0.1, 15, 500) y = x**3/np.exp(2*x) plt.figure(1) plt.plot(x, y) plt.yscale(&#39;linear&#39;) plt.title(&#39;linear&#39;) plt.grid(True) plt.figure(2) plt.plot(x, y) plt.yscale(&#39;log&#39;) plt.title(&#39;log&#39;) plt.grid(True) plt.figure(3) plt.plot(x, y) plt.yscale(&#39;logit&#39;) plt.title(&#39;logit&#39;) plt.grid(True) plt.figure(4) plt.plot(x, y - y.mean()) plt.yscale(&#39;symlog&#39;, linthreshy=0.05) plt.title(&#39;symlog&#39;) plt.grid(True) plt.show() . TypeError Traceback (most recent call last) c: Users user Desktop VS_C data_mining notebook Tools_matplotlib_(박찬성_번역_이제현_OO_API_추가).ipynb Cell 78&#39; in &lt;cell line: 26&gt;() &lt;a href=&#39;vscode-notebook-cell:/c%3A/Users/user/Desktop/VS_C/data_mining/notebook/Tools_matplotlib_%28%EB%B0%95%EC%B0%AC%EC%84%B1_%EB%B2%88%EC%97%AD_%EC%9D%B4%EC%A0%9C%ED%98%84_OO_API_%EC%B6%94%EA%B0%80%29.ipynb#ch0000076?line=23&#39;&gt;24&lt;/a&gt; plt.figure(4) &lt;a href=&#39;vscode-notebook-cell:/c%3A/Users/user/Desktop/VS_C/data_mining/notebook/Tools_matplotlib_%28%EB%B0%95%EC%B0%AC%EC%84%B1_%EB%B2%88%EC%97%AD_%EC%9D%B4%EC%A0%9C%ED%98%84_OO_API_%EC%B6%94%EA%B0%80%29.ipynb#ch0000076?line=24&#39;&gt;25&lt;/a&gt; plt.plot(x, y - y.mean()) &gt; &lt;a href=&#39;vscode-notebook-cell:/c%3A/Users/user/Desktop/VS_C/data_mining/notebook/Tools_matplotlib_%28%EB%B0%95%EC%B0%AC%EC%84%B1_%EB%B2%88%EC%97%AD_%EC%9D%B4%EC%A0%9C%ED%98%84_OO_API_%EC%B6%94%EA%B0%80%29.ipynb#ch0000076?line=25&#39;&gt;26&lt;/a&gt; plt.yscale(&#39;symlog&#39;, linthreshy=0.05) &lt;a href=&#39;vscode-notebook-cell:/c%3A/Users/user/Desktop/VS_C/data_mining/notebook/Tools_matplotlib_%28%EB%B0%95%EC%B0%AC%EC%84%B1_%EB%B2%88%EC%97%AD_%EC%9D%B4%EC%A0%9C%ED%98%84_OO_API_%EC%B6%94%EA%B0%80%29.ipynb#ch0000076?line=26&#39;&gt;27&lt;/a&gt; plt.title(&#39;symlog&#39;) &lt;a href=&#39;vscode-notebook-cell:/c%3A/Users/user/Desktop/VS_C/data_mining/notebook/Tools_matplotlib_%28%EB%B0%95%EC%B0%AC%EC%84%B1_%EB%B2%88%EC%97%AD_%EC%9D%B4%EC%A0%9C%ED%98%84_OO_API_%EC%B6%94%EA%B0%80%29.ipynb#ch0000076?line=27&#39;&gt;28&lt;/a&gt; plt.grid(True) File ~ AppData Local Programs Python Python310 lib site-packages matplotlib pyplot.py:3055, in yscale(value, **kwargs) &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/pyplot.py?line=3052&#39;&gt;3053&lt;/a&gt; @_copy_docstring_and_deprecators(Axes.set_yscale) &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/pyplot.py?line=3053&#39;&gt;3054&lt;/a&gt; def yscale(value, **kwargs): -&gt; &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/pyplot.py?line=3054&#39;&gt;3055&lt;/a&gt; return gca().set_yscale(value, **kwargs) File ~ AppData Local Programs Python Python310 lib site-packages matplotlib axes _base.py:4108, in _AxesBase.set_yscale(self, value, **kwargs) &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axes/_base.py?line=4105&#39;&gt;4106&lt;/a&gt; g = self.get_shared_y_axes() &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axes/_base.py?line=4106&#39;&gt;4107&lt;/a&gt; for ax in g.get_siblings(self): -&gt; &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axes/_base.py?line=4107&#39;&gt;4108&lt;/a&gt; ax.yaxis._set_scale(value, **kwargs) &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axes/_base.py?line=4108&#39;&gt;4109&lt;/a&gt; ax._update_transScale() &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axes/_base.py?line=4109&#39;&gt;4110&lt;/a&gt; ax.stale = True File ~ AppData Local Programs Python Python310 lib site-packages matplotlib axis.py:761, in Axis._set_scale(self, value, **kwargs) &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axis.py?line=758&#39;&gt;759&lt;/a&gt; def _set_scale(self, value, **kwargs): &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axis.py?line=759&#39;&gt;760&lt;/a&gt; if not isinstance(value, mscale.ScaleBase): --&gt; &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axis.py?line=760&#39;&gt;761&lt;/a&gt; self._scale = mscale.scale_factory(value, self, **kwargs) &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axis.py?line=761&#39;&gt;762&lt;/a&gt; else: &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axis.py?line=762&#39;&gt;763&lt;/a&gt; self._scale = value File ~ AppData Local Programs Python Python310 lib site-packages matplotlib scale.py:597, in scale_factory(scale, axis, **kwargs) &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/scale.py?line=594&#39;&gt;595&lt;/a&gt; scale = scale.lower() &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/scale.py?line=595&#39;&gt;596&lt;/a&gt; scale_cls = _api.check_getitem(_scale_mapping, scale=scale) --&gt; &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/scale.py?line=596&#39;&gt;597&lt;/a&gt; return scale_cls(axis, **kwargs) TypeError: SymmetricalLogScale.__init__() got an unexpected keyword argument &#39;linthreshy&#39; . x = np.linspace(0.1, 15, 500) y = x**3/np.exp(2*x) fig1, ax1 = plt.subplots() ax1.plot(x, y) ax1.set_yscale(&#39;linear&#39;) ax1.set_title(&#39;linear&#39;) ax1.grid(True) fig2, ax2 = plt.subplots() ax2.plot(x, y) ax2.set_yscale(&#39;log&#39;) ax2.set_title(&#39;log&#39;) ax2.grid(True) fig3, ax3 = plt.subplots() ax3.plot(x, y) ax3.set_yscale(&#39;logit&#39;) ax3.set_title(&#39;logit&#39;) ax3.grid(True) fig4, ax4 = plt.subplots() ax4.plot(x, y - y.mean()) ax4.set_yscale(&#39;symlog&#39;, linthreshy=0.05) ax4.set_title(&#39;symlog&#39;) ax4.grid(True) plt.show() . TypeError Traceback (most recent call last) c: Users user Desktop VS_C data_mining notebook Tools_matplotlib_(박찬성_번역_이제현_OO_API_추가).ipynb Cell 79&#39; in &lt;cell line: 26&gt;() &lt;a href=&#39;vscode-notebook-cell:/c%3A/Users/user/Desktop/VS_C/data_mining/notebook/Tools_matplotlib_%28%EB%B0%95%EC%B0%AC%EC%84%B1_%EB%B2%88%EC%97%AD_%EC%9D%B4%EC%A0%9C%ED%98%84_OO_API_%EC%B6%94%EA%B0%80%29.ipynb#ch0000077?line=23&#39;&gt;24&lt;/a&gt; fig4, ax4 = plt.subplots() &lt;a href=&#39;vscode-notebook-cell:/c%3A/Users/user/Desktop/VS_C/data_mining/notebook/Tools_matplotlib_%28%EB%B0%95%EC%B0%AC%EC%84%B1_%EB%B2%88%EC%97%AD_%EC%9D%B4%EC%A0%9C%ED%98%84_OO_API_%EC%B6%94%EA%B0%80%29.ipynb#ch0000077?line=24&#39;&gt;25&lt;/a&gt; ax4.plot(x, y - y.mean()) &gt; &lt;a href=&#39;vscode-notebook-cell:/c%3A/Users/user/Desktop/VS_C/data_mining/notebook/Tools_matplotlib_%28%EB%B0%95%EC%B0%AC%EC%84%B1_%EB%B2%88%EC%97%AD_%EC%9D%B4%EC%A0%9C%ED%98%84_OO_API_%EC%B6%94%EA%B0%80%29.ipynb#ch0000077?line=25&#39;&gt;26&lt;/a&gt; ax4.set_yscale(&#39;symlog&#39;, linthreshy=0.05) &lt;a href=&#39;vscode-notebook-cell:/c%3A/Users/user/Desktop/VS_C/data_mining/notebook/Tools_matplotlib_%28%EB%B0%95%EC%B0%AC%EC%84%B1_%EB%B2%88%EC%97%AD_%EC%9D%B4%EC%A0%9C%ED%98%84_OO_API_%EC%B6%94%EA%B0%80%29.ipynb#ch0000077?line=26&#39;&gt;27&lt;/a&gt; ax4.set_title(&#39;symlog&#39;) &lt;a href=&#39;vscode-notebook-cell:/c%3A/Users/user/Desktop/VS_C/data_mining/notebook/Tools_matplotlib_%28%EB%B0%95%EC%B0%AC%EC%84%B1_%EB%B2%88%EC%97%AD_%EC%9D%B4%EC%A0%9C%ED%98%84_OO_API_%EC%B6%94%EA%B0%80%29.ipynb#ch0000077?line=27&#39;&gt;28&lt;/a&gt; ax4.grid(True) File ~ AppData Local Programs Python Python310 lib site-packages matplotlib axes _base.py:4108, in _AxesBase.set_yscale(self, value, **kwargs) &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axes/_base.py?line=4105&#39;&gt;4106&lt;/a&gt; g = self.get_shared_y_axes() &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axes/_base.py?line=4106&#39;&gt;4107&lt;/a&gt; for ax in g.get_siblings(self): -&gt; &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axes/_base.py?line=4107&#39;&gt;4108&lt;/a&gt; ax.yaxis._set_scale(value, **kwargs) &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axes/_base.py?line=4108&#39;&gt;4109&lt;/a&gt; ax._update_transScale() &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axes/_base.py?line=4109&#39;&gt;4110&lt;/a&gt; ax.stale = True File ~ AppData Local Programs Python Python310 lib site-packages matplotlib axis.py:761, in Axis._set_scale(self, value, **kwargs) &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axis.py?line=758&#39;&gt;759&lt;/a&gt; def _set_scale(self, value, **kwargs): &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axis.py?line=759&#39;&gt;760&lt;/a&gt; if not isinstance(value, mscale.ScaleBase): --&gt; &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axis.py?line=760&#39;&gt;761&lt;/a&gt; self._scale = mscale.scale_factory(value, self, **kwargs) &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axis.py?line=761&#39;&gt;762&lt;/a&gt; else: &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/axis.py?line=762&#39;&gt;763&lt;/a&gt; self._scale = value File ~ AppData Local Programs Python Python310 lib site-packages matplotlib scale.py:597, in scale_factory(scale, axis, **kwargs) &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/scale.py?line=594&#39;&gt;595&lt;/a&gt; scale = scale.lower() &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/scale.py?line=595&#39;&gt;596&lt;/a&gt; scale_cls = _api.check_getitem(_scale_mapping, scale=scale) --&gt; &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/scale.py?line=596&#39;&gt;597&lt;/a&gt; return scale_cls(axis, **kwargs) TypeError: SymmetricalLogScale.__init__() got an unexpected keyword argument &#39;linthreshy&#39; . &#54001;&#44284; &#54001;&#52964; (Ticks and tickers) . 각 축에는 &quot;틱(ticks)&quot;이라는 작은 표시가 있습니다. 정확히 말하자면, &quot;틱&quot;은 표시(예. (-1, 0, 1))의 위치&quot;이며, 틱 선은 그 위치에 그려지는 작은 선입니다. 또한 &quot;틱 라벨&quot;은 틱 선 옆에 그려지는 라벨이며, &quot;틱커&quot;는 틱의 위치를 결정하는 객체 입니다. 기본적인 틱커는 ~5 에서 8 틱을 위치시키는데 꽤 잘 작동합니다. 즉, 틱 서로간에 적당한 거리를 표현합니다. . 하지만, 가끔은 좀 더 이를 제어할 필요가 있습니다 (예. 위의 로짓 그래프에서는 너무 많은 틱 라벨이 있습니다). 다행히도 matplotlib은 틱을 완전히 제어하는 방법을 제공합니다. 심지어 보조 눈금(minor tick)을 활성화 할 수도 있습니다. . # 이제현 주: 사실상 object oriented API 입니다. x = np.linspace(-2, 2, 100) plt.figure(1, figsize=(15,10)) plt.subplot(131) plt.plot(x, x**3) plt.grid(True) plt.title(&quot;Default ticks&quot;) ax = plt.subplot(132) plt.plot(x, x**3) ax.xaxis.set_ticks(np.arange(-2, 2, 1)) plt.grid(True) plt.title(&quot;Manual ticks on the x-axis&quot;) ax = plt.subplot(133) plt.plot(x, x**3) plt.minorticks_on() ax.tick_params(axis=&#39;x&#39;, which=&#39;minor&#39;, bottom=&#39;off&#39;) ax.xaxis.set_ticks([-2, 0, 1, 2]) ax.yaxis.set_ticks(np.arange(-5, 5, 1)) ax.yaxis.set_ticklabels([&quot;min&quot;, -4, -3, -2, -1, 0, 1, 2, 3, &quot;max&quot;]) plt.title(&quot;Manual ticks and tick labels n(plus minor ticks) on the y-axis&quot;) plt.grid(True) plt.show() . # 위 pyplot 예제는 사실상 object oriented API 입니다. # 여기에서는 같은 기능을 더 단순한 코드로 구현하였습니다 x = np.linspace(-2, 2, 100) fig, ax = plt.subplots(ncols=3, figsize=(15, 10)) ax[0].plot(x, x**3) ax[0].grid(True) ax[0].set_title(&quot;Default ticks&quot;) ax[1].plot(x, x**3) ax[1].grid(True) ax[1].set_xticks(np.arange(-2, 2, 1)) ax[1].set_title(&quot;Manual ticks on the x-axis&quot;) ax[2].plot(x, x**3) ax[2].grid(True) ax[2].minorticks_on() ax[2].set_xticks([-2, 0, 1, 2], minor=False) ax[2].set_yticks(np.arange(-5, 5, 1)) ax[2].set_yticklabels([&quot;min&quot;, -4, -3, -2, -1, 0, 1, 2, 3, &quot;max&quot;]) ax[2].set_title(&quot;Manual ticks and tick labels n(plus minor ticks) on the y-axis&quot;) plt.show() . &#44537;&#51340;&#54364;&#44228;&#51032; &#53804;&#50689; (Polar projection) . 극좌표계 그래프를 그리는 것은 매우 간단합니다. 부분 그래프를 생성할 때 projection 속성을 &quot;polar&quot;로 설정해 주기만 하면 됩니다. . 이제현 주: object oriented API는 일반적으로 plt.subplots()로 Figure와 Axes 객체를 동시에 생성합니다. plt.subplots()는 projection 속성을 가지고 있지 않습니다. . 따라서 projection을 사용할 때는 plt.figure()로 Figure 객체를 먼저 생성한 후 plt.subplot()이나 plt.add_subplot()으로 Axes 객체를 추가해 주거나, fig.subplots() 안에 subplot_kw=={&#39;polar&#39;:True}로 지정해 주어야 합니다. | . radius = 1 theta = np.linspace(0, 2*np.pi*radius, 1000) plt.subplot(111, projection=&#39;polar&#39;) plt.plot(theta, np.sin(5*theta), &quot;g-&quot;) plt.plot(theta, 0.5*np.cos(20*theta), &quot;b-&quot;) plt.show() . radius = 1 theta = np.linspace(0, 2*np.pi*radius, 1000) fig = plt.figure() ax = fig.add_subplot(projection=&#39;polar&#39;) # 또는, subplot_kw 를 이용해서 polar plot으로 설정합니다. # fig, ax = plt.subplots(subplot_kw={&#39;polar&#39;:True}) ax.plot(theta, np.sin(5*theta), &quot;g-&quot;) ax.plot(theta, 0.5*np.cos(20*theta), &quot;b-&quot;) plt.show() . 3&#52264;&#50896; &#53804;&#50689; . 3차원 그래프를 그리는것은 꽤 간단합니다. 우선 &quot;3d&quot; 투영을 등록하는 Axes3D를 임포트 해줘야 합니다. 그리곤 projection 속성을 &quot;3d&quot;로 설정된 부분 그래프 생성합니다. 그러면 Axes3DSubplot 이라는 객체가 반환되는데, 이 객체의 plot_surface 메서드를 호출하면 x, y, z 좌표를 포함한 추가적이나 속성을 지정할 수 있습니다. . # 이제현 주: 사실상 object oriented API 입니다. from mpl_toolkits.mplot3d import Axes3D x = np.linspace(-5, 5, 50) y = np.linspace(-5, 5, 50) X, Y = np.meshgrid(x, y) R = np.sqrt(X**2 + Y**2) Z = np.sin(R) figure = plt.figure(1, figsize = (12, 4)) subplot3d = plt.subplot(111, projection=&#39;3d&#39;) # 이제현 주: Axes 객체입니다. surface = subplot3d.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=matplotlib.cm.coolwarm, linewidth=0.1) plt.show() . 동일한 데이터를 출력하는 또 다른 방법은 등고선도(contour plot)를 이용하는 것입니다. . plt.contourf(X, Y, Z, cmap=matplotlib.cm.coolwarm) plt.colorbar() plt.show() . # 이제현 주: 종종 object oriented API가 pyplot보다 불편할 때가 있습니다. # contour plot의 colorbar는 무엇을 대상으로 할 지를 인자로 전달해야 합니다. fig, ax = plt.subplots() contour = ax.contourf(X, Y, Z, cmap=matplotlib.cm.coolwarm) plt.colorbar(contour) plt.show() . &#49328;&#51216;&#46020;(Scatter plot) . 단순히 각 점에 대한 x 및 y 좌표를 제공하면 산점도를 그릴 수 있습니다. . from numpy.random import rand x, y = rand(2, 100) plt.scatter(x, y) plt.show() . from numpy.random import rand x, y = rand(2, 100) fig, ax = plt.subplots() ax.scatter(x, y) plt.show() . 부수적으로 각 점의 크기를 정할 수도 있습니다. . x, y, scale = rand(3, 100) scale = 500 * scale ** 5 plt.scatter(x, y, s=scale) plt.show() . x, y, scale = rand(3, 100) scale = 500 * scale ** 5 fig, ax = plt.subplots() ax.scatter(x, y, s=scale) plt.show() . 마찬가지로 여러 속성을 설정할 수 있습니다. 가령 테두리 및 모양의 내부 색상, 그리고 투명도와 같은것의 설정이 가능합니다. . for color in [&#39;red&#39;, &#39;green&#39;, &#39;blue&#39;]: # for문이 3번 돌아가니까 점이 300개 있다. n = 100 x, y = rand(2, n) scale = 500.0 * rand(n) ** 5 plt.scatter(x, y, s=scale, c=color, alpha=0.3, edgecolors=&#39;blue&#39;) plt.grid(True) plt.show() . fig, ax = plt.subplots() for color in [&#39;red&#39;, &#39;green&#39;, &#39;blue&#39;]: n = 100 x, y = rand(2, n) scale = 500.0 * rand(n) ** 5 ax.scatter(x, y, s=scale, c=color, alpha=0.3, edgecolors=&#39;blue&#39;) ax.grid(True) plt.show() . &#49440; . 지금까지 해온것 처럼 plot 함수를 사용하여 선을 그릴 수 있습니다. 하지만, 가끔은 그래프를 통과하는 무한한 선을 그리는 유틸리티 함수를 만들면 편리합니다 (기울기와 절편으로). 또한 hlines 및 vlines 함수를 사용하면, 아래와 같이 부분 수평 및 수직 선을 그릴 수도 있습니다: . from numpy.random import randn def plot_line(axis, slope, intercept, **kargs): xmin, xmax = axis.get_xlim() plt.plot([xmin, xmax], [xmin*slope+intercept, xmax*slope+intercept], **kargs) x = randn(1000) y = 0.5*x + 5 + randn(1000)*2 plt.axis([-2.5, 2.5, -5, 15]) plt.scatter(x, y, alpha=0.2) plt.plot(1, 0, &quot;ro&quot;) plt.vlines(1, -5, 0, color=&quot;red&quot;) plt.hlines(0, -2.5, 1, color=&quot;red&quot;) plot_line(axis=plt.gca(), slope=0.5, intercept=5, color=&quot;magenta&quot;) plt.grid(True) plt.show() . from numpy.random import randn # Axis를 인자로 전달하여 함수 연산과 시각화를 수행합니다. def plot_line(axis, slope, intercept, **kargs): xmin, xmax = axis.get_xlim() axis.plot([xmin, xmax], [xmin*slope+intercept, xmax*slope+intercept], **kargs) x = randn(1000) y = 0.5*x + 5 + randn(1000)*2 fig, ax = plt.subplots() ax.set_xlim(-2.5, 2.5) ax.set_ylim(-5, 15) ax.scatter(x, y, alpha=0.2) ax.plot(1, 0, &quot;ro&quot;) ax.vlines(1, -5, 0, color=&quot;red&quot;) ax.hlines(0, -2.5, 1, color=&quot;red&quot;) plot_line(axis=ax, slope=0.5, intercept=5, color=&quot;magenta&quot;) ax.grid(True) plt.show() . &#55176;&#49828;&#53664;&#44536;&#47016; . data = [1, 1.1, 1.8, 2, 2.1, 3.2, 3, 3, 3, 3] plt.subplot(211) plt.hist(data, bins = 10, rwidth=0.8) plt.subplot(212) plt.hist(data, bins = [1, 1.5, 2, 2.5, 3], rwidth=0.95) plt.xlabel(&quot;Value&quot;) plt.ylabel(&quot;Frequency&quot;) plt.show() . data = [1, 1.1, 1.8, 2, 2.1, 3.2, 3, 3, 3, 3] fig, ax = plt.subplots(2, 1) ax[0].hist(data, bins = 10, rwidth=0.8) ax[1].hist(data, bins = [1, 1.5, 2, 2.5, 3], rwidth=0.95) ax[1].set_xlabel(&quot;Value&quot;) ax[1].set_ylabel(&quot;Frequency&quot;) plt.show() . data1 = np.random.randn(400) data2 = np.random.randn(500) + 3 data3 = np.random.randn(450) + 6 data4a = np.random.randn(200) + 9 data4b = np.random.randn(100) + 10 plt.hist(data1, bins=5, color=&#39;g&#39;, alpha=0.75, label=&#39;bar hist&#39;) # default histtype=&#39;bar&#39; plt.hist(data2, color=&#39;b&#39;, alpha=0.65, histtype=&#39;stepfilled&#39;, label=&#39;stepfilled hist&#39;) plt.hist(data3, color=&#39;r&#39;, histtype=&#39;step&#39;, label=&#39;step hist&#39;) plt.hist((data4a, data4b), color=(&#39;r&#39;,&#39;m&#39;), alpha=0.55, histtype=&#39;barstacked&#39;, label=(&#39;barstacked a&#39;, &#39;barstacked b&#39;)) plt.xlabel(&quot;Value&quot;) plt.ylabel(&quot;Frequency&quot;) plt.legend() plt.grid(True) plt.show() . data1 = np.random.randn(400) data2 = np.random.randn(500) + 3 data3 = np.random.randn(450) + 6 data4a = np.random.randn(200) + 9 data4b = np.random.randn(100) + 10 fig, ax = plt.subplots() ax.hist(data1, bins=5, color=&#39;g&#39;, alpha=0.75, label=&#39;bar hist&#39;) # default histtype=&#39;bar&#39; ax.hist(data2, color=&#39;b&#39;, alpha=0.65, histtype=&#39;stepfilled&#39;, label=&#39;stepfilled hist&#39;) ax.hist(data3, color=&#39;r&#39;, histtype=&#39;step&#39;, label=&#39;step hist&#39;) ax.hist((data4a, data4b), color=(&#39;r&#39;,&#39;m&#39;), alpha=0.55, histtype=&#39;barstacked&#39;, label=(&#39;barstacked a&#39;, &#39;barstacked b&#39;)) ax.set_xlabel(&quot;Value&quot;) ax.set_ylabel(&quot;Frequency&quot;) ax.legend() ax.grid(True) plt.show() . &#51060;&#48120;&#51648; . matplotlib에서의 이미지 불러오기, 생성하기, 화면에 그리기는 꽤 간단합니다. . 이미지를 불러오려면 matplotlib.image 모듈을 임포트하고, 파일이름을 지정한 imread 함수를 호출해 주면 됩니다. 그러면 이미지 데이터가 NumPy의 배열로서 반환됩니다. 앞서 저장했던 my_square_function.png 이미지에 대하여 이를 수행해 보겠습니다. . 이제현 주 : 이미지 단독 출력은 pyplot과 object oriented API 사이에 별 차이가 없습니다. Axes를 지정해서 출력하는 것이 다를 뿐입니다. . pyplot과의 중복성이 강하지만 익숙해지는 차원에서 object oriented API를 함께 도시합니다. | . import matplotlib.image as mpimg img = mpimg.imread(&#39;my_square_function.png&#39;) print(img.shape, img.dtype) . FileNotFoundError Traceback (most recent call last) c: Users user Desktop VS_C data_mining notebook Tools_matplotlib_(박찬성_번역_이제현_OO_API_추가).ipynb Cell 110&#39; in &lt;cell line: 3&gt;() &lt;a href=&#39;vscode-notebook-cell:/c%3A/Users/user/Desktop/VS_C/data_mining/notebook/Tools_matplotlib_%28%EB%B0%95%EC%B0%AC%EC%84%B1_%EB%B2%88%EC%97%AD_%EC%9D%B4%EC%A0%9C%ED%98%84_OO_API_%EC%B6%94%EA%B0%80%29.ipynb#ch0000108?line=0&#39;&gt;1&lt;/a&gt; import matplotlib.image as mpimg -&gt; &lt;a href=&#39;vscode-notebook-cell:/c%3A/Users/user/Desktop/VS_C/data_mining/notebook/Tools_matplotlib_%28%EB%B0%95%EC%B0%AC%EC%84%B1_%EB%B2%88%EC%97%AD_%EC%9D%B4%EC%A0%9C%ED%98%84_OO_API_%EC%B6%94%EA%B0%80%29.ipynb#ch0000108?line=2&#39;&gt;3&lt;/a&gt; img = mpimg.imread(&#39;my_square_function.png&#39;) &lt;a href=&#39;vscode-notebook-cell:/c%3A/Users/user/Desktop/VS_C/data_mining/notebook/Tools_matplotlib_%28%EB%B0%95%EC%B0%AC%EC%84%B1_%EB%B2%88%EC%97%AD_%EC%9D%B4%EC%A0%9C%ED%98%84_OO_API_%EC%B6%94%EA%B0%80%29.ipynb#ch0000108?line=3&#39;&gt;4&lt;/a&gt; print(img.shape, img.dtype) File ~ AppData Local Programs Python Python310 lib site-packages matplotlib image.py:1560, in imread(fname, format) &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/image.py?line=1557&#39;&gt;1558&lt;/a&gt; response = io.BytesIO(response.read()) &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/image.py?line=1558&#39;&gt;1559&lt;/a&gt; return imread(response, format=ext) -&gt; &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/image.py?line=1559&#39;&gt;1560&lt;/a&gt; with img_open(fname) as image: &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/image.py?line=1560&#39;&gt;1561&lt;/a&gt; return (_pil_png_to_float_array(image) &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/image.py?line=1561&#39;&gt;1562&lt;/a&gt; if isinstance(image, PIL.PngImagePlugin.PngImageFile) else &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/matplotlib/image.py?line=1562&#39;&gt;1563&lt;/a&gt; pil_to_array(image)) File ~ AppData Local Programs Python Python310 lib site-packages PIL ImageFile.py:100, in ImageFile.__init__(self, fp, filename) &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/PIL/ImageFile.py?line=95&#39;&gt;96&lt;/a&gt; self.decodermaxblock = MAXBLOCK &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/PIL/ImageFile.py?line=97&#39;&gt;98&lt;/a&gt; if isPath(fp): &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/PIL/ImageFile.py?line=98&#39;&gt;99&lt;/a&gt; # filename --&gt; &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/PIL/ImageFile.py?line=99&#39;&gt;100&lt;/a&gt; self.fp = open(fp, &#34;rb&#34;) &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/PIL/ImageFile.py?line=100&#39;&gt;101&lt;/a&gt; self.filename = fp &lt;a href=&#39;file:///c%3A/Users/user/AppData/Local/Programs/Python/Python310/lib/site-packages/PIL/ImageFile.py?line=101&#39;&gt;102&lt;/a&gt; self._exclusive_fp = True FileNotFoundError: [Errno 2] No such file or directory: &#39;my_square_function.png&#39; . 288x432 크기의 이미지를 불러왔습니다. 각 픽셀은 0~1 사이의 32비트 부동소수 값인 4개의 요소(빨강, 초록, 파랑, 투명도)로 구성된 배열로 표현됩니다. 이번에는 imshow함수를 호출해 보겠습니다: . plt.imshow(img) plt.show() . fig, ax = plt.subplots() ax.imshow(img) plt.show() . 허허허... 이미지 출력에 포함된 축을 숨기고 싶다면 아래와 같이 축을 off 시켜줄 수 있습니다: . plt.imshow(img) plt.axis(&#39;off&#39;) plt.show() . fig, ax = plt.subplots() ax.imshow(img) ax.axis(&#39;off&#39;) plt.show() . 여러분만의 이미지를 생성하는것도 마찬가지로 간단합니다: . img = np.arange(100*100).reshape(100, 100) print(img) plt.imshow(img) plt.show() . [[ 0 1 2 ... 97 98 99] [ 100 101 102 ... 197 198 199] [ 200 201 202 ... 297 298 299] ... [9700 9701 9702 ... 9797 9798 9799] [9800 9801 9802 ... 9897 9898 9899] [9900 9901 9902 ... 9997 9998 9999]] . img = np.arange(100*100).reshape(100, 100) print(img) fig, ax = plt.subplots() ax.imshow(img) plt.show() . [[ 0 1 2 ... 97 98 99] [ 100 101 102 ... 197 198 199] [ 200 201 202 ... 297 298 299] ... [9700 9701 9702 ... 9797 9798 9799] [9800 9801 9802 ... 9897 9898 9899] [9900 9901 9902 ... 9997 9998 9999]] . RGB 수준을 제공하지 않는다면, imshow 함수는 자동으로 값을 색그래디언트에 매핑합니다. 기본적인 동작에서의 색그래디언트는 파랑(낮은 값) 에서 빨강(높은 값)으로 움직입니다. 하지만 아래와 같이 다른 색상맵을 선택할 수도 있습니다: . plt.imshow(img, cmap=&quot;hot&quot;) plt.show() . fig, ax = plt.subplots() ax.imshow(img, cmap=&quot;hot&quot;) plt.show() . RGB 이미지를 직접적으로 생성하는것 또한 가능합니다: . img = np.empty((20,30,3)) img[:, :10] = [0, 0, 0.6] img[:, 10:20] = [1, 1, 1] img[:, 20:] = [0.6, 0, 0] plt.imshow(img, interpolation=&#39;bilinear&#39;) plt.show() . img = np.empty((20,30,3)) img[:, :10] = [0, 0, 0.6] img[:, 10:20] = [1, 1, 1] img[:, 20:] = [0.6, 0, 0] fig, ax = plt.subplots() ax.imshow(img, interpolation=&#39;bilinear&#39;) plt.show() . img 배열이 매우 작기 때문에 (20x30), imshow 함수는 이미지를 figure 크기에 맞도록 늘려버린채 출력합니다. 이러한 늘리기의 기본 동작은 쌍선형 보간법(bilinear interpolation)을 사용하여 추가된 픽셀을 매꿉니다. 테두리가 흐릿한 이유입니다. . 다른 보간법 알고리즘을 선택할 수도 있습니다. 가령 아래와 같이 근접 픽셀을 복사하는 방법이 있습니다: . 이제현 주 : 위 코드의 ax.imshow(img, interpolation=&#39;bilinear&#39;) 부분은 원문에서 ax.imshow(img)로 되어 있습니다. matplotlib 2.0 이전에는 interpolation=&#39;bilinear&#39;가 기본값이기 때문에 경계선이 흐려지는 문제가 있었습니다. . 그러나 이후 interpolation=&#39;nearest&#39;로 기본값이 변경되어 흐려지는 문제가 더 이상 발생하지 않습니다. | 자세한 사항은 이 글을 참고하십시오. | . plt.imshow(img, interpolation=&quot;nearest&quot;) plt.show() . fig, ax = plt.subplots() ax.imshow(img, interpolation=&quot;nearest&quot;) plt.show() . &#50528;&#45768;&#47700;&#51060;&#49496; . matplotlib은 이미지 생성에 주로 사용되지만, 애니메이션의 출력도 가능합니다. 우선 matplotlib.animation을 임포트 해 줘야 합니다. 그 다음은 (주피터 노트북에서) nbagg를 백엔드로 설정하거나, 아래의 코드를 실행해 주면 됩니다. . import matplotlib.animation as animation matplotlib.rc(&#39;animation&#39;, html=&#39;jshtml&#39;) . 다음의 예는 데이터를 생성하는것으로 시작됩니다. 그 다음, 빈 그래프를 생성하고, 애니메이션을 그릴 매 프레임 마다 호출될 갱신(update) 함수를 정의합니다. 마지막으로, FuncAnimation 인스턴스를 생성하여 그래프에 애니메이션을 추가합니다. . FuncAnimation 생성자는 figure, 갱신 함수, 그 외의 파라미터를 수용합니다. 각 프레임간 20ms의 시간차가 있는 100개의 프레임으로 구성된 애니메이션에 대한 인스턴스를 만들었습니다. 애니메이션의 각 프레임마다 FuncAnimation 는 갱신 함수를 호출하고, 프레임 번호를 num (이 예에서는 0~99의 범위) 으로서 전달해 줍니다. 또한 갱신 함수의 추가적인 두 파라미터는 FuncAnimation 생성시 fargs에 넣어준 값이 됩니다. . 작성한 갱신 함수는 선을 구성하는 데이터를 0 ~ num 데이터로 설정합니다 (따라서 데이터가 점진적으로 그려집니다). 그리고 약간의 재미 요소를 위해서, 각 데이터에 약간의 무작위 수를 추가하여 선이 씰룩씰룩 움직이게끔 해 주었습니다. . x = np.linspace(-1, 1, 100) y = np.sin(x**2*25) data = np.array([x, y]) fig = plt.figure() line, = plt.plot([], [], &quot;r-&quot;) # start with an empty plot plt.axis([-1.1, 1.1, -1.1, 1.1]) plt.plot([-0.5, 0.5], [0, 0], &quot;b-&quot;, [0, 0], [-0.5, 0.5], &quot;b-&quot;, 0, 0, &quot;ro&quot;) plt.grid(True) plt.title(&quot;Marvelous animation&quot;) # this function will be called at every iteration def update_line(num, data, line): line.set_data(data[..., :num] + np.random.rand(2, num) / 25) # we only plot the first `num` data points. return line, line_ani = animation.FuncAnimation(fig, update_line, frames=100, fargs=(data, line), interval=67) plt.close() line_ani . &lt;/input&gt; Once Loop Reflect x = np.linspace(-1, 1, 100) y = np.sin(x**2*25) data = np.array([x, y]) fig, ax = plt.subplots() line, = ax.plot([], [], &quot;r-&quot;) # start with an empty plot ax.set_xlim(-1.1, 1.1) ax.set_ylim(-1.1, 1.1) ax.plot([-0.5, 0.5], [0, 0], &quot;b-&quot;, [0, 0], [-0.5, 0.5], &quot;b-&quot;, 0, 0, &quot;ro&quot;) ax.grid(True) ax.set_title(&quot;Marvelous animation&quot;) # this function will be called at every iteration def update_line(num, data, line): line.set_data(data[..., :num] + np.random.rand(2, num) / 25) # we only plot the first `num` data points. return line, line_ani = animation.FuncAnimation(fig, update_line, frames=100, fargs=(data, line), interval=67) plt.close() line_ani . &lt;/input&gt; Once Loop Reflect &#50528;&#45768;&#47700;&#51060;&#49496;&#51012; &#48708;&#46356;&#50724;&#47196; &#51200;&#51109; . 비디오로 저장하기 위해서 Matplotlib은 써드파티 라이브러리(FFMPEG 또는 ImageMagick에 의존합니다. 다음의 예는 FFMPEG를 사용하기 때문에, 이 라이브러리가 먼저 설치되어 있어야만 합니다. 애니메이션을 GIF로 저장하고 싶다면 ImageMagick이 필요할 것입니다. . Writer = animation.writers[&#39;ffmpeg&#39;] writer = Writer(fps=15, metadata=dict(artist=&#39;Me&#39;), bitrate=1800) line_ani.save(&#39;my_wiggly_animation.mp4&#39;, writer=writer) . &#45796;&#51020;&#51008; &#47924;&#50631;&#51012; &#54644;&#50556;&#54624;&#44620;? . 이제 matplotlib의 모든 기본을 습득하셨습니다. 하지만, 그 외에도 수 많은 옵션이 있습니다. 이를 배우기위한 가장 좋은 방법은 갤러리 사이트를 방문하여 흥미로운 그래프를 골라본 다음, 코드를 주피터 노트북에 복사하고 이것저것 가지고 놀아보는 것입니다. .",
            "url": "https://kim-seung-jong.github.io/homepage/2022/06/15/Tools_matplotlib_(%EB%B0%95%EC%B0%AC%EC%84%B1_%EB%B2%88%EC%97%AD_%EC%9D%B4%EC%A0%9C%ED%98%84_OO_API_%EC%B6%94%EA%B0%80).html",
            "relUrl": "/2022/06/15/Tools_matplotlib_(%EB%B0%95%EC%B0%AC%EC%84%B1_%EB%B2%88%EC%97%AD_%EC%9D%B4%EC%A0%9C%ED%98%84_OO_API_%EC%B6%94%EA%B0%80).html",
            "date": " • Jun 15, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Python Language Basics",
            "content": "for x in array: if x &lt; pivot: less.append(x) else: greater.append(x) . a = 5; b = 6; c = 7 . a = 5; b = 6; c = 7 . c . 7 . Everything is an object . Comments . a = [1,2,3] . b=a . a.append(4) b . [1, 2, 3, 4] . Dynamic references, strong types . a = 5 type(a) . int . a = &#39;foo&#39; type(a) . str . &#39;5&#39; + 5 . TypeError Traceback (most recent call last) ~ AppData Local Temp/ipykernel_7472/417106373.py in &lt;module&gt; -&gt; 1 &#39;5&#39; + 5 TypeError: can only concatenate str (not &#34;int&#34;) to str . a = 4.5 b = 2 # String formatting, to be visited later print(&#39;a is {0}, b is {1}&#39;.format(type(a), type(b))) # format(a,b) . a is &lt;class &#39;float&#39;&gt;, b is &lt;class &#39;int&#39;&gt; . a = 5 isinstance(a, int) # a가 int 이냐? . True . a = 5; b = 4.5 isinstance(a, (int, float)) # a가 int, float 둘 중에 하나라도 포함되면 TRUE isinstance(b, (int, float)) . True . Attributes and methods . a = &#39;foo&#39; . a.capitalize() . &#39;Foo&#39; . a.upper() . &#39;FOO&#39; . getattr(a, &#39;split&#39;) . &lt;function str.split(sep=None, maxsplit=-1)&gt; . Duck typing . def isiterable(obj): try: iter(obj) return True except TypeError: # not iterable return False . isiterable(&#39;a string&#39;) . True . isiterable([1, 2, 3]) . True . isiterable(5) . False . 모듈 임포트 . PI = 3.14159 def f(x): return x + 2 def g(a, b): return a + b . import some_module result = some_module.f(5) result . 7 . pi = some_module.PI pi . 3.14159 . Or equivalently: . from some_module import f, g, PI result = g(5, PI) result . 8.14159 . as 예약어를 사용하면 모듈을 다른 이름으로 임포트할 수 있다. . import some_module as sm from some_module import PI as pi, g as gf r1 = sm.f(pi) r2 = gf(6, pi) . r1 . 5.14159 . r2 . 9.14159 . . a = [1, 2, 3] b = a c = list(a) a is b a is not c . True . a == c . True . a = None a is None . True . Mutable and immutable objects : 문자열이나 튜플은 변경 불가능하다 . a_list = [&#39;foo&#39;, 2, [4, 5]] a_list[2] = (3, 4) a_list . [&#39;foo&#39;, 2, (3, 4)] . Strings . c = &quot;&quot;&quot; This is a longer string that spans multiple lines &quot;&quot;&quot; . c . &#39; nThis is a longer string that nspans multiple lines n&#39; . c.count(&#39; n&#39;) . 3 . a = &#39;this is a string&#39; a[10] = &#39;f&#39; # 못바꿈 . TypeError Traceback (most recent call last) ~ AppData Local Temp/ipykernel_7472/3027454595.py in &lt;module&gt; 1 a = &#39;this is a string&#39; -&gt; 2 a[10] = &#39;f&#39; # 못바꿈 TypeError: &#39;str&#39; object does not support item assignment . b = a.replace(&#39;string&#39;, &#39;longer string&#39;) b . &#39;this is a longer string&#39; . a . &#39;this is a string&#39; . a = 5.6 s = str(a) print(s) . 5.6 . s = &#39;python&#39; list(s) s[:3] . &#39;pyt&#39; . s = &#39;12 34&#39; print(s) . 12 34 . s = r&#39;this has no special characters&#39; s . &#39;this has no special characters&#39; . a = &#39;this is the first half &#39; b = &#39;and this is the second half&#39; a + b . &#39;this is the first half and this is the second half&#39; . template = &#39;{0:.2f} {1:s} are worth US${2:d}&#39; # 소수점 2쨰자리까지 가지고 있는 float, . template . &#39;{0:.2f} {1:s} are worth US${2:d}&#39; . template.format(4.5560, &#39;Argentine Pesos&#39;, 1) . &#39;4.56 Argentine Pesos are worth US$1&#39; . None : 파이썬에서 사용하는 NULL값이다. . def add_and_maybe_multiply(a, b, c=None): result = a + b if c is not None: result = result * c return result . add_and_maybe_multiply(5,3) . 8 . add_and_maybe_multiply(5,3,10) . 80 . Date and times . from datetime import datetime, date, time dt = datetime(2011,10,29,20,30,21) dt . datetime.datetime(2011, 10, 29, 20, 30, 21) . dt.day # 일 . 29 . dt.minute # 분 . 30 . dt.date() . datetime.date(2011, 10, 29) . strftime 메서드는 datetime을 문자열로 만들어준다. . dt.strftime(&#39;%m,%d,%y %h:%m&#39;) . &#39;10,29,11 Oct:10&#39; . dt2 = datetime(2011,11,15,22,30) delta = dt2 - dt delta . datetime.timedelta(days=17, seconds=7179) . type(delta) . datetime.timedelta . for loops / 반복문 . sequence = [1,2,None,4,None,5] total = 0 for value in sequence: if value is None: continue total += value total . 12 . sequence = [1, 2, 0, 4, 6, 5, 2, 1] total_until_5 = 0 for value in sequence: if value ==5: break total_until_5 += value . total_until_5 . 13 . while loops : 반복해서 문장을 수행해야 할 경우 while문을 사용 . x = 256 total = 0 while x &gt; 0: if total &gt; 500: break total += x x = x// 2 total . 504 . x . 4 . 256+128+64+32+16+8 . 504 . Pass: 실행할 코드가 없는 것으로 다음 행동을 계속해서 진행합니다. . if x &lt; 0: print(&#39;negative!&#39;) elif x == 0: # TODO: put something smart here pass else: print(&#39;positive!&#39;) . positive! . range :연속된 숫자(정수)를 만들어주는 range() 함수 . range(10) . range(0, 10) . list(range(10)) . [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] . list(range(0,20,2)) . [0, 2, 4, 6, 8, 10, 12, 14, 16, 18] . list(range(5, 1, -1)) # range는 마지막 값 바로 이전 정수까지의 값을 반환한다. . [5, 4, 3, 2] . seq = [1, 2, 3, 4] for i in range(len(seq)): val = seq[i] print(val) . 1 2 3 4 . sum = 0 for i in range(100000): # % is the modulo operator if i % 3 == 0 or i % 5 == 0: sum += i . sum # range 함수는 임의 크기로 값을 생성해낼 수 있지만 메모리 사용량은 매우 적다 . 2333416667 . Ternary expressions: :삼항 표현식 . x = 5 &#39;Non-negative&#39; if x &gt;= 0 else &#39;Negative&#39; # 삼항 표현식은 id-else 블록처럼 조건이 참인 경우의 표현식만 실행한다. . &#39;Non-negative&#39; .",
            "url": "https://kim-seung-jong.github.io/homepage/2022/06/15/Python-basics.html",
            "relUrl": "/2022/06/15/Python-basics.html",
            "date": " • Jun 15, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "1. "Your First Map"",
            "content": "import geopandas as gpd from learntools.core import binder binder.bind(globals()) from learntools.geospatial.ex1 import * . import os os.getcwd() . &#39;c: Users user Desktop VS_C data_mining notebook homework&#39; . 1) Get the data. . Use the next cell to load the shapefile located at loans_filepath to create a GeoDataFrame world_loans. . loans_filepath = (&quot;data/kiva_loans/kiva_loans/kiva_loans.shp&quot;) # Your code here: Load the data world_loans = gpd.read_file(loans_filepath) world_loans.head() . Partner ID Field Part sector Loan Theme country amount geometry . 0 9 | KREDIT Microfinance Institution | General Financial Inclusion | Higher Education | Cambodia | 450 | POINT (102.89751 13.66726) | . 1 9 | KREDIT Microfinance Institution | General Financial Inclusion | Vulnerable Populations | Cambodia | 20275 | POINT (102.98962 13.02870) | . 2 9 | KREDIT Microfinance Institution | General Financial Inclusion | Higher Education | Cambodia | 9150 | POINT (102.98962 13.02870) | . 3 9 | KREDIT Microfinance Institution | General Financial Inclusion | Vulnerable Populations | Cambodia | 604950 | POINT (105.31312 12.09829) | . 4 9 | KREDIT Microfinance Institution | General Financial Inclusion | Sanitation | Cambodia | 275 | POINT (105.31312 12.09829) | . 2) Plot the data. . Run the next code cell without changes to load a GeoDataFrame world containing country boundaries. . world_filepath = gpd.datasets.get_path(&#39;naturalearth_lowres&#39;) world = gpd.read_file(world_filepath) world.head() . pop_est continent name iso_a3 gdp_md_est geometry . 0 920938 | Oceania | Fiji | FJI | 8374.0 | MULTIPOLYGON (((180.00000 -16.06713, 180.00000... | . 1 53950935 | Africa | Tanzania | TZA | 150600.0 | POLYGON ((33.90371 -0.95000, 34.07262 -1.05982... | . 2 603253 | Africa | W. Sahara | ESH | 906.5 | POLYGON ((-8.66559 27.65643, -8.66512 27.58948... | . 3 35623680 | North America | Canada | CAN | 1674000.0 | MULTIPOLYGON (((-122.84000 49.00000, -122.9742... | . 4 326625791 | North America | United States of America | USA | 18560000.0 | MULTIPOLYGON (((-122.84000 49.00000, -120.0000... | . Use the world and world_loans GeoDataFrames to visualize Kiva loan locations across the world. . ax = world.plot(figsize=(10,10), color=&#39;none&#39;, edgecolor=&#39;gainsboro&#39;, zorder=3) world_loans.plot(color=&#39;green&#39;, ax=ax) . &lt;AxesSubplot:&gt; . 3) Select loans based in the Philippines. . Next, you&#39;ll focus on loans that are based in the Philippines. Use the next code cell to create a GeoDataFrame PHL_loans which contains all rows from world_loans with loans that are based in the Philippines. . PHL_loans = world_loans.loc[world_loans.country.isin([&#39;Philippines&#39;])].copy() PHL_loans.head() . Partner ID Field Part sector Loan Theme country amount geometry . 2859 123 | Alalay sa Kaunlaran (ASKI) | General Financial Inclusion | General | Philippines | 400 | POINT (121.73961 17.64228) | . 2860 123 | Alalay sa Kaunlaran (ASKI) | General Financial Inclusion | General | Philippines | 400 | POINT (121.74169 17.63235) | . 2861 123 | Alalay sa Kaunlaran (ASKI) | General Financial Inclusion | General | Philippines | 400 | POINT (121.46667 16.60000) | . 2862 123 | Alalay sa Kaunlaran (ASKI) | General Financial Inclusion | General | Philippines | 6050 | POINT (121.73333 17.83333) | . 2863 123 | Alalay sa Kaunlaran (ASKI) | General Financial Inclusion | General | Philippines | 625 | POINT (121.51800 16.72368) | . 4) Understand loans in the Philippines. . Run the next code cell without changes to load a GeoDataFrame PHL containing boundaries for all islands in the Philippines. . gpd.io.file.fiona.drvsupport.supported_drivers[&#39;KML&#39;] = &#39;rw&#39; PHL = gpd.read_file(&quot;data/Philippines_AL258.kml&quot;, driver=&#39;KML&#39;) PHL.head() . Name Description geometry . 0 Autonomous Region in Muslim Mindanao | | MULTIPOLYGON (((119.46690 4.58718, 119.46653 4... | . 1 Bicol Region | | MULTIPOLYGON (((124.04577 11.57862, 124.04594 ... | . 2 Cagayan Valley | | MULTIPOLYGON (((122.51581 17.04436, 122.51568 ... | . 3 Calabarzon | | MULTIPOLYGON (((120.49202 14.05403, 120.49201 ... | . 4 Caraga | | MULTIPOLYGON (((126.45401 8.24400, 126.45407 8... | . Use the PHL and PHL_loans GeoDataFrames to visualize loans in the Philippines. . ax = PHL.plot(figsize=(10,10), color=&#39;none&#39;, edgecolor=&#39;gainsboro&#39;, zorder=3) PHL_loans.plot(color=&#39;green&#39;, ax=ax) . &lt;AxesSubplot:&gt; . Keep going . Continue to learn about coordinate reference systems. .",
            "url": "https://kim-seung-jong.github.io/homepage/2022/06/15/.-Your_First_Map.html",
            "relUrl": "/2022/06/15/.-Your_First_Map.html",
            "date": " • Jun 15, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "5. Proximity-analysis",
            "content": "import math import pandas as pd import geopandas as gpd from geopy.geocoders import Nominatim import folium from folium import Marker from folium.plugins import MarkerCluster . def embed_map(m, file_name): from IPython.display import IFrame m.save(file_name) return IFrame(file_name, width=&#39;100%&#39;, height=&#39;500px&#39;) . 1) Visualize the collision data. . Run the code cell below to load a GeoDataFrame collisions tracking major motor vehicle collisions in 2013-2018. . collisions = gpd.read_file(&quot;data/NYPD_Motor_Vehicle_Collisions/NYPD_Motor_Vehicle_Collisions/NYPD_Motor_Vehicle_Collisions.shp&quot;) collisions.head() . DATE TIME BOROUGH ZIP CODE LATITUDE LONGITUDE LOCATION ON STREET CROSS STRE OFF STREET ... CONTRIBU_2 CONTRIBU_3 CONTRIBU_4 UNIQUE KEY VEHICLE TY VEHICLE _1 VEHICLE _2 VEHICLE _3 VEHICLE _4 geometry . 0 07/30/2019 | 0:00 | BRONX | 10464 | 40.841100 | -73.784960 | (40.8411, -73.78496) | None | None | 121 PILOT STREET | ... | Unspecified | None | None | 4180045 | Sedan | Station Wagon/Sport Utility Vehicle | Station Wagon/Sport Utility Vehicle | None | None | POINT (1043750.211 245785.815) | . 1 07/30/2019 | 0:10 | QUEENS | 11423 | 40.710827 | -73.770660 | (40.710827, -73.77066) | JAMAICA AVENUE | 188 STREET | None | ... | None | None | None | 4180007 | Sedan | Sedan | None | None | None | POINT (1047831.185 198333.171) | . 2 07/30/2019 | 0:25 | None | None | 40.880318 | -73.841286 | (40.880318, -73.841286) | BOSTON ROAD | None | None | ... | None | None | None | 4179575 | Sedan | Station Wagon/Sport Utility Vehicle | None | None | None | POINT (1028139.293 260041.178) | . 3 07/30/2019 | 0:35 | MANHATTAN | 10036 | 40.756744 | -73.984590 | (40.756744, -73.98459) | None | None | 155 WEST 44 STREET | ... | None | None | None | 4179544 | Box Truck | Station Wagon/Sport Utility Vehicle | None | None | None | POINT (988519.261 214979.320) | . 4 07/30/2019 | 10:00 | BROOKLYN | 11223 | 40.600090 | -73.965910 | (40.60009, -73.96591) | AVENUE T | OCEAN PARKWAY | None | ... | None | None | None | 4180660 | Station Wagon/Sport Utility Vehicle | Bike | None | None | None | POINT (993716.669 157907.212) | . 5 rows × 30 columns . m_1 = folium.Map(location=[40.7, -74], zoom_start=11) # Your code here: Visualize the collision data HeatMap(data=collisions[[&#39;LATITUDE&#39;, &#39;LONGITUDE&#39;]], radius=15).add_to(m_1) # Uncomment to see a hint #q_1.hint() # Show the map embed_map(m_1, &quot;q_1.html&quot;) . 2) Understand hospital coverage. . Run the next code cell to load the hospital data. . hospitals = gpd.read_file(&quot;data/nyu_2451_34494/nyu_2451_34494/nyu_2451_34494.shp&quot;) hospitals.head() . id name address zip factype facname capacity capname bcode xcoord ycoord latitude longitude geometry . 0 317000001H1178 | BRONX-LEBANON HOSPITAL CENTER - CONCOURSE DIVI... | 1650 Grand Concourse | 10457 | 3102 | Hospital | 415 | Beds | 36005 | 1008872.0 | 246596.0 | 40.843490 | -73.911010 | POINT (1008872.000 246596.000) | . 1 317000001H1164 | BRONX-LEBANON HOSPITAL CENTER - FULTON DIVISION | 1276 Fulton Ave | 10456 | 3102 | Hospital | 164 | Beds | 36005 | 1011044.0 | 242204.0 | 40.831429 | -73.903178 | POINT (1011044.000 242204.000) | . 2 317000011H1175 | CALVARY HOSPITAL INC | 1740-70 Eastchester Rd | 10461 | 3102 | Hospital | 225 | Beds | 36005 | 1027505.0 | 248287.0 | 40.848060 | -73.843656 | POINT (1027505.000 248287.000) | . 3 317000002H1165 | JACOBI MEDICAL CENTER | 1400 Pelham Pkwy | 10461 | 3102 | Hospital | 457 | Beds | 36005 | 1027042.0 | 251065.0 | 40.855687 | -73.845311 | POINT (1027042.000 251065.000) | . 4 317000008H1172 | LINCOLN MEDICAL &amp; MENTAL HEALTH CENTER | 234 E 149 St | 10451 | 3102 | Hospital | 362 | Beds | 36005 | 1005154.0 | 236853.0 | 40.816758 | -73.924478 | POINT (1005154.000 236853.000) | . Use the &quot;latitude&quot; and &quot;longitude&quot; columns to visualize the hospital locations. . m_2 = folium.Map(location=[40.7, -74], zoom_start=11) # Your code here: Visualize the hospital locations for idx, row in hospitals.iterrows(): Marker([row[&#39;latitude&#39;], row[&#39;longitude&#39;]], popup=row[&#39;name&#39;]).add_to(m_2) # Uncomment to see a hint #q_2.hint() # Show the map embed_map(m_2, &quot;q_2.html&quot;) . 3) When was the closest hospital more than 10 kilometers away? . Create a DataFrame outside_range containing all rows from collisions with crashes that occurred more than 10 kilometers from the closest hospital. . Note that both hospitals and collisions have EPSG 2263 as the coordinate reference system, and EPSG 2263 has units of meters. . coverage = gpd.GeoDataFrame(geometry=hospitals.geometry).buffer(10000) my_union = coverage.geometry.unary_union outside_range = collisions.loc[~collisions[&quot;geometry&quot;].apply(lambda x: my_union.contains(x))] . The next code cell calculates the percentage of collisions that occurred more than 10 kilometers away from the closest hospital. . percentage = round(100*len(outside_range)/len(collisions), 2) print(&quot;Percentage of collisions more than 10 km away from the closest hospital: {}%&quot;.format(percentage)) . Percentage of collisions more than 10 km away from the closest hospital: 15.12% . 4) Make a recommender. . When collisions occur in distant locations, it becomes even more vital that injured persons are transported to the nearest available hospital. . With this in mind, you decide to create a recommender that: . takes the location of the crash (in EPSG 2263) as input, | finds the closest hospital (where distance calculations are done in EPSG 2263), and | returns the name of the closest hospital. | . def best_hospital(collision_location): idx_min = hospitals.geometry.distance(collision_location).idxmin() my_hospital = hospitals.iloc[idx_min] # your code here name = my_hospital[&quot;name&quot;] return name # Test your function: this should suggest CALVARY HOSPITAL INC print(best_hospital(outside_range.geometry.iloc[0])) # Check your answer q_4.check() . 5) Which hospital is under the highest demand? . Considering only collisions in the outside_range DataFrame, which hospital is most recommended? . Your answer should be a Python string that exactly matches the name of the hospital returned by the function you created in 4). . highest_demand = outside_range.geometry.apply(best_hospital).value_counts().idxmax() highest_demand . &#39;JAMAICA HOSPITAL MEDICAL CENTER&#39; . 6) Where should the city construct new hospitals? . Run the next code cell (without changes) to visualize hospital locations, in addition to collisions that occurred more than 10 kilometers away from the closest hospital. . m_6 = folium.Map(location=[40.7, -74], zoom_start=11) coverage = gpd.GeoDataFrame(geometry=hospitals.geometry).buffer(10000) folium.GeoJson(coverage.geometry.to_crs(epsg=4326)).add_to(m_6) HeatMap(data=outside_range[[&#39;LATITUDE&#39;, &#39;LONGITUDE&#39;]], radius=9).add_to(m_6) folium.LatLngPopup().add_to(m_6) embed_map(m_6, &#39;m_6.html&#39;) . Click anywhere on the map to see a pop-up with the corresponding location in latitude and longitude. . The city of New York reaches out to you for help with deciding locations for two brand new hospitals. They specifically want your help with identifying locations to bring the calculated percentage from step 3) to less than ten percent. Using the map (and without worrying about zoning laws or what potential buildings would have to be removed in order to build the hospitals), can you identify two locations that would help the city accomplish this goal? . Put the proposed latitude and longitude for hospital 1 in lat_1 and long_1, respectively. (Likewise for hospital 2.) . Then, run the rest of the cell as-is to see the effect of the new hospitals. Your answer will be marked correct, if the two new hospitals bring the percentage to less than ten percent. . lat_1 = 40.6728 long_1 = -73.7478 # Your answer here: proposed location of hospital 2 lat_2 = 40.6702 long_2 = -73.7612 # Do not modify the code below this line try: new_df = pd.DataFrame( {&#39;Latitude&#39;: [lat_1, lat_2], &#39;Longitude&#39;: [long_1, long_2]}) new_gdf = gpd.GeoDataFrame(new_df, geometry=gpd.points_from_xy(new_df.Longitude, new_df.Latitude)) new_gdf.crs = {&#39;init&#39; :&#39;epsg:4326&#39;} new_gdf = new_gdf.to_crs(epsg=2263) # get new percentage new_coverage = gpd.GeoDataFrame(geometry=new_gdf.geometry).buffer(10000) new_my_union = new_coverage.geometry.unary_union new_outside_range = outside_range.loc[~outside_range[&quot;geometry&quot;].apply(lambda x: new_my_union.contains(x))] new_percentage = round(100*len(new_outside_range)/len(collisions), 2) print(&quot;(NEW) Percentage of collisions more than 10 km away from the closest hospital: {}%&quot;.format(new_percentage)) # Did you help the city to meet its goal? q_6.check() # make the map m = folium.Map(location=[40.7, -74], zoom_start=11) folium.GeoJson(coverage.geometry.to_crs(epsg=4326)).add_to(m) folium.GeoJson(new_coverage.geometry.to_crs(epsg=4326)).add_to(m) for idx, row in new_gdf.iterrows(): Marker([row[&#39;Latitude&#39;], row[&#39;Longitude&#39;]]).add_to(m) HeatMap(data=new_outside_range[[&#39;LATITUDE&#39;, &#39;LONGITUDE&#39;]], radius=9).add_to(m) folium.LatLngPopup().add_to(m) display(embed_map(m, &#39;q_6.html&#39;)) except: q_6.hint() . Congratulations! . You have just completed the Geospatial Analysis micro-course! Great job! .",
            "url": "https://kim-seung-jong.github.io/homepage/2022/06/15/.-Proximity-Analysis.html",
            "relUrl": "/2022/06/15/.-Proximity-Analysis.html",
            "date": " • Jun 15, 2022"
        }
        
    
  
    
        ,"post6": {
            "title": "4. Manipulating Geospatial Data",
            "content": "import math import pandas as pd import geopandas as gpd from geopy.geocoders import Nominatim import folium from folium import Marker from folium.plugins import MarkerCluster . def embed_map(m, file_name): from IPython.display import IFrame m.save(file_name) return IFrame(file_name, width=&#39;100%&#39;, height=&#39;500px&#39;) . 1) Geocode the missing locations. . Run the next code cell to create a DataFrame starbucks containing Starbucks locations in the state of California. . starbucks = pd.read_csv(&quot;data/starbucks_locations.csv&quot;) starbucks.head() . Store Number Store Name Address City Longitude Latitude . 0 10429-100710 | Palmdale &amp; Hwy 395 | 14136 US Hwy 395 Adelanto CA | Adelanto | -117.40 | 34.51 | . 1 635-352 | Kanan &amp; Thousand Oaks | 5827 Kanan Road Agoura CA | Agoura | -118.76 | 34.16 | . 2 74510-27669 | Vons-Agoura Hills #2001 | 5671 Kanan Rd. Agoura Hills CA | Agoura Hills | -118.76 | 34.15 | . 3 29839-255026 | Target Anaheim T-0677 | 8148 E SANTA ANA CANYON ROAD AHAHEIM CA | AHAHEIM | -117.75 | 33.87 | . 4 23463-230284 | Safeway - Alameda 3281 | 2600 5th Street Alameda CA | Alameda | -122.28 | 37.79 | . Most of the stores have known (latitude, longitude) locations. But, all of the locations in the city of Berkeley are missing. . print(starbucks.isnull().sum()) # View rows with missing locations rows_with_missing = starbucks[starbucks[&quot;City&quot;]==&quot;Berkeley&quot;] rows_with_missing . Store Number 0 Store Name 0 Address 0 City 0 Longitude 5 Latitude 5 dtype: int64 . Store Number Store Name Address City Longitude Latitude . 153 5406-945 | 2224 Shattuck - Berkeley | 2224 Shattuck Avenue Berkeley CA | Berkeley | NaN | NaN | . 154 570-512 | Solano Ave | 1799 Solano Avenue Berkeley CA | Berkeley | NaN | NaN | . 155 17877-164526 | Safeway - Berkeley #691 | 1444 Shattuck Place Berkeley CA | Berkeley | NaN | NaN | . 156 19864-202264 | Telegraph &amp; Ashby | 3001 Telegraph Avenue Berkeley CA | Berkeley | NaN | NaN | . 157 9217-9253 | 2128 Oxford St. | 2128 Oxford Street Berkeley CA | Berkeley | NaN | NaN | . Use the code cell below to fill in these values with the Nominatim geocoder. . Note that in the tutorial, we used Nominatim() (from geopy.geocoders) to geocode values, and this is what you can use in your own projects outside of this course. . In this exercise, you will use a slightly different function Nominatim() (from learntools.geospatial.tools). This function was imported at the top of the notebook and works identically to the function from GeoPandas. . So, in other words, as long as: . you don&#39;t change the import statements at the top of the notebook, and | you call the geocoding function as geocode() in the code cell below, your code will work as intended! | . geolocator = Nominatim(user_agent=&quot;kaggle_learn&quot;) # Your code here def my_geocoder(row): point = geolocator.geocode(row).point return pd.Series({&#39;Latitude&#39;: point.latitude, &#39;Longitude&#39;: point.longitude}) berkeley_locations = rows_with_missing.apply(lambda x: my_geocoder(x[&#39;Address&#39;]), axis=1) starbucks.update(berkeley_locations) . 2) View Berkeley locations. . Let&#39;s take a look at the locations you just found. Visualize the (latitude, longitude) locations in Berkeley in the OpenStreetMap style. . m_2 = folium.Map(location=[37.88,-122.26], zoom_start=13) # Your code here: Add a marker for each Berkeley location for idx, row in starbucks[starbucks[&quot;City&quot;]==&#39;Berkeley&#39;].iterrows(): Marker([row[&#39;Latitude&#39;], row[&#39;Longitude&#39;]]).add_to(m_2) # Uncomment to see a hint #q_2.a.hint() # Show the map embed_map(m_2, &#39;q_2.html&#39;) . Considering only the five locations in Berkeley, how many of the (latitude, longitude) locations seem potentially correct (are located in the correct city)? . 3) Consolidate your data. . Run the code below to load a GeoDataFrame CA_counties containing the name, area (in square kilometers), and a unique id (in the &quot;GEOID&quot; column) for each county in the state of California. The &quot;geometry&quot; column contains a polygon with county boundaries. . CA_counties = gpd.read_file(&quot;data/CA_county_boundaries/CA_county_boundaries/CA_county_boundaries.shp&quot;) CA_counties.head() . GEOID name area_sqkm geometry . 0 6091 | Sierra County | 2491.995494 | POLYGON ((-120.65560 39.69357, -120.65554 39.6... | . 1 6067 | Sacramento County | 2575.258262 | POLYGON ((-121.18858 38.71431, -121.18732 38.7... | . 2 6083 | Santa Barbara County | 9813.817958 | MULTIPOLYGON (((-120.58191 34.09856, -120.5822... | . 3 6009 | Calaveras County | 2685.626726 | POLYGON ((-120.63095 38.34111, -120.63058 38.3... | . 4 6111 | Ventura County | 5719.321379 | MULTIPOLYGON (((-119.63631 33.27304, -119.6360... | . Next, we create three DataFrames: . CA_pop contains an estimate of the population of each county. | CA_high_earners contains the number of households with an income of at least $150,000 per year. | CA_median_age contains the median age for each county. | . CA_pop = pd.read_csv(&quot;data/CA_county_population.csv&quot;, index_col=&quot;GEOID&quot;) CA_high_earners = pd.read_csv(&quot;data/CA_county_high_earners.csv&quot;, index_col=&quot;GEOID&quot;) CA_median_age = pd.read_csv(&quot;data/CA_county_median_age.csv&quot;, index_col=&quot;GEOID&quot;) . Use the next code cell to join the CA_counties GeoDataFrame with CA_pop, CA_high_earners, and CA_median_age. . Name the resultant GeoDataFrame CA_stats, and make sure it has 8 columns: &quot;GEOID&quot;, &quot;name&quot;, &quot;area_sqkm&quot;, &quot;geometry&quot;, &quot;population&quot;, &quot;high_earners&quot;, and &quot;median_age&quot;. Also, make sure the CRS is set to {&#39;init&#39;: &#39;epsg:4326&#39;}. . cols_to_add = CA_pop.join([CA_high_earners, CA_median_age]).reset_index() CA_stats = CA_counties.merge(cols_to_add, on=&quot;GEOID&quot;) . Now that we have all of the data in one place, it&#39;s much easier to calculate statistics that use a combination of columns. Run the next code cell to create a &quot;density&quot; column with the population density. . CA_stats[&quot;density&quot;] = CA_stats[&quot;population&quot;] / CA_stats[&quot;area_sqkm&quot;] . 4) Which counties look promising? Collapsing all of the information into a single GeoDataFrame also makes it much easier to select counties that meet specific criteria. . Use the next code cell to create a GeoDataFrame sel_counties that contains a subset of the rows (and all of the columns) from the CA_stats GeoDataFrame. In particular, you should select counties where: . there are at least 100,000 households making $150,000 per year, | the median age is less than 38.5, and | the density of inhabitants is at least 285 (per square kilometer). | . Additionally, selected counties should satisfy at least one of the following criteria: . there are at least 500,000 households making $150,000 per year, | the median age is less than 35.5, or | the density of inhabitants is at least 1400 (per square kilometer). | . sel_counties = sel_counties = CA_stats[((CA_stats.high_earners &gt; 100000) &amp; (CA_stats.median_age &lt; 38.5) &amp; (CA_stats.density &gt; 285) &amp; ((CA_stats.median_age &lt; 35.5) | (CA_stats.density &gt; 1400) | (CA_stats.high_earners &gt; 500000)))] . 5) How many stores did you identify? . When looking for the next Starbucks Reserve Roastery location, you&#39;d like to consider all of the stores within the counties that you selected. So, how many stores are within the selected counties? . To prepare to answer this question, run the next code cell to create a GeoDataFrame starbucks_gdf with all of the starbucks locations. . starbucks_gdf = gpd.GeoDataFrame(starbucks, geometry=gpd.points_from_xy(starbucks.Longitude, starbucks.Latitude)) starbucks_gdf.crs = {&#39;init&#39;: &#39;epsg:4326&#39;} . c: Users user AppData Local Programs Python Python310 lib site-packages pyproj crs crs.py:130: FutureWarning: &#39;+init=&lt;authority&gt;:&lt;code&gt;&#39; syntax is deprecated. &#39;&lt;authority&gt;:&lt;code&gt;&#39; is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6 in_crs_string = _prepare_from_proj_string(in_crs_string) . So, how many stores are in the counties you selected? . locations_of_interest = gpd.sjoin(starbucks_gdf, sel_counties) num_stores = len(locations_of_interest) . C: Users user AppData Local Temp ipykernel_912 3855931823.py:1: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries. Use `to_crs()` to reproject one of the input geometries to match the CRS of the other. Left CRS: +init=epsg:4326 +type=crs Right CRS: EPSG:4326 locations_of_interest = gpd.sjoin(starbucks_gdf, sel_counties) . 6) Visualize the store locations. Create a map that shows the locations of the stores that you identified in the previous question. . m_6 = folium.Map(location=[37,-120], zoom_start=6) # Your code here: show selected store locations mc = MarkerCluster() locations_of_interest = gpd.sjoin(starbucks_gdf, sel_counties) for idx, row in locations_of_interest.iterrows(): if not math.isnan(row[&#39;Longitude&#39;]) and not math.isnan(row[&#39;Latitude&#39;]): mc.add_child(folium.Marker([row[&#39;Latitude&#39;], row[&#39;Longitude&#39;]])) m_6.add_child(mc) # Show the map embed_map(m_6, &#39;q_6.html&#39;) . Keep going Learn about how proximity analysis can help you to understand the relationships between points on a map. .",
            "url": "https://kim-seung-jong.github.io/homepage/2022/06/15/.-Mainpulating-Geospatial-Data.html",
            "relUrl": "/2022/06/15/.-Mainpulating-Geospatial-Data.html",
            "date": " • Jun 15, 2022"
        }
        
    
  
    
        ,"post7": {
            "title": "3. "Interactive Maps"",
            "content": "import pandas as pd import geopandas as gpd import folium from folium import Choropleth, Circle, Marker from folium.plugins import HeatMap, MarkerCluster . def embed_map(m, file_name): from IPython.display import IFrame m.save(file_name) return IFrame(file_name, width=&#39;100%&#39;, height=&#39;500px&#39;) . 1) Do earthquakes coincide with plate boundaries? . Run the code cell below to create a DataFrame plate_boundaries that shows global plate boundaries. The &quot;coordinates&quot; column is a list of (latitude, longitude) locations along the boundaries. . plate_boundaries = gpd.read_file(&quot;data/Plate_Boundaries/Plate_Boundaries/Plate_Boundaries.shp&quot;) plate_boundaries[&#39;coordinates&#39;] = plate_boundaries.apply(lambda x: [(b,a) for (a,b) in list(x.geometry.coords)], axis=&#39;columns&#39;) plate_boundaries.drop(&#39;geometry&#39;, axis=1, inplace=True) plate_boundaries.head() . HAZ_PLATES HAZ_PLAT_1 HAZ_PLAT_2 Shape_Leng coordinates . 0 TRENCH | SERAM TROUGH (ACTIVE) | 6722 | 5.843467 | [(-5.444200361999947, 133.6808931800001), (-5.... | . 1 TRENCH | WETAR THRUST | 6722 | 1.829013 | [(-7.760600482999962, 125.47879802900002), (-7... | . 2 TRENCH | TRENCH WEST OF LUZON (MANILA TRENCH) NORTHERN ... | 6621 | 6.743604 | [(19.817899819000047, 120.09999798800004), (19... | . 3 TRENCH | BONIN TRENCH | 9821 | 8.329381 | [(26.175899215000072, 143.20620700100005), (26... | . 4 TRENCH | NEW GUINEA TRENCH | 8001 | 11.998145 | [(0.41880004000006466, 132.8273013480001), (0.... | . Next, run the code cell below without changes to load the historical earthquake data into a DataFrame earthquakes. . earthquakes = pd.read_csv(&quot;data/earthquakes1970-2014.csv&quot;, parse_dates=[&quot;DateTime&quot;]) earthquakes.head() . DateTime Latitude Longitude Depth Magnitude MagType NbStations Gap Distance RMS Source EventID . 0 1970-01-04 17:00:40.200 | 24.139 | 102.503 | 31.0 | 7.5 | Ms | 90.0 | NaN | NaN | 0.0 | NEI | 1.970010e+09 | . 1 1970-01-06 05:35:51.800 | -9.628 | 151.458 | 8.0 | 6.2 | Ms | 85.0 | NaN | NaN | 0.0 | NEI | 1.970011e+09 | . 2 1970-01-08 17:12:39.100 | -34.741 | 178.568 | 179.0 | 6.1 | Mb | 59.0 | NaN | NaN | 0.0 | NEI | 1.970011e+09 | . 3 1970-01-10 12:07:08.600 | 6.825 | 126.737 | 73.0 | 6.1 | Mb | 91.0 | NaN | NaN | 0.0 | NEI | 1.970011e+09 | . 4 1970-01-16 08:05:39.000 | 60.280 | -152.660 | 85.0 | 6.0 | ML | 0.0 | NaN | NaN | NaN | AK | NaN | . The code cell below visualizes the plate boundaries on a map. Use all of the earthquake data to add a heatmap to the same map, to determine whether earthquakes coincide with plate boundaries. . m_1 = folium.Map(location=[35,136], tiles=&#39;cartodbpositron&#39;, zoom_start=5) for i in range(len(plate_boundaries)): folium.PolyLine(locations=plate_boundaries.coordinates.iloc[i], weight=2, color=&#39;black&#39;).add_to(m_1) # Your code here: Add a heatmap to the map HeatMap(data=earthquakes[[&#39;Latitude&#39;, &#39;Longitude&#39;]], radius=10).add_to(m_1) # Show the map embed_map(m_1, &#39;q_1.html&#39;) . 2) Is there a relationship between earthquake depth and proximity to a plate boundary in Japan? . You recently read that the depth of earthquakes tells us important information about the structure of the earth. You&#39;re interested to see if there are any intereresting global patterns, and you&#39;d also like to understand how depth varies in Japan. . m_2 = folium.Map(location=[35,136], tiles=&#39;cartodbpositron&#39;, zoom_start=5) for i in range(len(plate_boundaries)): folium.PolyLine(locations=plate_boundaries.coordinates.iloc[i], weight=2, color=&#39;black&#39;).add_to(m_2) # Your code here: Add a map to visualize earthquake depth def color_producer(val): if val &lt;= 100: return &#39;forestgreen&#39; else: return &#39;darkred&#39; # Add a bubble map to the base map for i in range(0,len(earthquakes)): folium.Circle( location=[earthquakes.iloc[i][&#39;Latitude&#39;], earthquakes.iloc[i][&#39;Longitude&#39;]], radius=200, color=color_producer(earthquakes.iloc[i][&#39;Depth&#39;])).add_to(m_2) # View the map embed_map(m_2, &#39;q_2.html&#39;) . 3) Which prefectures have high population density? . Run the next code cell (without changes) to create a GeoDataFrame prefectures that contains the geographical boundaries of Japanese prefectures. . prefectures = gpd.read_file(&quot;data/japan-prefecture-boundaries/japan-prefecture-boundaries/japan-prefecture-boundaries.shp&quot;) prefectures.set_index(&#39;prefecture&#39;, inplace=True) prefectures.head() . geometry . prefecture . Aichi MULTIPOLYGON (((137.09523 34.65330, 137.09546 ... | . Akita MULTIPOLYGON (((139.55725 39.20330, 139.55765 ... | . Aomori MULTIPOLYGON (((141.39860 40.92472, 141.39806 ... | . Chiba MULTIPOLYGON (((139.82488 34.98967, 139.82434 ... | . Ehime MULTIPOLYGON (((132.55859 32.91224, 132.55904 ... | . The next code cell creates a DataFrame stats containing the population, area (in square kilometers), and population density (per square kilometer) for each Japanese prefecture. Run the code cell without changes. . population = pd.read_csv(&quot;data/japan-prefecture-population.csv&quot;) population.set_index(&#39;prefecture&#39;, inplace=True) # Calculate area (in square kilometers) of each prefecture area_sqkm = pd.Series(prefectures.geometry.to_crs(epsg=32654).area / 10**6, name=&#39;area_sqkm&#39;) stats = population.join(area_sqkm) # Add density (per square kilometer) of each prefecture stats[&#39;density&#39;] = stats[&quot;population&quot;] / stats[&quot;area_sqkm&quot;] stats.head() . population area_sqkm density . prefecture . Tokyo 12868000 | 1800.614782 | 7146.448049 | . Kanagawa 8943000 | 2383.038975 | 3752.771186 | . Osaka 8801000 | 1923.151529 | 4576.342460 | . Aichi 7418000 | 5164.400005 | 1436.372085 | . Saitama 7130000 | 3794.036890 | 1879.264806 | . Use the next code cell to create a choropleth map to visualize population density. . m_3 = folium.Map(location=[35,136], tiles=&#39;cartodbpositron&#39;, zoom_start=5) # Your code here: create a choropleth map to visualize population density # Add a choropleth map to the base map Choropleth(geo_data=prefectures[&#39;geometry&#39;].__geo_interface__, data=stats[&#39;density&#39;], key_on=&quot;feature.id&quot;, fill_color=&#39;YlGnBu&#39;, legend_name=&#39;Major criminal incidents&#39; ).add_to(m_3) # View the map embed_map(m_3, &#39;q_3.html&#39;) . 4) Which high-density prefecture is prone to high-magnitude earthquakes? . Create a map to suggest one prefecture that might benefit from earthquake reinforcement. Your map should visualize both density and earthquake magnitude. . m_4 = folium.Map(location=[35,136], tiles=&#39;cartodbpositron&#39;, zoom_start=5) # Your code here: create a map Choropleth(geo_data=prefectures[&#39;geometry&#39;].__geo_interface__, data=stats[&#39;density&#39;], key_on=&quot;feature.id&quot;, fill_color=&#39;YlGnBu&#39;, legend_name=&#39;Major criminal incidents&#39; ).add_to(m_4) # Uncomment to see a hint #q_4.a.hint() # View the map embed_map(m_4, &#39;q_4.html&#39;) .",
            "url": "https://kim-seung-jong.github.io/homepage/2022/06/15/.-Interactive-Maps.html",
            "relUrl": "/2022/06/15/.-Interactive-Maps.html",
            "date": " • Jun 15, 2022"
        }
        
    
  
    
        ,"post8": {
            "title": "2. "Coordinate Refrence Systems"",
            "content": "import pandas as pd import geopandas as gpd . 1) Load the data. . Run the next code cell (without changes) to load the GPS data into a pandas DataFrame birds_df. . birds_df = pd.read_csv(&quot;data/purple_martin.csv&quot;, parse_dates=[&#39;timestamp&#39;]) print(&quot;There are {} different birds in the dataset.&quot;.format(birds_df[&quot;tag-local-identifier&quot;].nunique())) birds_df.head() . There are 11 different birds in the dataset. . timestamp location-long location-lat tag-local-identifier . 0 2014-08-15 05:56:00 | -88.146014 | 17.513049 | 30448 | . 1 2014-09-01 05:59:00 | -85.243501 | 13.095782 | 30448 | . 2 2014-10-30 23:58:00 | -62.906089 | -7.852436 | 30448 | . 3 2014-11-15 04:59:00 | -61.776826 | -11.723898 | 30448 | . 4 2014-11-30 09:59:00 | -61.241538 | -11.612237 | 30448 | . There are 11 birds in the dataset, where each bird is identified by a unique value in the &quot;tag-local-identifier&quot; column. Each bird has several measurements, collected at different times of the year. . Use the next code cell to create a GeoDataFrame birds. . birds should have all of the columns from birds_df, along with a &quot;geometry&quot; column that contains Point objects with (longitude, latitude) locations. | Set the CRS of birds to {&#39;init&#39;: &#39;epsg:4326&#39;}. | . birds = gpd.GeoDataFrame(birds_df, geometry=gpd.points_from_xy(birds_df[&#39;location-long&#39;], birds_df[&#39;location-lat&#39;])) # Your code here: Set the CRS to {&#39;init&#39;: &#39;epsg:4326&#39;} birds.crs = {&#39;init&#39;: &#39;epsg:4326&#39;} . c: Users user AppData Local Programs Python Python310 lib site-packages pyproj crs crs.py:130: FutureWarning: &#39;+init=&lt;authority&gt;:&lt;code&gt;&#39; syntax is deprecated. &#39;&lt;authority&gt;:&lt;code&gt;&#39; is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6 in_crs_string = _prepare_from_proj_string(in_crs_string) . birds.head() . timestamp location-long location-lat tag-local-identifier geometry . 0 2014-08-15 05:56:00 | -88.146014 | 17.513049 | 30448 | POINT (-88.14601 17.51305) | . 1 2014-09-01 05:59:00 | -85.243501 | 13.095782 | 30448 | POINT (-85.24350 13.09578) | . 2 2014-10-30 23:58:00 | -62.906089 | -7.852436 | 30448 | POINT (-62.90609 -7.85244) | . 3 2014-11-15 04:59:00 | -61.776826 | -11.723898 | 30448 | POINT (-61.77683 -11.72390) | . 4 2014-11-30 09:59:00 | -61.241538 | -11.612237 | 30448 | POINT (-61.24154 -11.61224) | . 2) Plot the data. . Next, we load in the &#39;naturalearth_lowres&#39; dataset from GeoPandas, and set americas to a GeoDataFrame containing the boundaries of all countries in the Americas (both North and South America). Run the next code cell without changes. . world = gpd.read_file(gpd.datasets.get_path(&#39;naturalearth_lowres&#39;)) americas = world.loc[world[&#39;continent&#39;].isin([&#39;North America&#39;, &#39;South America&#39;])] americas.head() . pop_est continent name iso_a3 gdp_md_est geometry . 3 35623680 | North America | Canada | CAN | 1674000.0 | MULTIPOLYGON (((-122.84000 49.00000, -122.9742... | . 4 326625791 | North America | United States of America | USA | 18560000.0 | MULTIPOLYGON (((-122.84000 49.00000, -120.0000... | . 9 44293293 | South America | Argentina | ARG | 879400.0 | MULTIPOLYGON (((-68.63401 -52.63637, -68.25000... | . 10 17789267 | South America | Chile | CHL | 436100.0 | MULTIPOLYGON (((-68.63401 -52.63637, -68.63335... | . 16 10646714 | North America | Haiti | HTI | 19340.0 | POLYGON ((-71.71236 19.71446, -71.62487 19.169... | . Use the next code cell to create a single plot that shows both: (1) the country boundaries in the americas GeoDataFrame, and (2) all of the points in the birds_gdf GeoDataFrame. . Don&#39;t worry about any special styling here; just create a preliminary plot, as a quick sanity check that all of the data was loaded properly. In particular, you don&#39;t have to worry about color-coding the points to differentiate between birds, and you don&#39;t have to differentiate starting points from ending points. We&#39;ll do that in the next part of the exercise. . ax = americas.plot(figsize=(8,8), color=&#39;whitesmoke&#39;, linestyle=&#39;:&#39;, edgecolor=&#39;black&#39;) birds.plot(color=&#39;green&#39;, ax=ax) . &lt;AxesSubplot:&gt; . 3) Where does each bird start and end its journey? (Part 1) . Now, we&#39;re ready to look more closely at each bird&#39;s path. Run the next code cell to create two GeoDataFrames: . path_gdf contains LineString objects that show the path of each bird. It uses the LineString() method to create a LineString object from a list of Point objects. | start_gdf contains the starting points for each bird. | . import pandas as pd import matplotlib.pyplot as plt import seaborn as sns . path_df = birds.groupby(&quot;tag-local-identifier&quot;)[&#39;geometry&#39;].apply(list).apply(lambda x: LineString(x)).reset_index() path_gdf = gpd.GeoDataFrame(path_df, geometry=path_df.geometry) path_gdf.crs = {&#39;init&#39; :&#39;epsg:4326&#39;} # GeoDataFrame showing starting point for each bird start_df = birds.groupby(&quot;tag-local-identifier&quot;)[&#39;geometry&#39;].apply(list).apply(lambda x: x[0]).reset_index() start_gdf = gpd.GeoDataFrame(start_df, geometry=start_df.geometry) start_gdf.crs = {&#39;init&#39; :&#39;epsg:4326&#39;} # Show first five rows of GeoDataFrame start_gdf.head() . Use the next code cell to create a GeoDataFrame end_gdf containing the final location of each bird. . The format should be identical to that of start_gdf, with two columns (&quot;tag-local-identifier&quot; and &quot;geometry&quot;), where the &quot;geometry&quot; column contains Point objects. | Set the CRS of end_gdf to {&#39;init&#39;: &#39;epsg:4326&#39;}. | . end_df = birds.groupby(&quot;tag-local-identifier&quot;)[&#39;geometry&#39;].apply(list).apply(lambda x: x[-1]).reset_index() end_gdf = gpd.GeoDataFrame(end_df, geometry=end_df.geometry) end_gdf.crs = {&#39;init&#39; :&#39;epsg:4326&#39;} . c: Users user AppData Local Programs Python Python310 lib site-packages pyproj crs crs.py:130: FutureWarning: &#39;+init=&lt;authority&gt;:&lt;code&gt;&#39; syntax is deprecated. &#39;&lt;authority&gt;:&lt;code&gt;&#39; is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6 in_crs_string = _prepare_from_proj_string(in_crs_string) . 4) Where does each bird start and end its journey? (Part 2) . Use the GeoDataFrames from the question above (path_gdf, start_gdf, and end_gdf) to visualize the paths of all birds on a single map. You may also want to use the americas GeoDataFrame. . ax = americas.plot(figsize=(8,8), color=&#39;none&#39;, edgecolor=&#39;gainsboro&#39;, zorder=3) start_gdf.plot(color=&#39;green&#39;, ax=ax) path_gdf.plot(color=&#39;blue&#39;, ax=ax) end_gdf.plot(color=&#39;black&#39;, ax=ax) . 5) Where are the protected areas in South America? (Part 1) . It looks like all of the birds end up somewhere in South America. But are they going to protected areas? . In the next code cell, you&#39;ll create a GeoDataFrame protected_areas containing the locations of all of the protected areas in South America. The corresponding shapefile is located at filepath protected_filepath. . protected_filepath = &quot;data/SAPA_Aug2019-shapefile/SAPA_Aug2019-shapefile/SAPA_Aug2019-shapefile-polygons.shp&quot; # Your code here protected_areas = gpd.read_file(protected_filepath) . protected_areas.head() . WDPAID WDPA_PID PA_DEF NAME ORIG_NAME DESIG DESIG_ENG DESIG_TYPE IUCN_CAT INT_CRIT ... GOV_TYPE OWN_TYPE MANG_AUTH MANG_PLAN VERIF METADATAID SUB_LOC PARENT_ISO ISO3 geometry . 0 14067.0 | 14067 | 1 | Het Spaans Lagoen | Het Spaans Lagoen | Ramsar Site, Wetland of International Importance | Ramsar Site, Wetland of International Importance | International | Not Reported | Not Reported | ... | Not Reported | Not Reported | Not Reported | Management plan is not implemented and not ava... | State Verified | 1856 | Not Reported | NLD | ABW | POLYGON ((-69.97523 12.47379, -69.97523 12.473... | . 1 14003.0 | 14003 | 1 | Bubali Pond Bird Sanctuary | Bubali Pond Bird Sanctuary | Bird Sanctuary | Bird Sanctuary | National | Not Reported | Not Applicable | ... | Not Reported | Not Reported | Not Reported | Not Reported | State Verified | 1899 | Not Reported | NLD | ABW | POLYGON ((-70.04734 12.56329, -70.04615 12.563... | . 2 555624439.0 | 555624439 | 1 | Arikok National Park | Arikok National Park | National Park | National Park | National | Not Reported | Not Applicable | ... | Non-profit organisations | Non-profit organisations | Fundacion Parke Nacional Arikok | Not Reported | State Verified | 1899 | Not Reported | NLD | ABW | MULTIPOLYGON (((-69.96302 12.48384, -69.96295 ... | . 3 303894.0 | 303894 | 1 | Madidi | Madidi | Area Natural de Manejo Integrado | Natural Integrated Management Area | National | Not Reported | Not Applicable | ... | Federal or national ministry or agency | Not Reported | Not Reported | Not Reported | State Verified | 1860 | BO-L | BOL | BOL | POLYGON ((-68.59060 -14.43388, -68.59062 -14.4... | . 4 303893.0 | 303893 | 1 | Apolobamba | Apolobamba | Area Natural de Manejo Integado Nacional | National Natural Integrated Management Area | National | Not Reported | Not Applicable | ... | Federal or national ministry or agency | Not Reported | Not Reported | Not Reported | State Verified | 1860 | BO-L | BOL | BOL | POLYGON ((-69.20949 -14.73334, -69.20130 -14.7... | . 5 rows × 29 columns . 6) Where are the protected areas in South America? (Part 2) . Create a plot that uses the protected_areas GeoDataFrame to show the locations of the protected areas in South America. (You&#39;ll notice that some protected areas are on land, while others are in marine waters.) . south_america = americas.loc[americas[&#39;continent&#39;]==&#39;South America&#39;] # Your code here: plot protected areas in South America ax = south_america.plot(figsize=(8,8), color=&#39;none&#39;, edgecolor=&#39;gainsboro&#39;, zorder=3) protected_areas.plot(markersize=1, ax=ax) . &lt;AxesSubplot:&gt; . 7) What percentage of South America is protected? . You&#39;re interested in determining what percentage of South America is protected, so that you know how much of South America is suitable for the birds. . As a first step, you calculate the total area of all protected lands in South America (not including marine area). To do this, you use the &quot;REP_AREA&quot; and &quot;REP_M_AREA&quot; columns, which contain the total area and total marine area, respectively, in square kilometers. . Run the code cell below without changes. . P_Area = sum(protected_areas[&#39;REP_AREA&#39;]-protected_areas[&#39;REP_M_AREA&#39;]) print(&quot;South America has {} square kilometers of protected areas.&quot;.format(P_Area)) . South America has 5396761.9116883585 square kilometers of protected areas. . south_america.head() . pop_est continent name iso_a3 gdp_md_est geometry . 9 44293293 | South America | Argentina | ARG | 879400.0 | MULTIPOLYGON (((-68.63401 -52.63637, -68.25000... | . 10 17789267 | South America | Chile | CHL | 436100.0 | MULTIPOLYGON (((-68.63401 -52.63637, -68.63335... | . 20 2931 | South America | Falkland Is. | FLK | 281.8 | POLYGON ((-61.20000 -51.85000, -60.00000 -51.2... | . 28 3360148 | South America | Uruguay | URY | 73250.0 | POLYGON ((-57.62513 -30.21629, -56.97603 -30.1... | . 29 207353391 | South America | Brazil | BRA | 3081000.0 | POLYGON ((-53.37366 -33.76838, -53.65054 -33.2... | . Calculate the total area of South America by following these steps: . Calculate the area of each country using the area attribute of each polygon (with EPSG 3035 as the CRS), and add up the results. The calculated area will be in units of square meters. | Convert your answer to have units of square kilometeters. | . totalArea = sum(south_america.geometry.to_crs(epsg=3035).area)/10**6 totalArea . 17759005.81506123 . percentage_protected = P_Area/totalArea print(&#39;Approximately {}% of South America is protected.&#39;.format(round(percentage_protected*100, 2))) . Approximately 30.39% of South America is protected. . 8) Where are the birds in South America? . So, are the birds in protected areas? . Create a plot that shows for all birds, all of the locations where they were discovered in South America. Also plot the locations of all protected areas in South America. . To exclude protected areas that are purely marine areas (with no land component), you can use the &quot;MARINE&quot; column (and plot only the rows in protected_areas[protected_areas[&#39;MARINE&#39;]!=&#39;2&#39;], instead of every row in the protected_areas GeoDataFrame). . ax = protected_areas[protected_areas[&#39;MARINE&#39;]!=&#39;2&#39;].plot(figsize=(10,10), color=&#39;none&#39;, edgecolor=&#39;gainsboro&#39;, zorder=3) birds[birds.geometry.y &lt; 0].plot(ax=ax, color=&#39;red&#39;, alpha=0.6, markersize=10, zorder=2) . &lt;AxesSubplot:&gt; .",
            "url": "https://kim-seung-jong.github.io/homepage/2022/06/15/.-Coordinate-Refrence-Systems.html",
            "relUrl": "/2022/06/15/.-Coordinate-Refrence-Systems.html",
            "date": " • Jun 15, 2022"
        }
        
    
  
    
        ,"post9": {
            "title": "Markdown Cheat sheet",
            "content": "Markdown Cheat Sheet . Thanks for visiting The Markdown Guide! . This Markdown cheat sheet provides a quick overview of all the Markdown syntax elements. It can’t cover every edge case, so if you need more information about any of these elements, refer to the reference guides for basic syntax and extended syntax. . Basic Syntax . These are the elements outlined in John Gruber’s original design document. All Markdown applications support these elements. . Heading . H1 . H2 . H3 . Bold . bold text . Italic . italicized text . Blockquote . blockquote . Ordered List . First item | Second item | Third item | Unordered List . First item | Second item | Third item | . Code . code . Horizontal Rule . . Link . Markdown Guide . Image . . Extended Syntax . These elements extend the basic syntax by adding additional features. Not all Markdown applications support these elements. . Table . Syntax Description . Header | Title | . Paragraph | Text | . Fenced Code Block . { &quot;firstName&quot;: &quot;John&quot;, &quot;lastName&quot;: &quot;Smith&quot;, &quot;age&quot;: 25 } . Footnote . Here’s a sentence with a footnote. 1 . Heading ID . My Great Heading . Definition List . term definition Strikethrough . The world is flat. . Task List . Write the press release | Update the website | Contact the media | . Emoji . That is so funny! :joy: . (See also Copying and Pasting Emoji) . Highlight . I need to highlight these ==very important words==. . Subscript . H~2~O . Superscript . X^2^ . This is the footnote. &#8617; . |",
            "url": "https://kim-seung-jong.github.io/homepage/markdown/2022/03/11/Markdown-basics.html",
            "relUrl": "/markdown/2022/03/11/Markdown-basics.html",
            "date": " • Mar 11, 2022"
        }
        
    
  
    
        ,"post10": {
            "title": "Numpy 기본!",
            "content": "도구 - 넘파이(NumPy) . *넘파이(NumPy)는 파이썬의 과학 컴퓨팅을 위한 기본 라이브러리입니다. 넘파이의 핵심은 강력한 N-차원 배열 객체입니다. 또한 선형 대수, 푸리에(Fourier) 변환, 유사 난수 생성과 같은 유용한 함수들도 제공합니다.&quot; . 구글 코랩에서 실행하기 | &#48176;&#50676; &#49373;&#49457; . numpy를 임포트해 보죠. 대부분의 사람들이 np로 알리아싱하여 임포트합니다: . import numpy as np . np.zeros . zeros 함수는 0으로 채워진 배열을 만듭니다: . np.zeros(5) . array([0., 0., 0., 0., 0.]) . 2D 배열(즉, 행렬)을 만들려면 원하는 행과 열의 크기를 튜플로 전달합니다. 예를 들어 다음은 $3 times 4$ 크기의 행렬입니다: . np.zeros((3,4)) . array([[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.]]) . &#50857;&#50612; . 넘파이에서 각 차원을 축(axis) 이라고 합니다 | 축의 개수를 랭크(rank) 라고 합니다. 예를 들어, 위의 $3 times 4$ 행렬은 랭크 2인 배열입니다(즉 2차원입니다). | 첫 번째 축의 길이는 3이고 두 번째 축의 길이는 4입니다. | . | 배열의 축 길이를 배열의 크기(shape)라고 합니다. 예를 들어, 위 행렬의 크기는 (3, 4)입니다. | 랭크는 크기의 길이와 같습니다. | . | 배열의 사이즈(size)는 전체 원소의 개수입니다. 축의 길이를 모두 곱해서 구할 수 있습니다(가령, $3 times 4=12$). | . a = np.zeros((3,4)) a . array([[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.]]) . a.shape . (3, 4) . a.ndim # len(a.shape)와 같습니다 . 2 . a.size . 12 . N-&#52264;&#50896; &#48176;&#50676; . 임의의 랭크 수를 가진 N-차원 배열을 만들 수 있습니다. 예를 들어, 다음은 크기가 (2,3,4)인 3D 배열(랭크=3)입니다: . np.zeros((2,2,5)) . array([[[0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.]], [[0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.]]]) . &#48176;&#50676; &#53440;&#51077; . 넘파이 배열의 타입은 ndarray입니다: . type(np.zeros((3,4))) . numpy.ndarray . np.ones . ndarray를 만들 수 있는 넘파이 함수가 많습니다. . 다음은 1로 채워진 $3 times 4$ 크기의 행렬입니다: . np.ones((3,4)) . array([[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.]]) . np.full . 주어진 값으로 지정된 크기의 배열을 초기화합니다. 다음은 π로 채워진 $3 times 4$ 크기의 행렬입니다. . np.full((3,4), np.pi) . array([[3.14159265, 3.14159265, 3.14159265, 3.14159265], [3.14159265, 3.14159265, 3.14159265, 3.14159265], [3.14159265, 3.14159265, 3.14159265, 3.14159265]]) . np.empty . 초기화되지 않은 $2 times 3$ 크기의 배열을 만듭니다(배열의 내용은 예측이 불가능하며 메모리 상황에 따라 달라집니다): . np.empty((2,3)) . array([[9.6677106e-317, 0.0000000e+000, 0.0000000e+000], [0.0000000e+000, 0.0000000e+000, 0.0000000e+000]]) . np.array . array 함수는 파이썬 리스트를 사용하여 ndarray를 초기화합니다: . np.array([[1,2,3,4], [10, 20, 30, 40]]) . array([[ 1, 2, 3, 4], [10, 20, 30, 40]]) . np.arange . 파이썬의 기본 range 함수와 비슷한 넘파이 arange 함수를 사용하여 ndarray를 만들 수 있습니다: . np.arange(1, 5) . array([1, 2, 3, 4]) . 부동 소수도 가능합니다: . np.arange(1.0, 5.0) . array([1., 2., 3., 4.]) . 파이썬의 기본 range 함수처럼 건너 뛰는 정도를 지정할 수 있습니다: . np.arange(1, 5, 0.5) . array([1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5]) . 부동 소수를 사용하면 원소의 개수가 일정하지 않을 수 있습니다. 예를 들면 다음과 같습니다: . print(np.arange(0, 5/3, 1/3)) # 부동 소수 오차 때문에, 최댓값은 4/3 또는 5/3이 됩니다. print(np.arange(0, 5/3, 0.333333333)) print(np.arange(0, 5/3, 0.333333334)) . [0. 0.33333333 0.66666667 1. 1.33333333 1.66666667] [0. 0.33333333 0.66666667 1. 1.33333333 1.66666667] [0. 0.33333333 0.66666667 1. 1.33333334] . np.linspace . 이런 이유로 부동 소수를 사용할 땐 arange 대신에 linspace 함수를 사용하는 것이 좋습니다. linspace 함수는 지정된 개수만큼 두 값 사이를 나눈 배열을 반환합니다(arange와는 다르게 최댓값이 포함됩니다): . print(np.linspace(0, 5/3, 6)) . [0. 0.33333333 0.66666667 1. 1.33333333 1.66666667] . np.rand&#50752; np.randn . 넘파이의 random 모듈에는 ndarray를 랜덤한 값으로 초기화할 수 있는 함수들이 많이 있습니다. 예를 들어, 다음은 (균등 분포인) 0과 1사이의 랜덤한 부동 소수로 $3 times 4$ 행렬을 초기화합니다: . np.random.rand(3,4) . array([[0.37892456, 0.17966937, 0.38206837, 0.34922123], [0.80462136, 0.9845914 , 0.9416127 , 0.28305275], [0.21201033, 0.54891417, 0.03781613, 0.4369229 ]]) . 다음은 평균이 0이고 분산이 1인 일변량 정규 분포(가우시안 분포)에서 샘플링한 랜덤한 부동 소수를 담은 $3 times 4$ 행렬입니다: . np.random.randn(3,4) . array([[ 0.83811287, -0.57131751, -0.4381827 , 1.1485899 ], [ 1.45316084, -0.47259181, -1.23426057, -0.0669813 ], [ 1.01003549, 1.04381736, -0.93060038, 2.39043293]]) . 이 분포의 모양을 알려면 맷플롯립을 사용해 그려보는 것이 좋습니다(더 자세한 것은 맷플롯립 튜토리얼을 참고하세요): . %matplotlib inline import matplotlib.pyplot as plt . plt.hist(np.random.rand(100000), density=True, bins=100, histtype=&quot;step&quot;, color=&quot;blue&quot;, label=&quot;rand&quot;) plt.hist(np.random.randn(100000), density=True, bins=100, histtype=&quot;step&quot;, color=&quot;red&quot;, label=&quot;randn&quot;) plt.axis([-2.5, 2.5, 0, 1.1]) plt.legend(loc = &quot;upper left&quot;) plt.title(&quot;Random distributions&quot;) plt.xlabel(&quot;Value&quot;) plt.ylabel(&quot;Density&quot;) plt.show() . np.fromfunction . 함수를 사용하여 ndarray를 초기화할 수도 있습니다: . def my_function(z, y, x): return x + 10 * y + 100 * z np.fromfunction(my_function, (3, 2, 10)) . array([[[ 0., 1., 2., 3., 4., 5., 6., 7., 8., 9.], [ 10., 11., 12., 13., 14., 15., 16., 17., 18., 19.]], [[100., 101., 102., 103., 104., 105., 106., 107., 108., 109.], [110., 111., 112., 113., 114., 115., 116., 117., 118., 119.]], [[200., 201., 202., 203., 204., 205., 206., 207., 208., 209.], [210., 211., 212., 213., 214., 215., 216., 217., 218., 219.]]]) . 넘파이는 먼저 크기가 (3, 2, 10)인 세 개의 ndarray(차원마다 하나씩)를 만듭니다. 각 배열은 축을 따라 좌표 값과 같은 값을 가집니다. 예를 들어, z 축에 있는 배열의 모든 원소는 z-축의 값과 같습니다: . [[[ 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [ 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] [[ 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] [ 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]] [[ 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.] [ 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]]] . 위의 식 x + 10 * y + 100 * z에서 x, y, z는 사실 ndarray입니다(배열의 산술 연산에 대해서는 아래에서 설명합니다). 중요한 점은 함수 my_function이 원소마다 호출되는 것이 아니고 딱 한 번 호출된다는 점입니다. 그래서 매우 효율적으로 초기화할 수 있습니다. . &#48176;&#50676; &#45936;&#51060;&#53552; . dtype . 넘파이의 ndarray는 모든 원소가 동일한 타입(보통 숫자)을 가지기 때문에 효율적입니다. dtype 속성으로 쉽게 데이터 타입을 확인할 수 있습니다: . c = np.arange(1, 5) print(c.dtype, c) . int64 [1 2 3 4] . c = np.arange(1.0, 5.0) print(c.dtype, c) . float64 [1. 2. 3. 4.] . 넘파이가 데이터 타입을 결정하도록 내버려 두는 대신 dtype 매개변수를 사용해서 배열을 만들 때 명시적으로 지정할 수 있습니다: . d = np.arange(1, 5, dtype=np.complex64) print(d.dtype, d) . complex64 [1.+0.j 2.+0.j 3.+0.j 4.+0.j] . 가능한 데이터 타입은 int8, int16, int32, int64, uint8|16|32|64, float16|32|64, complex64|128가 있습니다. 전체 리스트는 온라인 문서를 참고하세요. . itemsize . itemsize 속성은 각 아이템의 크기(바이트)를 반환합니다: . e = np.arange(1, 5, dtype=np.complex64) e.itemsize . 8 . data &#48260;&#54140; . 배열의 데이터는 1차원 바이트 버퍼로 메모리에 저장됩니다. data 속성을 사용해 참조할 수 있습니다(사용할 일은 거의 없겠지만요). . f = np.array([[1,2],[1000, 2000]], dtype=np.int32) f.data . &lt;memory at 0x7f97929dd790&gt; . 파이썬 2에서는 f.data가 버퍼이고 파이썬 3에서는 memoryview입니다. . if (hasattr(f.data, &quot;tobytes&quot;)): data_bytes = f.data.tobytes() # python 3 else: data_bytes = memoryview(f.data).tobytes() # python 2 data_bytes . b&#39; x01 x00 x00 x00 x02 x00 x00 x00 xe8 x03 x00 x00 xd0 x07 x00 x00&#39; . 여러 개의 ndarray가 데이터 버퍼를 공유할 수 있습니다. 하나를 수정하면 다른 것도 바뀝니다. 잠시 후에 예를 살펴 보겠습니다. . &#48176;&#50676; &#53356;&#44592; &#48320;&#44221; . &#51088;&#49888;&#51012; &#48320;&#44221; . ndarray의 shape 속성을 지정하면 간단히 크기를 바꿀 수 있습니다. 배열의 원소 개수는 동일하게 유지됩니다. . g = np.arange(24) print(g) print(&quot;랭크:&quot;, g.ndim) . [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23] 랭크: 1 . g.shape = (6, 4) print(g) print(&quot;랭크:&quot;, g.ndim) . [[ 0 1 2 3] [ 4 5 6 7] [ 8 9 10 11] [12 13 14 15] [16 17 18 19] [20 21 22 23]] 랭크: 2 . g.shape = (2, 3, 4) print(g) print(&quot;랭크:&quot;, g.ndim) . [[[ 0 1 2 3] [ 4 5 6 7] [ 8 9 10 11]] [[12 13 14 15] [16 17 18 19] [20 21 22 23]]] 랭크: 3 . reshape . reshape 함수는 동일한 데이터를 가리키는 새로운 ndarray 객체를 반환합니다. 한 배열을 수정하면 다른 것도 함께 바뀝니다. . g2 = g.reshape(4,6) print(g2) print(&quot;랭크:&quot;, g2.ndim) . [[ 0 1 2 3 4 5] [ 6 7 8 9 10 11] [12 13 14 15 16 17] [18 19 20 21 22 23]] 랭크: 2 . 행 1, 열 2의 원소를 999로 설정합니다(인덱싱 방식은 아래를 참고하세요). . g2[1, 2] = 999 g2 . array([[ 0, 1, 2, 3, 4, 5], [ 6, 7, 999, 9, 10, 11], [ 12, 13, 14, 15, 16, 17], [ 18, 19, 20, 21, 22, 23]]) . 이에 상응하는 g의 원소도 수정됩니다. . g . array([[[ 0, 1, 2, 3], [ 4, 5, 6, 7], [999, 9, 10, 11]], [[ 12, 13, 14, 15], [ 16, 17, 18, 19], [ 20, 21, 22, 23]]]) . ravel . 마지막으로 ravel 함수는 동일한 데이터를 가리키는 새로운 1차원 ndarray를 반환합니다: . g.ravel() . array([ 0, 1, 2, 3, 4, 5, 6, 7, 999, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]) . &#49328;&#49696; &#50672;&#49328; . 일반적인 산술 연산자(+, -, *, /, //, ** 등)는 모두 ndarray와 사용할 수 있습니다. 이 연산자는 원소별로 적용됩니다: . a = np.array([14, 23, 32, 41]) b = np.array([5, 4, 3, 2]) print(&quot;a + b =&quot;, a + b) print(&quot;a - b =&quot;, a - b) print(&quot;a * b =&quot;, a * b) print(&quot;a / b =&quot;, a / b) print(&quot;a // b =&quot;, a // b) print(&quot;a % b =&quot;, a % b) print(&quot;a ** b =&quot;, a ** b) . a + b = [19 27 35 43] a - b = [ 9 19 29 39] a * b = [70 92 96 82] a / b = [ 2.8 5.75 10.66666667 20.5 ] a // b = [ 2 5 10 20] a % b = [4 3 2 1] a ** b = [537824 279841 32768 1681] . 여기 곱셈은 행렬 곱셈이 아닙니다. 행렬 연산은 아래에서 설명합니다. . 배열의 크기는 같아야 합니다. 그렇지 않으면 넘파이가 브로드캐스팅 규칙을 적용합니다. . &#48652;&#47196;&#46300;&#52880;&#49828;&#54021; . 일반적으로 넘파이는 동일한 크기의 배열을 기대합니다. 그렇지 않은 상황에는 브로드캐시틍 규칙을 적용합니다: . &#44508;&#52825; 1 . 배열의 랭크가 동일하지 않으면 랭크가 맞을 때까지 랭크가 작은 배열 앞에 1을 추가합니다. . h = np.arange(5).reshape(1, 1, 5) h . array([[[0, 1, 2, 3, 4]]]) . 여기에 (1,1,5) 크기의 3D 배열에 (5,) 크기의 1D 배열을 더해 보죠. 브로드캐스팅의 규칙 1이 적용됩니다! . h + [10, 20, 30, 40, 50] # 다음과 동일합니다: h + [[[10, 20, 30, 40, 50]]] . array([[[10, 21, 32, 43, 54]]]) . &#44508;&#52825; 2 . 특정 차원이 1인 배열은 그 차원에서 크기가 가장 큰 배열의 크기에 맞춰 동작합니다. 배열의 원소가 차원을 따라 반복됩니다. . k = np.arange(6).reshape(2, 3) k . array([[0, 1, 2], [3, 4, 5]]) . (2,3) 크기의 2D ndarray에 (2,1) 크기의 2D 배열을 더해 보죠. 넘파이는 브로드캐스팅 규칙 2를 적용합니다: . k + [[100], [200]] # 다음과 같습니다: k + [[100, 100, 100], [200, 200, 200]] . array([[100, 101, 102], [203, 204, 205]]) . 규칙 1과 2를 합치면 다음과 같이 동작합니다: . k + [100, 200, 300] # 규칙 1 적용: [[100, 200, 300]], 규칙 2 적용: [[100, 200, 300], [100, 200, 300]] . array([[100, 201, 302], [103, 204, 305]]) . 또 매우 간단히 다음 처럼 해도 됩니다: . k + 1000 # 다음과 같습니다: k + [[1000, 1000, 1000], [1000, 1000, 1000]] . array([[1000, 1001, 1002], [1003, 1004, 1005]]) . &#44508;&#52825; 3 . 규칙 1 &amp; 2을 적용했을 때 모든 배열의 크기가 맞아야 합니다. . try: k + [33, 44] except ValueError as e: print(e) . operands could not be broadcast together with shapes (2,3) (2,) . 브로드캐스팅 규칙은 산술 연산 뿐만 아니라 넘파이 연산에서 많이 사용됩니다. 아래에서 더 보도록 하죠. 브로드캐스팅에 관한 더 자세한 정보는 온라인 문서를 참고하세요. . &#50629;&#52880;&#49828;&#54021; . dtype이 다른 배열을 합칠 때 넘파이는 (실제 값에 상관없이) 모든 값을 다룰 수 있는 타입으로 업캐스팅합니다. . k1 = np.arange(0, 5, dtype=np.uint8) print(k1.dtype, k1) . uint8 [0 1 2 3 4] . k2 = k1 + np.array([5, 6, 7, 8, 9], dtype=np.int8) print(k2.dtype, k2) . int16 [ 5 7 9 11 13] . 모든 int8과 uint8 값(-128에서 255까지)을 표현하기 위해 int16이 필요합니다. 이 코드에서는 uint8이면 충분하지만 업캐스팅되었습니다. . k3 = k1 + 1.5 print(k3.dtype, k3) . float64 [1.5 2.5 3.5 4.5 5.5] . &#51312;&#44148; &#50672;&#49328;&#51088; . 조건 연산자도 원소별로 적용됩니다: . m = np.array([20, -5, 30, 40]) m &lt; [15, 16, 35, 36] . array([False, True, True, False]) . 브로드캐스팅을 사용합니다: . m &lt; 25 # m &lt; [25, 25, 25, 25] 와 동일 . array([ True, True, False, False]) . 불리언 인덱싱과 함께 사용하면 아주 유용합니다(아래에서 설명하겠습니다). . m[m &lt; 25] . array([20, -5]) . &#49688;&#54617; &#54632;&#49688;&#50752; &#53685;&#44228; &#54632;&#49688; . ndarray에서 사용할 수 있는 수학 함수와 통계 함수가 많습니다. . ndarray &#47700;&#49436;&#46300; . 일부 함수는 ndarray 메서드로 제공됩니다. 예를 들면: . a = np.array([[-2.5, 3.1, 7], [10, 11, 12]]) print(a) print(&quot;평균 =&quot;, a.mean()) . [[-2.5 3.1 7. ] [10. 11. 12. ]] 평균 = 6.766666666666667 . 이 명령은 크기에 상관없이 ndarray에 있는 모든 원소의 평균을 계산합니다. . 다음은 유용한 ndarray 메서드입니다: . for func in (a.min, a.max, a.sum, a.prod, a.std, a.var): print(func.__name__, &quot;=&quot;, func()) . min = -2.5 max = 12.0 sum = 40.6 prod = -71610.0 std = 5.084835843520964 var = 25.855555555555554 . 이 함수들은 선택적으로 매개변수 axis를 사용합니다. 지정된 축을 따라 원소에 연산을 적용하는데 사용합니다. 예를 들면: . c=np.arange(24).reshape(2,3,4) c . array([[[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]], [[12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23]]]) . c.sum(axis=0) # 첫 번째 축을 따라 더함, 결과는 3x4 배열 . array([[12, 14, 16, 18], [20, 22, 24, 26], [28, 30, 32, 34]]) . c.sum(axis=1) # 두 번째 축을 따라 더함, 결과는 2x4 배열 . array([[12, 15, 18, 21], [48, 51, 54, 57]]) . 여러 축에 대해서 더할 수도 있습니다: . c.sum(axis=(0,2)) # 첫 번째 축과 세 번째 축을 따라 더함, 결과는 (3,) 배열 . array([ 60, 92, 124]) . 0+1+2+3 + 12+13+14+15, 4+5+6+7 + 16+17+18+19, 8+9+10+11 + 20+21+22+23 . (60, 92, 124) . &#51068;&#48152; &#54632;&#49688; . 넘파이는 일반 함수(universal function) 또는 ufunc라고 부르는 원소별 함수를 제공합니다. 예를 들면 square 함수는 원본 ndarray를 복사하여 각 원소를 제곱한 새로운 ndarray 객체를 반환합니다: . a = np.array([[-2.5, 3.1, 7], [10, 11, 12]]) np.square(a) . array([[ 6.25, 9.61, 49. ], [100. , 121. , 144. ]]) . 다음은 유용한 단항 일반 함수들입니다: . print(&quot;원본 ndarray&quot;) print(a) for func in (np.abs, np.sqrt, np.exp, np.log, np.sign, np.ceil, np.modf, np.isnan, np.cos): print(&quot; n&quot;, func.__name__) print(func(a)) . 원본 ndarray [[-2.5 3.1 7. ] [10. 11. 12. ]] absolute [[ 2.5 3.1 7. ] [10. 11. 12. ]] sqrt [[ nan 1.76068169 2.64575131] [3.16227766 3.31662479 3.46410162]] exp [[8.20849986e-02 2.21979513e+01 1.09663316e+03] [2.20264658e+04 5.98741417e+04 1.62754791e+05]] log [[ nan 1.13140211 1.94591015] [2.30258509 2.39789527 2.48490665]] sign [[-1. 1. 1.] [ 1. 1. 1.]] ceil [[-2. 4. 7.] [10. 11. 12.]] modf (array([[-0.5, 0.1, 0. ], [ 0. , 0. , 0. ]]), array([[-2., 3., 7.], [10., 11., 12.]])) isnan [[False False False] [False False False]] cos [[-0.80114362 -0.99913515 0.75390225] [-0.83907153 0.0044257 0.84385396]] . &lt;ipython-input-59-d791c8e37e6f&gt;:5: RuntimeWarning: invalid value encountered in sqrt print(func(a)) &lt;ipython-input-59-d791c8e37e6f&gt;:5: RuntimeWarning: invalid value encountered in log print(func(a)) . &#51060;&#54637; &#51068;&#48152; &#54632;&#49688; . 두 개의 ndarray에 원소별로 적용되는 이항 함수도 많습니다. 두 배열이 동일한 크기가 아니면 브로드캐스팅 규칙이 적용됩니다: . a = np.array([1, -2, 3, 4]) b = np.array([2, 8, -1, 7]) np.add(a, b) # a + b 와 동일 . array([ 3, 6, 2, 11]) . np.greater(a, b) # a &gt; b 와 동일 . array([False, False, True, False]) . np.maximum(a, b) . array([2, 8, 3, 7]) . np.copysign(a, b) . array([ 1., 2., -3., 4.]) . &#48176;&#50676; &#51064;&#45937;&#49905; . 1&#52264;&#50896; &#48176;&#50676; . 1차원 넘파이 배열은 보통의 파이썬 배열과 비슷하게 사용할 수 있습니다: . a = np.array([1, 5, 3, 19, 13, 7, 3]) a[3] . 19 . a[2:5] . array([ 3, 19, 13]) . a[2:-1] . array([ 3, 19, 13, 7]) . a[:2] . array([1, 5]) . a[2::2] . array([ 3, 13, 3]) . a[::-1] . array([ 3, 7, 13, 19, 3, 5, 1]) . 물론 원소를 수정할 수 있죠: . a[3]=999 a . array([ 1, 5, 3, 999, 13, 7, 3]) . 슬라이싱을 사용해 ndarray를 수정할 수 있습니다: . a[2:5] = [997, 998, 999] a . array([ 1, 5, 997, 998, 999, 7, 3]) . &#48372;&#53685;&#51032; &#54028;&#51060;&#50028; &#48176;&#50676;&#44284; &#52264;&#51060;&#51216; . 보통의 파이썬 배열과 대조적으로 ndarray 슬라이싱에 하나의 값을 할당하면 슬라이싱 전체에 복사됩니다. 위에서 언급한 브로드캐스팅 덕택입니다. . a[2:5] = -1 a . array([ 1, 5, -1, -1, -1, 7, 3]) . 또한 이런 식으로 ndarray 크기를 늘리거나 줄일 수 없습니다: . try: a[2:5] = [1,2,3,4,5,6] # 너무 길어요 except ValueError as e: print(e) . cannot copy sequence with size 6 to array axis with dimension 3 . 원소를 삭제할 수도 없습니다: . try: del a[2:5] except ValueError as e: print(e) . cannot delete array elements . 중요한 점은 ndarray의 슬라이싱은 같은 데이터 버퍼를 바라보는 뷰(view)입니다. 슬라이싱된 객체를 수정하면 실제 원본 ndarray가 수정됩니다! . a_slice = a[2:6] a_slice[1] = 1000 a # 원본 배열이 수정됩니다! . array([ 1, 5, -1, 1000, -1, 7, 3]) . a[3] = 2000 a_slice # 비슷하게 원본 배열을 수정하면 슬라이싱 객체에도 반영됩니다! . array([ -1, 2000, -1, 7]) . 데이터를 복사하려면 copy 메서드를 사용해야 합니다: . another_slice = a[2:6].copy() another_slice[1] = 3000 a # 원본 배열이 수정되지 않습니다 . array([ 1, 5, -1, 2000, -1, 7, 3]) . a[3] = 4000 another_slice # 마찬가지로 원본 배열을 수정해도 복사된 배열은 바뀌지 않습니다 . array([ -1, 3000, -1, 7]) . &#45796;&#52264;&#50896; &#48176;&#50676; . 다차원 배열은 비슷한 방식으로 각 축을 따라 인덱싱 또는 슬라이싱해서 사용합니다. 콤마로 구분합니다: . b = np.arange(48).reshape(4, 12) b . array([[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], [36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]]) . b[1, 2] # 행 1, 열 2 . 14 . b[1, :] # 행 1, 모든 열 . array([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]) . b[:, 1] # 모든 행, 열 1 . array([ 1, 13, 25, 37]) . 주의: 다음 두 표현에는 미묘한 차이가 있습니다: . b[1, :] . array([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]) . b[1:2, :] . array([[12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]]) . 첫 번째 표현식은 (12,) 크기인 1D 배열로 행이 하나입니다. 두 번째는 (1, 12) 크기인 2D 배열로 같은 행을 반환합니다. . &#54060;&#49884; &#51064;&#45937;&#49905;(Fancy indexing) . 관심 대상의 인덱스 리스트를 지정할 수도 있습니다. 이를 팬시 인덱싱이라고 부릅니다. . b[(0,2), 2:5] # 행 0과 2, 열 2에서 4(5-1)까지 . array([[ 2, 3, 4], [26, 27, 28]]) . b[:, (-1, 2, -1)] # 모든 행, 열 -1 (마지막), 2와 -1 (다시 반대 방향으로) . array([[11, 2, 11], [23, 14, 23], [35, 26, 35], [47, 38, 47]]) . 여러 개의 인덱스 리스트를 지정하면 인덱스에 맞는 값이 포함된 1D ndarray를 반환됩니다. . b[(-1, 2, -1, 2), (5, 9, 1, 9)] # returns a 1D array with b[-1, 5], b[2, 9], b[-1, 1] and b[2, 9] (again) . array([41, 33, 37, 33]) . &#44256;&#52264;&#50896; . 고차원에서도 동일한 방식이 적용됩니다. 몇 가지 예를 살펴 보겠습니다: . c = b.reshape(4,2,6) c . array([[[ 0, 1, 2, 3, 4, 5], [ 6, 7, 8, 9, 10, 11]], [[12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23]], [[24, 25, 26, 27, 28, 29], [30, 31, 32, 33, 34, 35]], [[36, 37, 38, 39, 40, 41], [42, 43, 44, 45, 46, 47]]]) . c[2, 1, 4] # 행렬 2, 행 1, 열 4 . 34 . c[2, :, 3] # 행렬 2, 모든 행, 열 3 . array([27, 33]) . 어떤 축에 대한 인덱스를 지정하지 않으면 이 축의 모든 원소가 반환됩니다: . c[2, 1] # 행렬 2, 행 1, 모든 열이 반환됩니다. c[2, 1, :]와 동일합니다. . array([30, 31, 32, 33, 34, 35]) . &#49373;&#47029; &#48512;&#54840; (...) . 생략 부호(...)를 쓰면 모든 지정하지 않은 축의 원소를 포함합니다. . c[2, ...] # 행렬 2, 모든 행, 모든 열. c[2, :, :]와 동일 . array([[24, 25, 26, 27, 28, 29], [30, 31, 32, 33, 34, 35]]) . c[2, 1, ...] # 행렬 2, 행 1, 모든 열. c[2, 1, :]와 동일 . array([30, 31, 32, 33, 34, 35]) . c[2, ..., 3] # 행렬 2, 모든 행, 열 3. c[2, :, 3]와 동일 . array([27, 33]) . c[..., 3] # 모든 행렬, 모든 행, 열 3. c[:, :, 3]와 동일 . array([[ 3, 9], [15, 21], [27, 33], [39, 45]]) . &#48520;&#47532;&#50616; &#51064;&#45937;&#49905; . 불리언 값을 가진 ndarray를 사용해 축의 인덱스를 지정할 수 있습니다. . b = np.arange(48).reshape(4, 12) b . array([[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], [36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]]) . rows_on = np.array([True, False, True, False]) b[rows_on, :] # 행 0과 2, 모든 열. b[(0, 2), :]와 동일 . array([[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]]) . cols_on = np.array([False, True, False] * 4) b[:, cols_on] # 모든 행, 열 1, 4, 7, 10 . array([[ 1, 4, 7, 10], [13, 16, 19, 22], [25, 28, 31, 34], [37, 40, 43, 46]]) . np.ix_ . 여러 축에 걸쳐서는 불리언 인덱싱을 사용할 수 없고 ix_ 함수를 사용합니다: . b[np.ix_(rows_on, cols_on)] . array([[ 1, 4, 7, 10], [25, 28, 31, 34]]) . np.ix_(rows_on, cols_on) . (array([[0], [2]]), array([[ 1, 4, 7, 10]])) . ndarray와 같은 크기의 불리언 배열을 사용하면 해당 위치가 True인 모든 원소를 담은 1D 배열이 반환됩니다. 일반적으로 조건 연산자와 함께 사용합니다: . b[b % 3 == 1] . array([ 1, 4, 7, 10, 13, 16, 19, 22, 25, 28, 31, 34, 37, 40, 43, 46]) . &#48152;&#48373; . ndarray를 반복하는 것은 일반적인 파이썬 배열을 반복한는 것과 매우 유사합니다. 다차원 배열을 반복하면 첫 번째 축에 대해서 수행됩니다. . c = np.arange(24).reshape(2, 3, 4) # 3D 배열 (두 개의 3x4 행렬로 구성됨) c . array([[[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]], [[12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23]]]) . for m in c: print(&quot;아이템:&quot;) print(m) . 아이템: [[ 0 1 2 3] [ 4 5 6 7] [ 8 9 10 11]] 아이템: [[12 13 14 15] [16 17 18 19] [20 21 22 23]] . for i in range(len(c)): # len(c) == c.shape[0] print(&quot;아이템:&quot;) print(c[i]) . 아이템: [[ 0 1 2 3] [ 4 5 6 7] [ 8 9 10 11]] 아이템: [[12 13 14 15] [16 17 18 19] [20 21 22 23]] . ndarray에 있는 모든 원소를 반복하려면 flat 속성을 사용합니다: . for i in c.flat: print(&quot;아이템:&quot;, i) . 아이템: 0 아이템: 1 아이템: 2 아이템: 3 아이템: 4 아이템: 5 아이템: 6 아이템: 7 아이템: 8 아이템: 9 아이템: 10 아이템: 11 아이템: 12 아이템: 13 아이템: 14 아이템: 15 아이템: 16 아이템: 17 아이템: 18 아이템: 19 아이템: 20 아이템: 21 아이템: 22 아이템: 23 . &#48176;&#50676; &#49939;&#44592; . 종종 다른 배열을 쌓아야 할 때가 있습니다. 넘파이는 이를 위해 몇 개의 함수를 제공합니다. 먼저 배열 몇 개를 만들어 보죠. . q1 = np.full((3,4), 1.0) q1 . array([[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.]]) . q2 = np.full((4,4), 2.0) q2 . array([[2., 2., 2., 2.], [2., 2., 2., 2.], [2., 2., 2., 2.], [2., 2., 2., 2.]]) . q3 = np.full((3,4), 3.0) q3 . array([[3., 3., 3., 3.], [3., 3., 3., 3.], [3., 3., 3., 3.]]) . vstack . vstack 함수를 사용하여 수직으로 쌓아보죠: . q4 = np.vstack((q1, q2, q3)) q4 . array([[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.], [2., 2., 2., 2.], [2., 2., 2., 2.], [2., 2., 2., 2.], [2., 2., 2., 2.], [3., 3., 3., 3.], [3., 3., 3., 3.], [3., 3., 3., 3.]]) . q4.shape . (10, 4) . q1, q2, q3가 모두 같은 크기이므로 가능합니다(수직으로 쌓기 때문에 수직 축은 크기가 달라도 됩니다). . hstack . hstack을 사용해 수평으로도 쌓을 수 있습니다: . q5 = np.hstack((q1, q3)) q5 . array([[1., 1., 1., 1., 3., 3., 3., 3.], [1., 1., 1., 1., 3., 3., 3., 3.], [1., 1., 1., 1., 3., 3., 3., 3.]]) . q5.shape . (3, 8) . q1과 q3가 모두 3개의 행을 가지고 있기 때문에 가능합니다. q2는 4개의 행을 가지고 있기 때문에 q1, q3와 수평으로 쌓을 수 없습니다: . try: q5 = np.hstack((q1, q2, q3)) except ValueError as e: print(e) . all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 3 and the array at index 1 has size 4 . concatenate . concatenate 함수는 지정한 축으로도 배열을 쌓습니다. . q7 = np.concatenate((q1, q2, q3), axis=0) # vstack과 동일 q7 . array([[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.], [2., 2., 2., 2.], [2., 2., 2., 2.], [2., 2., 2., 2.], [2., 2., 2., 2.], [3., 3., 3., 3.], [3., 3., 3., 3.], [3., 3., 3., 3.]]) . q7.shape . (10, 4) . 예상했겠지만 hstack은 axis=1으로 concatenate를 호출하는 것과 같습니다. . stack . stack 함수는 새로운 축을 따라 배열을 쌓습니다. 모든 배열은 같은 크기를 가져야 합니다. . q8 = np.stack((q1, q3)) q8 . array([[[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.]], [[3., 3., 3., 3.], [3., 3., 3., 3.], [3., 3., 3., 3.]]]) . q8.shape . (2, 3, 4) . &#48176;&#50676; &#48516;&#54624; . 분할은 쌓기의 반대입니다. 예를 들어 vsplit 함수는 행렬을 수직으로 분할합니다. . 먼저 6x4 행렬을 만들어 보죠: . r = np.arange(24).reshape(6,4) r . array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23]]) . 수직으로 동일한 크기로 나누어 보겠습니다: . r1, r2, r3 = np.vsplit(r, 3) r1 . array([[0, 1, 2, 3], [4, 5, 6, 7]]) . r2 . array([[ 8, 9, 10, 11], [12, 13, 14, 15]]) . r3 . array([[16, 17, 18, 19], [20, 21, 22, 23]]) . split 함수는 주어진 축을 따라 배열을 분할합니다. vsplit는 axis=0으로 split를 호출하는 것과 같습니다. hsplit 함수는 axis=1로 split를 호출하는 것과 같습니다: . r4, r5 = np.hsplit(r, 2) r4 . array([[ 0, 1], [ 4, 5], [ 8, 9], [12, 13], [16, 17], [20, 21]]) . r5 . array([[ 2, 3], [ 6, 7], [10, 11], [14, 15], [18, 19], [22, 23]]) . &#48176;&#50676; &#51204;&#52824; . transpose 메서드는 주어진 순서대로 축을 뒤바꾸어 ndarray 데이터에 대한 새로운 뷰를 만듭니다. . 예를 위해 3D 배열을 만들어 보죠: . t = np.arange(24).reshape(4,2,3) t . array([[[ 0, 1, 2], [ 3, 4, 5]], [[ 6, 7, 8], [ 9, 10, 11]], [[12, 13, 14], [15, 16, 17]], [[18, 19, 20], [21, 22, 23]]]) . 0, 1, 2(깊이, 높이, 너비) 축을 1, 2, 0 (깊이→너비, 높이→깊이, 너비→높이) 순서로 바꾼 ndarray를 만들어 보겠습니다: . t1 = t.transpose((1,2,0)) t1 . array([[[ 0, 6, 12, 18], [ 1, 7, 13, 19], [ 2, 8, 14, 20]], [[ 3, 9, 15, 21], [ 4, 10, 16, 22], [ 5, 11, 17, 23]]]) . t1.shape . (2, 3, 4) . transpose 기본값은 차원의 순서를 역전시킵니다: . t2 = t.transpose() # t.transpose((2, 1, 0))와 동일 t2 . array([[[ 0, 6, 12, 18], [ 3, 9, 15, 21]], [[ 1, 7, 13, 19], [ 4, 10, 16, 22]], [[ 2, 8, 14, 20], [ 5, 11, 17, 23]]]) . t2.shape . (3, 2, 4) . 넘파이는 두 축을 바꾸는 swapaxes 함수를 제공합니다. 예를 들어 깊이와 높이를 뒤바꾸어 t의 새로운 뷰를 만들어 보죠: . t3 = t.swapaxes(0,1) # t.transpose((1, 0, 2))와 동일 t3 . array([[[ 0, 1, 2], [ 6, 7, 8], [12, 13, 14], [18, 19, 20]], [[ 3, 4, 5], [ 9, 10, 11], [15, 16, 17], [21, 22, 23]]]) . t3.shape . (2, 4, 3) . &#49440;&#54805; &#45824;&#49688;&#54617; . 넘파이 2D 배열을 사용하면 파이썬에서 행렬을 효율적으로 표현할 수 있습니다. 주요 행렬 연산을 간단히 둘러 보겠습니다. 선형 대수학, 벡터와 행렬에 관한 자세한 내용은 Linear Algebra tutorial를 참고하세요. . &#54665;&#47148; &#51204;&#52824; . T 속성은 랭크가 2보다 크거나 같을 때 transpose()를 호출하는 것과 같습니다: . m1 = np.arange(10).reshape(2,5) m1 . array([[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]) . m1.T . array([[0, 5], [1, 6], [2, 7], [3, 8], [4, 9]]) . T 속성은 랭크가 0이거나 1인 배열에는 아무런 영향을 미치지 않습니다: . m2 = np.arange(5) m2 . array([0, 1, 2, 3, 4]) . m2.T . array([0, 1, 2, 3, 4]) . 먼저 1D 배열을 하나의 행이 있는 행렬(2D)로 바꾼다음 전치를 수행할 수 있습니다: . m2r = m2.reshape(1,5) m2r . array([[0, 1, 2, 3, 4]]) . m2r.T . array([[0], [1], [2], [3], [4]]) . &#54665;&#47148; &#44273;&#49480; . 두 개의 행렬을 만들어 dot 메서드로 행렬 곱셈을 실행해 보죠. . n1 = np.arange(10).reshape(2, 5) n1 . array([[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]) . n2 = np.arange(15).reshape(5,3) n2 . array([[ 0, 1, 2], [ 3, 4, 5], [ 6, 7, 8], [ 9, 10, 11], [12, 13, 14]]) . n1.dot(n2) . array([[ 90, 100, 110], [240, 275, 310]]) . 주의: 앞서 언급한 것처럼 n1*n2는 행렬 곱셈이 아니라 원소별 곱셈(또는 아다마르 곱이라 부릅니다)입니다. . &#50669;&#54665;&#47148;&#44284; &#50976;&#49324; &#50669;&#54665;&#47148; . numpy.linalg 모듈 안에 많은 선형 대수 함수들이 있습니다. 특히 inv 함수는 정방 행렬의 역행렬을 계산합니다: . import numpy.linalg as linalg m3 = np.array([[1,2,3],[5,7,11],[21,29,31]]) m3 . array([[ 1, 2, 3], [ 5, 7, 11], [21, 29, 31]]) . linalg.inv(m3) . array([[-2.31818182, 0.56818182, 0.02272727], [ 1.72727273, -0.72727273, 0.09090909], [-0.04545455, 0.29545455, -0.06818182]]) . pinv 함수를 사용하여 유사 역행렬을 계산할 수도 있습니다: . linalg.pinv(m3) . array([[-2.31818182, 0.56818182, 0.02272727], [ 1.72727273, -0.72727273, 0.09090909], [-0.04545455, 0.29545455, -0.06818182]]) . &#45800;&#50948; &#54665;&#47148; . 행렬과 그 행렬의 역행렬을 곱하면 단위 행렬이 됩니다(작은 소숫점 오차가 있습니다): . m3.dot(linalg.inv(m3)) . array([[ 1.00000000e+00, -1.66533454e-16, 0.00000000e+00], [ 6.31439345e-16, 1.00000000e+00, -1.38777878e-16], [ 5.21110932e-15, -2.38697950e-15, 1.00000000e+00]]) . eye 함수는 NxN 크기의 단위 행렬을 만듭니다: . np.eye(3) . array([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]]) . QR &#48516;&#54644; . qr 함수는 행렬을 QR 분해합니다: . q, r = linalg.qr(m3) q . array([[-0.04627448, 0.98786672, 0.14824986], [-0.23137241, 0.13377362, -0.96362411], [-0.97176411, -0.07889213, 0.22237479]]) . r . array([[-21.61018278, -29.89331494, -32.80860727], [ 0. , 0.62427688, 1.9894538 ], [ 0. , 0. , -3.26149699]]) . q.dot(r) # q.r는 m3와 같습니다 . array([[ 1., 2., 3.], [ 5., 7., 11.], [21., 29., 31.]]) . &#54665;&#47148;&#49885; . det 함수는 행렬식을 계산합니다: . linalg.det(m3) # 행렬식 계산 . 43.99999999999997 . &#44256;&#50995;&#44050;&#44284; &#44256;&#50976;&#48289;&#53552; . eig 함수는 정방 행렬의 고윳값과 고유벡터를 계산합니다: . eigenvalues, eigenvectors = linalg.eig(m3) eigenvalues # λ . array([42.26600592, -0.35798416, -2.90802176]) . eigenvectors # v . array([[-0.08381182, -0.76283526, -0.18913107], [-0.3075286 , 0.64133975, -0.6853186 ], [-0.94784057, -0.08225377, 0.70325518]]) . m3.dot(eigenvectors) - eigenvalues * eigenvectors # m3.v - λ*v = 0 . array([[ 8.88178420e-15, 2.22044605e-16, -3.10862447e-15], [ 3.55271368e-15, 2.02615702e-15, -1.11022302e-15], [ 3.55271368e-14, 3.33413852e-15, -8.43769499e-15]]) . &#53945;&#51079;&#44050; &#48516;&#54644; . svd 함수는 행렬을 입력으로 받아 그 행렬의 특잇값 분해를 반환합니다: . m4 = np.array([[1,0,0,0,2], [0,0,3,0,0], [0,0,0,0,0], [0,2,0,0,0]]) m4 . array([[1, 0, 0, 0, 2], [0, 0, 3, 0, 0], [0, 0, 0, 0, 0], [0, 2, 0, 0, 0]]) . U, S_diag, V = linalg.svd(m4) U . array([[ 0., 1., 0., 0.], [ 1., 0., 0., 0.], [ 0., 0., 0., -1.], [ 0., 0., 1., 0.]]) . S_diag . array([3. , 2.23606798, 2. , 0. ]) . svd 함수는 Σ의 대각 원소 값만 반환합니다. 전체 Σ 행렬은 다음과 같이 만듭니다: . S = np.zeros((4, 5)) S[np.diag_indices(4)] = S_diag S # Σ . array([[3. , 0. , 0. , 0. , 0. ], [0. , 2.23606798, 0. , 0. , 0. ], [0. , 0. , 2. , 0. , 0. ], [0. , 0. , 0. , 0. , 0. ]]) . V . array([[-0. , 0. , 1. , -0. , 0. ], [ 0.4472136 , 0. , 0. , 0. , 0.89442719], [-0. , 1. , 0. , -0. , 0. ], [ 0. , 0. , 0. , 1. , 0. ], [-0.89442719, 0. , 0. , 0. , 0.4472136 ]]) . U.dot(S).dot(V) # U.Σ.V == m4 . array([[1., 0., 0., 0., 2.], [0., 0., 3., 0., 0.], [0., 0., 0., 0., 0.], [0., 2., 0., 0., 0.]]) . &#45824;&#44033;&#50896;&#49548;&#50752; &#45824;&#44033;&#54633; . np.diag(m3) # m3의 대각 원소입니다(왼쪽 위에서 오른쪽 아래) . array([ 1, 7, 31]) . np.trace(m3) # np.diag(m3).sum()와 같습니다 . 39 . &#49440;&#54805; &#48169;&#51221;&#49885; &#54400;&#44592; . solve 함수는 다음과 같은 선형 방정식을 풉니다: . $2x + 6y = 6$ | $5x + 3y = -9$ | . coeffs = np.array([[2, 6], [5, 3]]) depvars = np.array([6, -9]) solution = linalg.solve(coeffs, depvars) solution . array([-3., 2.]) . solution을 확인해 보죠: . coeffs.dot(solution), depvars # 네 같네요 . (array([ 6., -9.]), array([ 6, -9])) . 좋습니다! 다른 방식으로도 solution을 확인해 보죠: . np.allclose(coeffs.dot(solution), depvars) . True . &#48289;&#53552;&#54868; . 한 번에 하나씩 개별 배열 원소에 대해 연산을 실행하는 대신 배열 연산을 사용하면 훨씬 효율적인 코드를 만들 수 있습니다. 이를 벡터화라고 합니다. 이를 사용하여 넘파이의 최적화된 성능을 활용할 수 있습니다. . 예를 들어, $sin(xy/40.5)$ 식을 기반으로 768x1024 크기 배열을 생성하려고 합니다. 중첩 반복문 안에 파이썬의 math 함수를 사용하는 것은 나쁜 방법입니다: . import math data = np.empty((768, 1024)) for y in range(768): for x in range(1024): data[y, x] = math.sin(x*y/40.5) # 매우 비효율적입니다! . 작동은 하지만 순수한 파이썬 코드로 반복문이 진행되기 때문에 아주 비효율적입니다. 이 알고리즘을 벡터화해 보죠. 먼저 넘파이 meshgrid 함수로 좌표 벡터를 사용해 행렬을 만듭니다. . x_coords = np.arange(0, 1024) # [0, 1, 2, ..., 1023] y_coords = np.arange(0, 768) # [0, 1, 2, ..., 767] X, Y = np.meshgrid(x_coords, y_coords) X . array([[ 0, 1, 2, ..., 1021, 1022, 1023], [ 0, 1, 2, ..., 1021, 1022, 1023], [ 0, 1, 2, ..., 1021, 1022, 1023], ..., [ 0, 1, 2, ..., 1021, 1022, 1023], [ 0, 1, 2, ..., 1021, 1022, 1023], [ 0, 1, 2, ..., 1021, 1022, 1023]]) . Y . array([[ 0, 0, 0, ..., 0, 0, 0], [ 1, 1, 1, ..., 1, 1, 1], [ 2, 2, 2, ..., 2, 2, 2], ..., [765, 765, 765, ..., 765, 765, 765], [766, 766, 766, ..., 766, 766, 766], [767, 767, 767, ..., 767, 767, 767]]) . 여기서 볼 수 있듯이 X와 Y 모두 768x1024 배열입니다. X에 있는 모든 값은 수평 좌표에 해당합니다. Y에 있는 모든 값은 수직 좌표에 해당합니다. . 이제 간단히 배열 연산을 사용해 계산할 수 있습니다: . data = np.sin(X*Y/40.5) . 맷플롯립의 imshow 함수를 사용해 이 데이터를 그려보죠(matplotlib tutorial을 참조하세요). . import matplotlib.pyplot as plt import matplotlib.cm as cm fig = plt.figure(1, figsize=(7, 6)) plt.imshow(data, cmap=cm.hot) plt.show() . &#51200;&#51109;&#44284; &#47196;&#46377; . 넘파이는 ndarray를 바이너리 또는 텍스트 포맷으로 손쉽게 저장하고 로드할 수 있습니다. . &#48148;&#51060;&#45320;&#47532; .npy &#54252;&#47607; . 랜덤 배열을 만들고 저장해 보죠. . a = np.random.rand(2,3) a . array([[0.5435938 , 0.92886307, 0.01535158], [0.4157283 , 0.9102127 , 0.55129708]]) . np.save(&quot;my_array&quot;, a) . 끝입니다! 파일 이름의 확장자를 지정하지 않았기 때문에 넘파이는 자동으로 .npy를 붙입니다. 파일 내용을 확인해 보겠습니다: . with open(&quot;my_array.npy&quot;, &quot;rb&quot;) as f: content = f.read() content . b&#34; x93NUMPY x01 x00v x00{&#39;descr&#39;: &#39;&lt;f8&#39;, &#39;fortran_order&#39;: False, &#39;shape&#39;: (2, 3), } nY xc1 xfc xd0 x1ee xe1? xde{3 t? xb9 xed? x80V x08 xef xa5p x8f? x96I} xe0J x9b xda? xe0U xfaav xed? xd8 xe50 xc59 xa4 xe1?&#34; . 이 파일을 넘파이 배열로 로드하려면 load 함수를 사용합니다: . a_loaded = np.load(&quot;my_array.npy&quot;) a_loaded . array([[0.5435938 , 0.92886307, 0.01535158], [0.4157283 , 0.9102127 , 0.55129708]]) . &#53581;&#49828;&#53944; &#54252;&#47607; . 배열을 텍스트 포맷으로 저장해 보죠: . np.savetxt(&quot;my_array.csv&quot;, a) . 파일 내용을 확인해 보겠습니다: . with open(&quot;my_array.csv&quot;, &quot;rt&quot;) as f: print(f.read()) . 5.435937959464737235e-01 9.288630656918674955e-01 1.535157809943688001e-02 4.157283012656532994e-01 9.102126992826775620e-01 5.512970782648904944e-01 . 이 파일은 탭으로 구분된 CSV 파일입니다. 다른 구분자를 지정할 수도 있습니다: . np.savetxt(&quot;my_array.csv&quot;, a, delimiter=&quot;,&quot;) . 이 파일을 로드하려면 loadtxt 함수를 사용합니다: . a_loaded = np.loadtxt(&quot;my_array.csv&quot;, delimiter=&quot;,&quot;) a_loaded . array([[0.5435938 , 0.92886307, 0.01535158], [0.4157283 , 0.9102127 , 0.55129708]]) . &#50517;&#52629;&#46108; .npz &#54252;&#47607; . 여러 개의 배열을 압축된 한 파일로 저장하는 것도 가능합니다: . b = np.arange(24, dtype=np.uint8).reshape(2, 3, 4) b . array([[[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]], [[12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23]]], dtype=uint8) . np.savez(&quot;my_arrays&quot;, my_a=a, my_b=b) . 파일 내용을 확인해 보죠. .npz 파일 확장자가 자동으로 추가되었습니다. . with open(&quot;my_arrays.npz&quot;, &quot;rb&quot;) as f: content = f.read() repr(content)[:180] + &quot;[...]&quot; . &#39;b&#34;PK x03 x04 x14 x00 x00 x00 x00 x00 x00 x00! x00 x063 xcf xb9 xb0 x00 x00 x00 xb0 x00 x00 x00 x08 x00 x14 x00my_a.npy x01 x00 x10 x00 xb0 x00 x00 x00 x00 x00 x00 x00 xb0 x00 x00 x[...]&#39; . 다음과 같이 이 파일을 로드할 수 있습니다: . my_arrays = np.load(&quot;my_arrays.npz&quot;) my_arrays . &lt;numpy.lib.npyio.NpzFile at 0x7f9791c73d60&gt; . 게으른 로딩을 수행하는 딕셔너리와 유사한 객체입니다: . my_arrays.keys() . KeysView(&lt;numpy.lib.npyio.NpzFile object at 0x7f9791c73d60&gt;) . my_arrays[&quot;my_a&quot;] . array([[0.5435938 , 0.92886307, 0.01535158], [0.4157283 , 0.9102127 , 0.55129708]]) . &#44536; &#45796;&#51020;&#51008;? . 넘파이 기본 요소를 모두 배웠지만 훨씬 더 많은 기능이 있습니다. 이를 배우는 가장 좋은 방법은 넘파이를 직접 실습해 보고 훌륭한 넘파이 문서에서 필요한 함수와 기능을 찾아 보세요. .",
            "url": "https://kim-seung-jong.github.io/homepage/jupyter/python/2022/03/04/numpy.html",
            "relUrl": "/jupyter/python/2022/03/04/numpy.html",
            "date": " • Mar 4, 2022"
        }
        
    
  
    
        ,"post11": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://kim-seung-jong.github.io/homepage/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post12": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://kim-seung-jong.github.io/homepage/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "About me . 안녕하세요. 저는 한남대학교 빅데이터응용학과에 재학중인 김승종입니다. .",
          "url": "https://kim-seung-jong.github.io/homepage/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://kim-seung-jong.github.io/homepage/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}